# 第1章 互联网的增长引擎——推荐系统

## 1.2 推荐系统的架构

推荐系统要处理的是“人”和“信息”的关系。这里的“信息”，在商品推荐中指的是“商品信息”，在视频推荐中指的是“视频信息”，在新闻推荐中指的是“新闻信息”，简而言之，可统称为“**物品信息**”。

而从“人”的角度触发，为了更可靠地推测出“人”的兴趣点，推荐系统希望利用大量与“人”相关的信息，包括历史行为、人口属性、关系网络等，这些可统称为“**用户信息**”。

此外，在具体的推荐场景中，用户的最终选择一般会受时间、地点、用户的状态等一系列环境信息的影响，可称为“**场景信息**”或“上下文信息”。

### 1.2.1 推荐系统的逻辑框架

在获知“用户信息”“物品信息”“场景信息”的基础上，推荐系统要处理的问题可以较形式化地定义为：对于用户U（User），在特定场景C（context）下，针对海量地“物品”信息，构建一个函数f(U,I,C)，预测用户对特定候选物品I(item)的喜好程度，再根据喜好程度对所有候选物品进行排序，生成推荐列表的问题。

### 1.2.2 数据系统的技术架构

在实际的推荐系统中，工程师需要将抽象的概念和模块具体化、工程化。在前面逻辑框架基础上，工程师需要着重解决的问题有两类。

1. **数据和信息相关的问题**，即“用户信息”“物品信息”“场景信息”分别是什么？如何存储、更新和处理？
2. **推荐系统算法和模型相关的问题**，即推荐模型如何训练、如何预测、如何达成更好的推荐效果？

可以将这两类问题分成两个部分：“数据和信息”部分逐渐发展为推荐系统中融合了数据离线批处理、实时流处理的数据流框架；“算法和模型”部分则进一步细化为推荐系统中集训练（training）、评估（evaluation）、部署（deployment）、线上推断（online inference）为一体的模型框架。

![推荐系统_推荐系统技术架构示意图](..\..\整理后的文件\推荐系统 配图\推荐系统_推荐系统技术架构示意图.png)

### 1.2.3 推荐系统的数据部分

推荐系统的数据部分主要负责“用户”“物品”“场景”的信息收集与处理。具体地讲，讲负责数据收集与处理的三种平台按照实时性的强弱排序，依次为“客户端及服务器端实时数据处理”“流处理平台准实时数据处理”“大数据平台离线数据处理”。在实时性由强到弱递减的同时，三种平台的海量数据处理能力则由弱到强。因此，一个成熟的推荐系统的数据流系统会将三者取长补短，配合使用。

得到原始的数据信息后，推荐系统的数据处理系统会将原始数据进一步加工，加工后的数据出口主要有三个：

1. 生成推荐模型所需的样本数据，用于算法模型的训练和评估。
2. 生成推荐模型服务（model serving）所需的“特征”，用于推荐系统的线上推断。
3. 生成系统监控、商业智能（Business Intelligence，BI）系统所需的统计数据。

### 1.2.4 推荐系统的模型部分

推荐系统的“模型部分”是推荐系统的主体。模型结构一般由“召回层”“排序层”“补充策略与算法层”组成。

1. “**召回层**”
   一般利用高效的召回规则、算法或简单的模型，快速从海量的候选集中召回用户可能感兴趣的物品。
2. “**排序层**”
   利用排序模型对初筛的候选集进行排序
3. “**补充策略与算法层**”
   也被称为“再排序层”，可以在将推荐列表返回用户之前，为兼顾结果的“多样性”“流行度”“新鲜度”等指标，结合一些补充的策略和算法对推荐列表进行一定的调整，最终形成用户可见的推荐列表。

从推荐模型接收到所有候选物品集，到最后产生推荐列表。这一过程一般称为模型服务过程。

在线环境进行模型服务之前，需要通过模型训练（model training）确定模型结构、结构中不同参数权重的具体数值，以及模型相关算法和策略中的参数取值。模型的训练方法又可以根据模型训练环境的不同，分为“离线训练”和“在线更新”两部分，其中：离线训练的特点是可以利用全量样本和特征，使模型逼近全局最优点；在线更新则可以准实时地“消化”新的数据样本，更快地反映新的数据变化趋势，满足模型实时性的需求。

除此之外，为了评估推荐模型的效果，方便模型的迭代优化，推荐系统的模型部分提供了“离线评估”和“线上A/B测试”等多种模块，用得出的线下和线上评估指标，指导下一步的模型迭代优化。

以上所有模块共同组成了推荐系统模型部分的技术框架。模型部分，特别是“排序层”模型是推荐系统产生效果的重点，也是业界和学界研究的重心。下面着重介绍模型部分，特别是“排序层”模型的主流技术及其演化趋势。

# 第2章 前深度学习时代——推荐系统的进化之路

在互联网永不停歇的增长需求的驱动下，推荐系统的发展可谓一日千里，从2010年之前千篇一律的**协同过滤**（Collaborative Filtering，CF）、**逻辑回归**（Logistic Regression，LR），进化到**因子分解机**（Factorization Machine, FM）、**梯度提升树**（Gradient Boosting Decision Tree, GBDT），再到2015年之后**深度学习推荐模型**的百花齐放，各种模型架构层出不穷。推荐模型的主流模型经历了**从单一模型到组合模型，从经典框架到深度学习**的发展过程。

诚然，深度学习推荐模型已经成了推荐、广告、搜索领域的主流，但前深度学习时代的推荐模型仍是十分重要的，原因如下：

1. 即使在深度学习空前流行的今天，协同过滤、逻辑回归、因子分解机等传统推荐模型仍然凭借其可解释性强、硬件环境要求低、易于快速训练和部署等不可替代的优势，拥有大量适用的应用场景。
2. 传统推荐模型是深度学习推荐模型的基础。构成深度神经网络（Deep Neural Network，DNN）的基本单元是神经元，而应用广泛的传统逻辑回归模型正式神经元的另一种表现形式；深度学习推荐模型中影响力很大的**基于因子分解机支持的神经网络**（Factorization machine supported Neural Network，FNN）、**深度因子分解机**（Deep Factorization Machine， DeepFM）、**神经网络因子分解机**（Neural Factorization Machine, NFM）等深度学习模型更是与传统的FM模型有着千丝万缕的联系。此外，在传统推荐模型训练中广泛采用的**梯度下降**等训练方式，更是沿用至深度学习时代。所以说，传统推荐模型是深度学习推荐模型的基础，也是学习的入口。

## 2.1 传统推荐模型的演化关系图

![推荐系统_传统推荐模型的演化关系图](..\..\整理后的文件\推荐系统 配图\推荐系统_传统推荐模型的演化关系图.png)

简要来说，传统推荐模型的发展脉络主要由以下几个部分组成：

1. **协同过滤算法族**（UserCF、ItemCF、MF）。
   经典的协同过滤算法曾是推荐系统的首选模型，从物品相似度和用户相似度角度出发，协同过滤衍生出物品协同过滤（ItemCF）和用户协同过滤（UserCF）两种算法。为了使协同过滤能够更好地处理稀疏共现矩阵问题、增强模型的泛化能力，从协同过滤衍生出矩阵分解模型（Matrix Factorization，MF），并发展出矩阵分解的各分支模型。
2. **逻辑回归模型族**。
   与协同过滤仅仅利用用户和物品之间的显式或隐式反馈信息相比，逻辑回归能够利用和融合更多用户、物品以及上下文特征。从LR模型衍生出的模型同样“枝繁叶茂”，包括增强了非线性能力的大规模分片线性模型（Large Scale Piece-wise Linear Model，LS-PLM），由逻辑回归发展出来的FM模型，以及与多种不同模型配合使用后的组合模型，等等。
3. **因子分解机模型族**。
   因子分解机在传统逻辑回归的基础上，加入了二阶部分，使模型具备了进行特征组合的能力。更进一步，在因子分解机基础上发展出来的域感知因子分解机（Field-aware Factorization Machine，FFM）则通过加入特征域的概念，进一步加强了因子分解机特征交叉的能力。
4. **组合模型**。
   为了融合多个模型的优点，将不同模型组合使用是构建推荐模型的常用方法。Facebook提出GBDT+LR（梯度提升决策树（Gradient Boosting Decision Tree）+逻辑回归）组合模型是在业界影响力较大的组合方式。

## 2.2 协同过滤——经典的推荐算法

### 2.2.1 什么是协同过滤

顾名思义，“协同过滤”就是协同大家的反馈、评价和意见对海量的信息进行过滤，从中筛选出目标用户可能感兴趣的信息的推荐过程。

一个电商网站场景下的协同过滤推荐过程，其推荐过程按照顺序共分为6步。

1. 电商网站的商品库里一共有4件商品：游戏机、某小说、某杂志和某品牌电视机。
2. 用户X访问该电商网站，电商网站的推荐系统需要决定是否推荐电视机给用户X。可以利用的用户数据有用户X对其他商品的历史评价数据，以及其他用户对这些商品的历史评价数据。用户、商品、评价记录构成了带有标识的有向图。
3. 为了便于计算，将有向图转换为矩阵的形式（被称为“共现矩阵”），用户作为矩阵行坐标，商品作为列坐标，将“点赞”和“踩”的用户行为数据转换为矩阵中的相应元素值。
4. 预测的第一步就是找到与用户X兴趣最相似的n（Top n用户）个用户，然后综合相似用户对“电视机”的评价，得出用户X对“电视机”评价的预测。
5. 从共现矩阵中可知，用户B和用户C由于跟用户X的行向量近似，被选为Top n(这里假设n取2)相似用户，用户B和用户C对“电视机”的评价都是负面的。
6. 相似用户对“电视机”的评价是负面的，因此可预测用户X对“电视机”的评价也是负面的。

### 2.2.2 用户相似度的计算

1. **余弦相似度**
   余弦相似度（Cosine Similarity）衡量了用户向量 $\vec i$ 和用户向量$\vec j$ 之间的夹角大小。显然，夹角越小，证明余弦相似度越大，两个用户越相似。
   $$
   sim(i,j)=cos(i,j)=\frac{i \cdot j}{||i||\cdot||j||}
   $$

2. **皮尔逊相关系数**
   相比余弦相似度，皮尔逊相关系数通过使用用户平均分对各独立评分进行修正，减少了用户评分偏置的影响。
   $$
   sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\overline{R_i})(R_{j,p}-\overline{R_j})}{\sqrt{\sum_{p\in P}(R_{i,p}-\overline{R_i})^2} \sqrt{\sum_{p\in P}(R_{j,p}-\overline{R_j})^2}}
   \\其中，R_{i,p}代表用户 i 对用户p的评分。
   \\\overline{R_i}代表用户 i 对所有物品的平均评分，
   \\P代表所有物品的集合。
   $$

3. 基于皮尔逊系数的思路，还可以通过引入物品平均分的方式，减少物品评分偏置对结果的影响
   $$
   sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\overline{R_p})(R_{j,p}-\overline{R_p})}{\sqrt{\sum_{p\in P}(R_{i,p}-\overline{R_p})^2} \sqrt{\sum_{p\in P}(R_{j,p}-\overline{R_p})^2}}
   \\其中，\overline{R_p} 代表物品p得到的所有评分的平均分。
   $$

在传统协同过滤改进过程中，人们也是通过对相似度定义的改进来解决传统协同过滤算法存在的一些缺陷的。

### 2.2.3 最终结果的排序

获得Top n相似用户之后，利用Top n用户生成最终推荐结果的过程如下。假设“目标用户与其相似用户的喜好是相似的”，可根据相似用户的已有评价对目标用户的偏好进行预测。

这里最常用的方式是利用用户相似度和相似用户的评价的加权平均获得目标用户的评测预测。
$$
R_{u,p}=\frac{\sum_{s\in S}(w_{u,s}\cdot R_{s,p})}{\sum_{s\in S}w_{u,s}}
\\其中，权重w_{u,s}是用户u和用户s的相似度，
\\R_{s,p}是用户s对物品p的评分。
$$
在获得用户u对不同物品的评价预测后，最终的推荐列表根据预测得分进行排序即可得到。至此，完成协同过滤的全部推荐过程。

以上介绍的协同过滤算法基于用户相似度进行推荐，因此也被称为基于用户的协同过滤（UserCF）。但从技术的角度，它也存在一些缺点，主要包括以下两点。

1. 互联网应用的场景下，用户数往往远大于物品数，而UserCF需要维护用户相似度矩阵以便快速找出Top n相似用户。该用户相似度矩阵的存储开销非常大，且随着用户数的增长，存储空间以$n^2$的速度快速增长
2. 用户的历史数据向量往往非常稀疏，对于只有几次购买或者点击行为的用户来说，找到相似用户的准确度是非常低的。

## 2.2.4 ItemCF

由于UserCF技术上的两点缺陷，无论是Amazon，还是NetFlix，都没有采用UserCF算法，而采用了ItemCF算法实现其最初的推荐系统。

具体的讲，ItemCF是基于物品相似度进行推荐的协同过滤算法。通过计算共现矩阵中物品列向量的相似度得到物品之间的相似矩阵，再找到用户历史正反馈物品的相似物品进行进一步排序和推荐，ItemCF的具体步骤如下：

1. 基于历史数据，构建以用户（假设用户总数为m）为行坐标，物品（物品总数为n）为列坐标的 $m\times n$ 维共现矩阵。
2. 计算共现矩阵两两列向量间的相似性（相似度计算方式与用户相似度的计算方式相同），构建 $n\times n$ 维的物品相似度矩阵。
3. 获得用户历史行为数据中的正反馈物品列表。
4. 利用物品相似度矩阵，针对目标用户历史行为中的正反馈物品，找出相似的Top k个物品，组成相似物品集合。
5. 对相似物品集合中的物品，利用相似度分值进行排序，生成最终的推荐列表。

第五步中，如果一个物品与多个用户行为历史中的正反馈物品相似，那么该物品最终的相似度应该是多个相似度的累加
$$
R_{u,p}=\sum_{h \in H}(w_{p,h}\cdot R_{u,h})
\\其中，H是目标用户的正反馈物品集合，
\\w_{p,h}是物品p与物品h的物品相似度，
\\R_{u,h}是用户u对物品h的已有评分。
$$

### 2.2.6 协同过滤的下一步发展

协同过滤是一个非常直观、可解释性很强的模型，但它并不具备较强的泛化能力，换句话说，协同过滤无法将两个物品相似这个信息推广到其他物品的相似性计算上。这就导致了一个比较严重的问题——热门的物品具有很强的头部效应，容易跟大量物品产生相似性；而尾部的物品由于特征向量稀疏，很少与其他物品产生相似性，导致很少被推荐。

这一现象揭示了协同过滤的天然缺陷——**推荐结果的头部效应比较明显，处理稀疏向量的能力弱**。

为解决上述问题，同时增加模型的泛化能力，**矩阵分解技术**被提出。该方法在协同过滤的共现矩阵的基础上，<u>使用更稠密的隐向量标识用户和物品</u>，挖掘用户和物品的隐含兴趣和隐含特征。

另外，<u>协同过滤仅仅利用用户和物品的交互信息</u>，无法有效地引入用户年龄、性别、商品描述、商品分类、当前时间等一系列用户特征、物品特征和上下文特征，<u>这无疑造成了有效信息地遗漏</u>。为了在推荐模型中引入这些特征，推荐系统逐渐发展到以**逻辑回归模型**为核心的、能够综合不同类型特征的**机器学习模型**的道路上。

## 2.3 矩阵分解算法 ——协同过滤的进化

2006年，Netflix举办的著名推荐算法竞赛Netflix Prize Challenge中，以矩阵分解为主的推荐算法大放异彩，拉开了矩阵分解在业界流行的序幕。本节借用Netflix的场景例子说明矩阵分解算法的原理。

### 2.3.1 矩阵分解算法的原理

矩阵分解算法期望为每一个用户和视频生成一个隐向量，将用户和视频定位到隐向量的表示空间上，距离相近的用户和视频表明兴趣特点相近，在推荐过程中，就应该把距离相近的视频推荐给目标用户。

在“矩阵分解”的算法框架下，**用户和物品的隐向量是通过分解协同过滤生成的共现矩阵得到的**。这也是“矩阵分解”名字的由来。

矩阵分解算法将 $m \times n$ 维的共现矩阵R分解为 $m\times k$ 维的用户矩阵U和 $k\times n$ 维的物品矩阵V相乘的形式。其中m是用户数量，n是物品数量，k是隐向量的维度。k的大小决定了隐向量表达能力的强弱。k的取值越小，隐向量包含的信息越少，模型的泛化程度越高；反之，k的取值越大，隐向量的表达能力越强，但泛化程度相应降低。此外，k的取值还与矩阵分解的求解复杂度直接相关。在具体应用中，k的取值要经过多次试验找到一个推荐效果和工程开销的平衡点。

基于用户矩阵U和物品矩阵V，用户u对物品i的预估评分:
$$
\hat r_{ui}=q^T_i p_u
\\其中p_u是用户u在用户矩阵U中的对应行向量，
\\q_i是物品i在物品矩阵V中的对应列向量
$$

### 2.3.2 矩阵分解的求解过程

对矩阵进行矩阵分解的主要方法有三种：**特征值分解**（Eiden Decomposition）、**奇异值分解**（Singular Value Decomposition，SVD）和**梯度下降**（Gradient Descent）。其中，特征值分解只能作用于方阵，显然不适用于分解用户-物品矩阵。

**奇异值分解**的具体描述如下：

假设矩阵$\boldsymbol M$是一个$m\times n$的矩阵，则一定存在一个分解$\boldsymbol M = \boldsymbol{U \Sigma V^T}$，其中$\boldsymbol U$是$m\times m$的正交矩阵，$\boldsymbol V$是$n \times n$的正交矩阵，$\boldsymbol \Sigma$是$m\times n$的对角阵。

取对角阵$\boldsymbol \Sigma$中较大的k个元素作为隐含特征，删除$\boldsymbol \Sigma$的其他维度及$\boldsymbol U$和$\boldsymbol V$中的对应维度，矩阵$\boldsymbol M$被分解为$\boldsymbol M \approx \boldsymbol U_{m\times k}\boldsymbol \Sigma_{k\times k} V_{k\times n}^T$，至此完成了隐向量维度为k的矩阵分解。

可以说，奇异值分解似乎完美地解决了矩阵分解的问题，但其存在两点缺陷，使其不宜作为互联网场景下矩阵分解的主要方法。

1. 奇异值分解要求原始的共现矩阵是稠密的。互联网场景下大部分用户的行为历史非常少，用户-物品的共现矩阵非常稀疏，这与奇异值分解的应用条件相悖。如果应用奇异值分解，就必须对缺失的元素值进行填充。
2. 传统奇异值分解的计算复杂度达到了$O(mn^2)$的级别，这对于商品数量动辄上百万、用户数量往往上千万的互联网场景来说几乎是不可接受的。



由于上述两个原因，传统奇异值分解也不适用于解决大规模稀疏矩阵的矩阵分解问题。因此，**梯度下降法**成了进行矩阵分解的主要方法，这里对其进行具体介绍。

求解矩阵分解的目标函数：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\boldsymbol q^T_i \boldsymbol p_u)^2
$$


该目标函数的目的是让原始评分 $\boldsymbol r_{ui}$ 与用户向量和物品向量之积 $\boldsymbol q^T_i \boldsymbol p_u$ 的差尽量小，这样才能最大限度地保存共现矩阵地原始信息。其中K是所有用户评分样本的集合。为了减少过拟合现象，加入正则化项后的 <span id="MFfunction">目标函数</span> 如下：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\boldsymbol q^T_i \boldsymbol p_u)^2+\lambda(||\boldsymbol q_i||^2+||\boldsymbol p_u||^2)
$$

>**什么是过拟合现象和正则化**？
>
>正则化对应的英文是Regulation，直译过来是“规则化”，即希望让训练出的模型更“规则”、更稳定，避免预测出一些不稳定的“离奇”结果。（过拟合现象）
>
>为了让模型更“稳重”，需要给模型加入一些限制，这些限制就是正则化项。在加入正则化项之后再次进行训练，拟合函数避免受个别“噪声点”的影响，模型的预测输出更加稳定。
>
>正则化项严格的数学形式是什么样的呢？下面是某模型的损失函数（Loss Function）
>$$
>\frac{1}{2}\sum^n_{n=1}{t_n-\boldsymbol W^T\varnothing(\boldsymbol X_n)}^2+\frac{\lambda}{q}\sum^M_{j=1}|\boldsymbol w_j|^q\\
>其中t_n是训练集样本的真实输出，\boldsymbol W是权重,\varnothing是基函数。
>$$
>如果不考虑加号后面的部分，则上面式子是一个标准的L2损失函数。
>
>在加号后面的项就是正则化项，其中$\lambda$被称为正则化系数，$\lambda$ 越大，正则化的限制越强。剩余部分就是模型权重的q次方之和，q取1时被称为L1正则化，q取2时被称为L2正则化。
>
>将正则化项加入损失函数来保持模型稳定的做法也可以做如下理解。对于加入了正则化项的损失函数来说，模型权重越大，损失函数的值越大。梯度下降是朝着损失（Loss）小的方向发展的，因此正则化项其实是希望在尽量不影响原模型与数据集之间损失的前提下，使模型的权重变小，权重的减小自然会让模型的输出波动更小，从而达到让模型更稳定的目的。

对[目标函数](#MFfunction)的求解可以利用非常标准的梯度下降过程完成。

1. 确定[目标函数](#MFfunction)。

2. 对目标函数求偏导，求取梯度下降的方向和幅度。
   对$\boldsymbol q_i$求偏导，得到的结果为：
   $$
   2(\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol p_u - 2\lambda\boldsymbol q_i
   $$
   对$\boldsymbol p_u$求偏导的结果为
   $$
   2(\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol q_i - 2\lambda\boldsymbol p_u
   $$

3. 利用第2步的求导结果，沿梯度的反方向更新参数：
   $$
   \boldsymbol q_i \leftarrow\boldsymbol q_i-\gamma((\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol p_u-\lambda\boldsymbol q_i)\\
   \boldsymbol p_u \leftarrow\boldsymbol p_u-\gamma((\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol q_i-\lambda\boldsymbol p_u)\\
   其中\gamma为学习率
   $$
   
4. 当迭代次数超过上限n或损失低于阈值$\theta$时，结束训练，否则循环第3步。

在完成矩阵分解过程后，即可得到所有用户和物品的隐向量。在对某用户进行推荐时，可利用该用户的隐向量与所有物品的隐向量进行逐一的内积运算，得出该用户对所有物品的评分评测，再依次进行排序，得到最终的推荐列表。

在了解了矩阵分解的原理之后，就可以更清楚地解释为什么矩阵分解相较协同过滤有更强的泛化能力。在矩阵分解算法中，由于隐向量的存在，使任意的用户和物品之间都可以得到评测分值。而隐向量其实是利用全局信息生成的，有更强的泛化能力；而对协同过滤来说，如果两个用户没有相同的历史行为，两个物品没有相同的购买，那么这两个用户和两个物品的相似度计算，这能使协同过滤不具备泛化利用全局信息的能力）。

### 2.3.3 消除用户和物品打分的偏差

由于不同用户的打分体系不同（比如在5分为满分的情况下，有的用户认为打3分已经是很低的分数了，而有的用户认为打1分才是比较差的评分），不同物品的衡量标准也有所区别（比如电子产品的平均分和日用品的平均分差异也可能比较大），为了消除用户和物品打分的偏差（Bias），常用的做法是在矩阵分解时加入用户和物品的偏差向量，如：
$$
\boldsymbol r_{ui}=\mu+b_i+b_u+\boldsymbol q^T_i\boldsymbol p_u\\
其中\mu是全局偏差常数，\\
b_i是物品偏差系数，可使用物品i收到的所有评分的平均值，\\
b_u是用户偏差系数，可使用用户u给出的所有评分的均值
$$
与此同时，矩阵分解目标函数也需要在[之前目标函数](#MFfunction)基础上做相应改变，如下：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*,\boldsymbol b^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\mu-b_u-b_i-\boldsymbol q^T_i\boldsymbol p_u)^2+\lambda(||\boldsymbol p_u||^2+||\boldsymbol q_i||^2+b_u^2+b_i^2)
$$
同理，矩阵分解的求解过程会随着目标函数的改变而变化，主要区别在于利用新的目标函数，通过求导得出新的梯度下降公式，在此不再赘述。

加入用户和物品的打分偏差项之后，矩阵分解得到的隐向量更能反映不同用户对不同物品的“真实”态度差异，也就更容易捕获评价数据中有价值的信息，从而避免推荐结果有偏。

### 2.3.4 矩阵分解的优点和局限性

相比协同过滤，矩阵分解有如下非常明显的优点。

1. **泛化能力强**。在一定程度上解决了数据稀疏问题。
2. **空间复杂度低**。不需再存储协同过滤服务阶段所需的“庞大”的用户相似性或物品相似性矩阵，只需存储用户和物品隐向量。空间复杂度由$n^2$级别降低到$(n+m)\cdot k$级别。
3. **更好的扩展性和灵活性**。矩阵分解的最终产出是用户和物品隐向量，这其实与深度学习中Embedding思想不谋而合，因此矩阵分解的结果也非常便于与其他特征进行组合和拼接，并便于与深度学习网络进行无缝结合。

与此同时，也要意识到矩阵分解的局限性。与协同过滤一样，矩阵分解同样不方便加入用户、物品和上下文相关的特征，这使得矩阵分解丧失了利用很多有效信息的机会，同时在缺乏用户历史行为时，无法进行有效的推荐。为了解决这个问题，逻辑回归模型及其后续发展出的因子分解机等模型，凭借其天然的融合不同特征的能力，逐渐在推荐系统领域得到更广泛的应用。

## 2.4 逻辑回归——融合多种特征的推荐模型

相比协同过滤模型仅利用用户和物品的相互行为信息进行推荐，逻辑回归模型能够综合利用用户、物品、上下文等多种不同特征，生成较为“全面”的推荐结果。另外，逻辑回归的另一种表现形式“感知机”作为神经网络中最基础的单一神经元，是深度学习的基础性结构。因此，能够进行多特征融合的逻辑回归模型成了独立于协同过滤的推荐模型发展的另一个主要方向。

相比于协同过滤和矩阵分解利用用户和物品的“相似度”进行推荐，逻辑回归将推荐问题看成一个分类问题，通过预测正样本的概率对物品进行排序。这里的正样本可以是用户“点击”了某商品，也可以是用户“观看”了某视频，均是推荐系统希望用户产生的“正反馈”行为。因此，逻辑回归模型将推荐问题转换成了一个点击率（Click Through Rate，CTR）预估问题。

### 2.4.1 基于逻辑回归模型的推荐流程

基于逻辑回归的推荐过程如下：

1. 将用户年龄、性别、物品属性、物品描述、当前时间、当前地点等特征转换成数值型特征向量。
2. 确定逻辑回归模型的优化目标（以优化“点击率”为例），利用已有样本数据对逻辑回归模型进行训练，确定逻辑回归模型的内部参数。
3. 在模型服务阶段，将特征向量输入逻辑回归模型，经过逻辑回归模型的推断，得到用户“点击”（这里用点击作为推荐系统正反馈行为的例子）物品的概率。
4. 利用“点击”概率对所有候选物品进行排序，得到推荐列表。

基于逻辑回归的推荐过程的重点在于，利用样本的特征向量进行模型训练和在线推断。

### 2.4.2 逻辑回归模型的数学形式

![推荐模型_逻辑回归模型的数学形式的推断过程](..\..\整理后的文件\推荐系统 配图\推荐模型_逻辑回归模型的数学形式的推断过程.png)

逻辑回归模型的推断过程可以分为如下几步:

1. 将特征向量 $\boldsymbol x=(x_1,x_2,\cdots,x_n)^T$ 作为模型的输入。
2. 通过为各特征赋予相应的权重 $(w_1,w_2,\cdots,w_{n+1})$ 来表示各特征的重要性差异，将各特征进行加权求和，得到 $\boldsymbol x^T \boldsymbol w$。
3. 将 $\boldsymbol x^T \boldsymbol w$ 输入sigmoid函数，使之映射到0~1的区间，得到最终的“点击率”。

其中sigmoid函数的具体形式：

$$
f(z)=\frac{1}{1+e^{-z}}
$$
 ![sigmoid函数图像](..\..\整理后的文件\推荐系统 配图\sigmoid函数图像.png)

可以直观的看到sigmoid的值域在0~1之间，符合“点击率”的物理意义。

综上，<span id = "LRmath">逻辑回归模型整个推断过程的数学形式 </span>为：
$$
f(\boldsymbol x)=\frac{1}{1+e^{-(\boldsymbol w \cdot \boldsymbol x+b)}}
$$

### 2.4.3 逻辑回归模型的训练方法

对于标准的逻辑回归模型来说，要确定的参数就是特征向量相应的权重向量 $\boldsymbol w$，下面介绍逻辑回归模型的权重向量 $\boldsymbol w$ 的训练方法。

逻辑回归模型常用的训练方法是梯度下降法、牛顿法、拟牛顿法等，其中梯度下降法是应用最广泛的训练方法，也是学习深度学习各种训练方法的基础。

>**什么是梯度下降法**？
>
>梯度下降法是一个一阶最优化算法。应用梯度下降法的目的是找到一个函数局部极小值。为此，必须沿函数上当前点对应梯度（或者近似梯度）的反方向进行规定步长距离的迭代搜索。如果向梯度正方向迭代进行搜索，则会接近函数的局部极大值点，这个过程被称为梯度上升法。
>
>这利用了“梯度”的性质：如果实值函数F(x)在点$x_0$处可微且有定义，那么函数F(x)在点$x_0$处沿着梯度相反的方向$-\nabla F(x)$ 下降最快。
>
>因此，在优化某模型的目标函数时，只需对目标函数进行求导，得到梯度的方向，沿梯度的反方向下降，并迭代此过程直至寻找到局部最小点。

使用梯度下降法求解逻辑回归模型的第一步时确定逻辑回归的目标函数。已知[逻辑回归的数学形式](#LRmath)，这里表示成$f_{\boldsymbol w}(\boldsymbol x)$。对于一个输入样本 $\boldsymbol x$ ，预测结果为正样本（类别1）和负样本（类别0）的概率如下：
$$
\left\{
	\begin{array}{l}
		P(y=1|\boldsymbol x;\boldsymbol w)=f_{\boldsymbol w}(\boldsymbol x)\\
		P(y=0|\boldsymbol x;\boldsymbol w)=1-f_{\boldsymbol w}(\boldsymbol x)
	\end{array}
\right.
$$
综合起来，可以写成：
$$
P(y|\boldsymbol x;\boldsymbol w)=(f_{\boldsymbol w}(\boldsymbol x))^y(1-f_{\boldsymbol w}(\boldsymbol x))^{1-y}
$$
由极大似然估计的原理可以写出逻辑回归的目标函数：
$$
L(\boldsymbol w)=\prod^m_{i=1}P(y|\boldsymbol x;\boldsymbol w)
$$
由于目标函数连乘的形式不便于求导，故在上式两侧取log，并乘以系数-(1/m)，将求最大值的问题转换成求极小值的问题，最终的目标函数形式如下：
$$
J(\boldsymbol w)=-\frac{1}{m}l(\boldsymbol w)=-\frac{1}{m}logL(\boldsymbol w)\\
=-\frac{1}{m}(\sum^m_{i=1}(y^i logf_{\boldsymbol w}(\boldsymbol x^i)+(1-y^i)log(1-f_{\boldsymbol w}(\boldsymbol x^i)))
$$
在得到逻辑回归的目标函数后，需对每个参数求偏导，得到梯度方向，对$J(\boldsymbol w)$中参数$w_j$求偏导的结果如下：
$$
\frac{\partial}{\partial w_j}J(\boldsymbol w)=\frac{1}{m}\sum^m_{i=1}(f_{\boldsymbol w}(\boldsymbol x^i)-y^i)\boldsymbol x^i_j
$$
在得到梯度之后，即可得到模型参数的更新方式，如下：
$$
w_j \leftarrow w_j -\gamma\frac{1}{m}\sum^m_{i=1}(f_w(x^i)-y^i)x^i_j
$$
至此，完成了逻辑回归模型的更新推导。

可以看出，无论矩阵分解还是逻辑回归，在用梯度下降求解时都遵循其基本步骤。问题的关键在于利用模型的数学形式找出其目标函数，并通过求导得到梯度下降的公式。

### 2.4.4 逻辑回归模型的优势

在深度学习模型流行之前，逻辑回归模型曾在相当长的一段时间里是推荐系统、计算广告业界的主要选择之一。除了在形式上适于融合不同特征，形成较“全面”的推荐结果，其流行还有三个方面的原因：一是数学含义上的支撑；二是可解释性强；三是工程化的需要。

1. **数学含义上的支撑**
   逻辑回归作为广义线性模型的一种，它的假设是因变量y服从伯努利分布。那么在CTR预估这个问题上，“点击”事件是否发生就是模型的因变量y，而用户是否点击广告是一个经典的掷偏心硬币问题。因此，CTR模型的因变量显然应该服从伯努利分布。所以，采用逻辑回归作为CTR模型是符合“点击”这一事件的物理意义的。
   与之相比，线性回归作为广义线性模型的另一个特例，其假设是因变量y服从高斯分布，这显然不是点击这类二分类问题的数学假设。

2. **可解释性强**
   直观地讲，逻辑回归模型地数学形式是各特征的加权和，再施以sigmoid函数。在逻辑回归数学基础的支撑下，逻辑回归的简单数学形式页非常符合人类对预估过程的直觉认知。
   使用各特征的加权和是为了综合不同特征对CTR的影响，而不同特征的重要程度不一样，所以，为不同特征指定不同的权重，代表不同的特征的重要程度。最后，通过sigmoid函数，使其值能够映射到0~1区间，正好符合CTR的物理意义。
   逻辑回归如此符合人类的直觉认识显然有其他的好处——使模型具有极强的可解释性。算法工程师可以轻易地根据权重的不同解释哪些特征比较重要，在CTR模型的预测有偏差时定位是哪些因素影响了最后的结果。在与负责运营、产品的同事合作时，也便于给出可解释的原因，有效降低沟通成本。

3. **工程化的需要**

   在互联网公司每天动辄TB级别的数据面前，模型的训练开销和在线推断效率显得异常重要。在GPU尚未流行的2012年之前，逻辑回归模型凭借其易于并行化、模型简单、训练开销小等特点，占据着工程领域的主流。囿于工程团队的限制，即使其他复杂模型的效果有所提升，在没有明显击败逻辑回归模型之前，公司也不会贸然加大计算资源的投入，升级推荐模型或CTR模型，这是逻辑回归持续流行的另一重要原因。

### 2.4.5 逻辑回归模型的局限性

逻辑回归作为一个基础模型，显然有其简单、直观、易用的特点。但其局限性也是非常明显的：表达能力不强，无法进行特征交叉、特征筛选等一系列较为“高级”的操作，因此不可避免地造成信息地损失。为解决这一问题，推荐模型朝着复杂化的方向继续发展，衍生出因子分解机等高维的复杂模型。在进入深度学习时代之后，多层神经网络强大的表达能力可以完全替代逻辑回归模型，让它逐渐从各公司退役。

## 2.5 从FM到FFM——自动化特征交叉的解决方案

逻辑回归模型表达能力不强的问题，会不可避免地造成有效信息地损失。在仅使用单一特征而非交叉特征进行判断地情况下，有时不仅是信息损失地问题，甚至会得出错误地结论。著名地“辛普森悖论”用一个简单地例子，说明了进行多维度特征交叉地重要性。

> **什么是辛普森悖论**？
>
> 在对样本集合进行分组研究时，在分组比较中都占优势的一方，在总评中有时反而是失势的一方，这种有悖常理的现象，被称为“辛普森悖论”。
>
> 假如下面两表为视频应用中男性用户和女性用户点击视频的数据。
>
> 男性：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 8          | 530        | 1.51%  |
> | 视频B | 51         | 1520       | 3.36%  |
>
> 女性：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 201        | 2510       | 8.01%  |
> | 视频B | 92         | 1010       | 9.11%  |
>
> 从以上数据中可以看出，无论男性用户还是女性用户，对视频B的点击率都高于A，显然推荐系统应该优先考虑向用户推荐B。
>
> 那么，如果忽略性别这个维度，将数据汇总会得出什么结论呢？
>
> 汇总：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 209        | 3040       | 6.88%  |
> | 视频B | 143        | 2530       | 5.65%  |
>
> 在汇总结果中，视频A的点击率居然比视频B高。如果据此进行推荐，将得出与之前的结果完全相反的结论，这就是所谓的“辛普森悖论”。

逻辑回归只对单一特征做简单加权，不具备进行特征交叉生成高维组合特征的能力，因此表达能力很弱，甚至可能得出像“辛普森悖论”那样的错误结论。因此，通过改造逻辑回归模型，使其具备特征交叉能力是必要和迫切的。

### 2.5.1 POLY2模型——特征交叉的开始

针对特征交叉的问题，算法工程师经常采用先手动组合特征，再通过各种分析手段筛选特征的方法，但该方法无疑是低效的。更遗憾的是，人类的经验往往有局限性，程序员的时间和精力也无法支撑其找到最优的特征组合。因此，采用POLY2模型进行特征的“暴力”组合成了可行的选择。

$$
\empty POLY2(\boldsymbol w,\boldsymbol x)=\sum^{n-1}_{j_1=1}\sum^n_{j_2=j_1+1}w_h(j_1,j_2)x_{j_1}x_{j_2}
$$

可以看到，该模型对所有特征进行两两交叉（特征$x_{j_1}$和$x_{j_2}$），并对所有的特征组合赋予权重$w_h(j_1,j_2)$。POLY2通过暴力组合特征的方式，在一定程度上解决了特征组合的问题。POLY2模型本质上仍是线性模型，其训练方法与逻辑回归并无区别，因此便于工程上的兼容。

但POLY2模型存在两个较大的缺陷。

1. 在处理互联网数据时，经常采用one-hot编码的方法处理类别型数据，致使特征向量极度稀疏，POLY2进行无选择的特征交叉——原本就非常稀疏的特征向量更加稀疏，导致大部分交叉特征的权重缺乏有效的数据进行训练，无法收敛。
2. 权重参数的数量从n直接上升到$n^2$，极大的增加了训练复杂度。

> **什么是one-hot编码**？
>
> one-hot编码是将类别型特征向量的一种编码方式。由于类别型特征不具备数值化意义，如果不进行one-hot编码，无法将其直接作为特征向量的一个维度使用。
>
> 举例来说，某样本有三个特征，分别是星期、性别和城市，用`[Weekday=Tuesday,Gender=Male,City=London]`表示。由于模型的输入特征向量仅可以是数值型特征向量，最常用的方法就是将特征做one-hot编码。编码结果如下：
> $$
> \begin{matrix} \underbrace{ [0,1,0,0,0,0,0] }\\Weekday=Tuesday \end{matrix}
> \begin{matrix} \underbrace{ [0,1] }\\Gender=Male \end{matrix}
> \begin{matrix} \underbrace{ [0,0,1,0,\cdots,0,0] }\\City=London \end{matrix}
> $$
> 可以看到，Weekday这个特征域有7个维度，Tuesday对应第2个维度，所以把对应维度置为1。Gender分为Male和Female，one-hot编码就有两个维度，City特征域同理。
>
> 虽然one-hot编码方式可以将类别型特征转变成数值型特征向量，但是会不可避免地造成特征向量中存在大量数值为0的特征维度。这在互联网这种海量用户场景下尤为明显。假设某应用有一亿用户，那么将用户id进行one-hot编码后，将造成1亿维特征向量中仅有1维是非零的。这是造成互联网模型的输入特征向量稀疏的主要原因。

### 2.5.2 FM模型——隐向量特征交叉

为了解决POLY2模型的缺陷，2010年，Rendle提出了FM模型。

FM二阶部分的数学形式：
$$
\varnothing FM(\boldsymbol w,\boldsymbol x)=\sum^n_{j_i=1}\sum^n_{j_2=j_1+1}（\boldsymbol w_{j_i}\cdot\boldsymbol w_{j_2}）x_{j_1}x_{j_2}
$$
与POLY2相比，其主要区别是用两个向量的内积（$\boldsymbol w_{j_i}\cdot\boldsymbol w_{j_2}$）取代了单一的权重系数$w_h(j_1,j_2)$。具体地说，FM为每个特征学习了一个隐权重向量（lacent vector）。在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。

本质上，FM引入隐向量的做法，与矩阵分解用隐向量代表用户和物品的做法异曲同工。可以说，FM是将矩阵分解隐向量的思想进行了进一步扩展，从单纯的用户、物品隐向量扩展到了所有特征上。

FM通过引入特征隐向量的方式，直接把POLY2模型$n^2$级别的权重参数数量减少到了nk（k为隐向量维度，n>>k）。在使用梯度下降法进行FM训练的过程中，FM的训练复杂度同样可被降低到nk级别，极大地降低了训练开销。

隐向量的引入使FM能更好地解决数据稀疏性地问题。举例来说，在某商品推荐的场景下，样本有两个特征，分别是频道（channel）和品牌（brand），某训练样本的特征组合是（ESPN, Adidas）。在POLY2中，只有当ESPN和Adidas同时出现在一个训练样本中时，模型才能学到这个组合特征对应的权重；而在FM中，ESPN的隐向量也可以通过（ESPN, Gucci）样本进行更新，Adidas的隐向量也可以通过（NBC, Adidas）样本进行更新，这大幅降低了模型对数据稀疏性的要求。甚至对于一个从未出现过的特征组合（NBC, Gucci），由于模型之前已经分别学习过NBC, Gucci的隐向量，具备了计算该特征组合权重的能力，这是POLY2无法实现的。相比POLY2，FM虽然丢失了某些具体特征组合的精确记忆能力，但是泛化能力大大提高。

在工程方面，FM同样可以用梯度下降法进行学习，使其不失实时性和灵活性。相比之后深度学习模型复杂的网络结构导致难以部署和线上服务，FM较容易实现的模型结构使其线上推断的过程相对简单，也更容易进行线上部署和服务。因此，FM在2012-2016年前后，成为业界主流的推荐模型之一。

### 2.5.3 FFM模型——引入特征域的概念

2015年，基于FM提出的FFM在多项CTR预估大赛中夺魁，并被Criteo、美团等公司深度应用在推荐系统、CTR预估等领域。相比FM模型，FFM模型引入了特征域感知（field-aware）这一概念，使模型的表达能力更强。
$$
\varnothing FFM(\boldsymbol w,\boldsymbol x)=\sum^n_{j_1=1}\sum^n_{j_2=j_1+1}(\boldsymbol w_{j_1,f_2}\cdot\boldsymbol w_{j_2,f_1})x_{j_1}x_{j_2}
$$
上式是FFM的数学形式的二阶部分。其与FM的区别在于隐向量由原来的$\boldsymbol w_{j_1}$变成了$\boldsymbol w_{j_1,f_2}$,这意味着每个特征对应的不是唯一一个隐向量，而是一组隐向量。当$\boldsymbol x_{j_1}$特征与$\boldsymbol x_{j_2}$特征进行交叉时，$\boldsymbol x_{j_1}$特征会从$\boldsymbol x_{j_1}$的这一组隐向量中挑出与特征$\boldsymbol x_{j_2}$的域$f_2$对应的隐向量$\boldsymbol w_{j_1,f_2}$进行交叉。同理，$\boldsymbol x_{j_2}$也会用与$\boldsymbol x_{j_1}$的域$f_1$对应的隐向量进行交叉。

这里所说的域（field）简单地讲，代表特征域，域内的特征一般是采用one-hot编码形成的一段one-hot特征向量。例如，用户的性别分为男、女、未知三类，那么对一个女性用户来说，采用one-hot方式的编码的特征向量为`[0,1,0]`，这个三维的特征向量就是一个”性别“特征域。将所有特征域连接起来，就组成了样本的整体特征向量。

下面介绍Criteo FFM的论文中的一个例子，更具体地说明FFM的特点。假设在训练推荐模型过程中接收到的训练样本如下：

~~~
Publisher(P)		Advertiser(A)		Gender(G)
ESPN				NIKE				Male
~~~

其中，Publisher、Advertiser、Gender是三个特征域，ESPN、NIKE、Male分别是这三个特征域的特征值（还需要转换成one-hot特征）。

如果按照FM的原理，特征ESPN和NIKE和Male都有对应的隐向量$\boldsymbol w_{ESPN}$，$\boldsymbol w_{NIKE}$，$\boldsymbol w_{Male}$，那么ESPN特征与NIKE特征、ESPN特征与Male特征做交叉的权重应该是$\boldsymbol w_{ESPN}\cdot \boldsymbol w_{NIKE}$和$\boldsymbol w_{ESPN}\cdot \boldsymbol w_{Male}$。其中，ESPN对应的隐向量$\boldsymbol w_{ESPN}$在两次特征交叉过程中是不变的。

而在FFM中，ESPN与NIKE、ESPN与Male交叉特殊的权重分别是$\boldsymbol w_{ESPN,A}\cdot \boldsymbol w_{NIKE,P}$和$\boldsymbol w_{ESPN,G}\cdot \boldsymbol w_{Male,P}$。

细心的读者肯定已经注意到，ESPN在与NIKE和Male交叉时分别使用了不同的隐向量$\boldsymbol w_{ESPN,A}$和$\boldsymbol w_{ESPN,G}$，这是由于NIKE和Male分别在不同的特征域Advertiser（A）和Gender(G)导致的。

在FFM模型的训练过程中，需要学习n个特征在f个域上的k维隐向量，参数数量共$n\cdot k\cdot f$个。在训练方面，FFM的二次项并不能像FM那样简化，因此其复杂度为$kn^2$。

相比FM，FFM引入了特征域的概念，为模型引入了更多有价值的信息，使模型的表达能力更强，但与此同时，FFM的计算复杂度上升到$kn^2$，远大于FM的$kn$。在实际工程应用中，需要在模型效果和工程投入之间进行权衡。

### 2.5.4 从POLY2到FFM的模型演化过程

POLY2模型直接学习每个交叉特征的权重，若特征数量为n，则权重数量为$n^2$量级，具体为n(n-1)/2个。如下所示，每个圆点代表一个特征交叉项。

~~~
f(w,x) =	⚪		+		⚪		+		⚪
		w(ESPN,NIKE)	w(ESPN,Male)	w(NIKE,Male)
~~~

FM模型学习每个特征的k维隐向量，交叉特征由相应特征隐向量的内积得到，权重数量共nk个。FM比POLY2的泛化能力强，但记忆能力有所减弱，处理稀疏特征向量的能力远强于POLY2。每个特征交叉项不再是单独的圆点，而是3个圆点的内积，代表每个特征有一个3维的隐向量。

~~~
			⚪		⚪				⚪		⚪				⚪		⚪
f(w,x) =	⚪	·	⚪		+		⚪	·	⚪		+		⚪	·	⚪
			⚪		⚪				⚪		⚪				⚪		⚪
		w(ESPN)		w(NIKE)			w(ESPN)		w(Male)			w(NIKE)	w(Male)
~~~

FFM模型在FM模型的基础上引入了特征域的概念，在做特征交叉时，每个特征选择与对方域对应的隐向量做内积运算，得到交叉特征的权重，在有n个特征，f个特征域，隐向量维度为k的前提下，参数数量共$n\cdot k\cdot f$个。如下所示，每个特征都有两个隐向量，根据特征交叉对象特征域的不同，选择使用对应的隐向量。

~~~
			⚪⚪		⚪⚪			⚪⚪		⚪⚪			⚪⚪		⚪⚪
f(w,x) =	⚪⚪	·	⚪⚪		+	⚪⚪	·	⚪⚪		+	⚪⚪	·	⚪⚪
			⚪⚪		⚪⚪			⚪⚪		⚪⚪			⚪⚪		⚪⚪
		w(ESPN,A)	w(NIKE,P)		w(ESPN,G)	w(Male,P)	w(NIKE,G)	w(Male,A)
~~~

理论上，FM模型族利用交叉特征的思路可以引申到三阶特征交叉，甚至更高维的阶段，但由于组合爆炸问题的限制，三阶FM无论是权重数量还是训练复杂度都过高，难以在实际工程中实现。那么，如何突破二阶特征交叉的限制，进一步加强模型特征组合的能力，就成了推荐模型发展的方向。

## 2.6 GBDT+LR——特征工程模型化的开端

FFM模型采用引入特征域的方式增强了模型的特征交叉能力，但无论如何，FFM只能做二阶的特征交叉，如果继续提高特征交叉的维度，会不可避免地产生组合爆炸和计算复杂度过高的问题。那么，有没有其他方法可以有效地处理高维特征组合和筛选的问题呢？2014年，Facebook提出了基于GBDT+LR组合模型的解决方案。

### 2.6.1 GBDT+LR组合模型的结构

简而言之，Facebook提出了一种利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当作LR模型输入，预估CTR的模型结构。

> GBDT+LR的模型结构：
>
> 输入特征 --> 树分裂 --> 转换后的特征 --> 线性分类器

需要强调的是，用GDBT构建特征工程，利用LR预估CTR这两步是独立训练的，所以不存在如何将LR的梯度回传到GDBT这类复杂的问题。利用LR预估CTR的过程在2.4逻辑回归可以看到，本节着重讲解利用GBDT构建新的特征向量的过程。

> **什么是GBDT模型**？
>
> GBDT的基本结构是决策树组成的树林，学习方式是梯度提升。
>
> 具体地讲，GBDT作为集成模型，预测的方式是把所有子树的结果加起来。
> $$
> D(x)=d_{tree1}(x)+d_{tree2}(x)+\cdots
> $$
> GBDT通过逐一生成决策子树的方式生成整个树林，生成新子树的过程是利用样本标签值与当前树林预测值之间的残差，构建新的子树。
>
> 假设当前已经生成了3棵子树，则当前的预测值为
> $$
> D(x)=d_{tree1}(x)+d_{tree2}(x)+d_{tree3}(x)
> $$
> GBDT期望的是构建第4棵子树，使当前树林的预测结果D(x)与第4棵子树的预测结果$d_{tree4}(x)$之和，能进一步逼近理论上拟合函数f(x)，即
> $$
> D(x)+d_{tree4}(x)=f(x)
> $$
> 所以，第4棵子树的生成过程是以目标拟合函数和已有树林预测结果的残差R(X)为目标的：
> $$
> R(x)=f(x)-D(x)
> $$
> 理论上，如果可以无限生成决策树，那么GBDT可以无限逼近由所有训练集样本组成的目标拟合函数，从而达到减少预测误差的目的。

GBDT是由多棵回归树组成的树林，后一棵树以前面树林的结果与真实结果的残差为拟合目标。每棵树生成的过程是一棵标准的回归树生成过程，因此回归树中每个节点的分裂是一个自然的特征选择的过程，而多层节点的结构则对特征进行了有效的自动组合，也就非常高效的解决了过去棘手的特征选择和特征组合的问题。

### 2.6.2 GBDT进行特征转换的过程

利用训练集训练好GBDT模型之后，就可以利用该模型完成从原始特征向量到新的离散型特征向量的转化。具体过程如下。

一个训练样本在输入GBDT的某一子树后，会根据每个节点的规则最终落入某一叶子节点，把该叶子节点置为1，其他叶子节点置为0，所有叶子节点组成的向量即形成了该棵树的特征向量，把GBDT所有子树的特征向量连接起来，即形成了后续LR模型输入的离散型特征向量。

举例来说，GBDT可以由三棵子树构成，每棵子树有4个叶子节点，输入一个训练样本后，其先后落入”子树1“的第3个叶节点中，那么特征向量就是`[0,0,1,0]`，”子树2“的第1个叶节点，特征向量为`[1,0,0,0]`，”子树3“的第4个叶节点，特征向量为`[0,0,0,1]`，最后连接所有特征向量，形成最终的特征向量`[0,0,1,0,1,0,0,0,0,0,0,1]`。

事实上，决策树的深度决定了特征交叉的阶数。如果决策树的深度为4，则通过3次节点分裂，最终的叶节点实际上是进行三阶特征组合后的结果，如此强的特征组合能力显然是FM系的模型不具备的。但GBDT容易产生过拟合，以及GBDT的特征转换方式实际上丢失了大量特征的数值信息，因此不能简单地说GBDT的特征交叉能力强，效果就比FFM好，在模型的选择和调试上，永远都是多种因素综合作用的结果。

### 1.8.3 GBDT+LR组合模型开启的特征工程新趋势

GBDT+LR组合模型对于推荐系统领域的重要性在于，它大大推进了特征工程模型化这一重要趋势。在GBDT+LR组合模型出现之前，特征工程的主要解决方法有两个：一是进行人工的或半人工的特征组合和特征筛选；二是通过改造目标函数，改进模型结构，增加特征交叉项的方式增强特征组合能力。但这两种方法都有弊端，第一种方法对算法工程师的经验和精力投入要求较高；第二种方法则要求从根本上改变模型结构，对模型设计能力的要求较高。

GBDT+LR组合模型的提出，意味着特征工程可以完全交由一个独立的模型来完成，模型的输入可以是原始的特征向量，不必在特征工程上投入过多的人工筛选和模型设计的精力，实现真正的端到端（End to End）训练。

广义上讲，深度学习模型通过各类网络结构、Embedding层等方法完成特征工程的自动化，都是GBDT+LR开启的特征工程模型化这一趋势的延续。

## 2.7 LS-PLM——阿里巴巴曾经的主流推荐模型

阿里巴巴曾经的主流推荐模型——”大规模分段线性模型“（Large Scale Piece-wise Linear Model，简称为LS-PLM）。

虽然该模型在2017年才被阿里巴巴公之于众，但其实早在2012年，它就是阿里巴巴主流的推荐模型，并在深度学习模型提出之前长时间应用于阿里巴巴的各类广告场景。

LS-PLM的结构与三层神经网络极其相似，在深度学习来临的前夜，可以将它看作推荐系统领域连接两个时代的节点。

### 2.7.1 LS-PLM模型的主要结构

LS-PLM，又被称为MLR（Mixed Logistic Regression，混合逻辑回归）模型。本质上，LS-PLM可以看作对逻辑回归的自然推广，它在逻辑回归的基础上采用分而治之的思路，先对样本进行分片，再在样本分片中应用逻辑回归进行CTR预估。

在逻辑回归的基础上加入聚类思想，其灵感来自对广告推荐领域样本特点的观察。举例来说，如果CTR模型要预估的是女性受众点击女装广告的CTR，那么显然，我们不希望把男性用户点击数码类产品的样本数据也考虑进来，因为这样的样本不仅与女性购买女装的广告场景毫无相关性，甚至会在模型训练过程中干扰相关特征的权重。为了让CTR模型对不同用户群体、不同使用场景更有针对性，其采用的方法是先对全量样本进行聚类，再对每个分类施以逻辑回归模型进行CTR预估。LS-PLM的实现思路就是由该灵感产生的。

LS-PLM的数学形式，首先用聚类函数$\pi$对样本进行分类（这里的$\pi$采用了softmax函数对样本进行多分类），再用LR模型计算样本在分片中具体的CTR，然后将二者相乘后求和。
$$
f(x)=\sum^m_{i=1}\pi_i(x)\cdot\eta_i(x)=\sum^m_{i=1}\frac{e^{\eta_i\cdot x}}{\sum^m_{j=1}e^{\mu_j\cdot x}}\cdot\frac{1}{1+e^{-w_i\cdot x}}
$$
其中的超参数”分片数“m可以较好地平衡模型的拟合与推广能力。当m=1时，LS-PLM就退化为普通的逻辑回归。m越大，模型的拟合能力越强。与此同时，模型参数规模也随m的增大而线性增长，模型收敛所需的训练样本也随之增长。在实践中，阿里巴巴给出的m的经验值为12.

> **什么是softmax函数**？
>
> softmax函数，又称**归一化指数函数。**它是二分类函数sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。
>
> 它能将一个含任意实数的K维向量z“压缩”到另一个K维实向量σ(z)中，使得每一个元素的范围都在(0,1)之间，并且所有元素的和为1。该函数多于多分类问题中。

如下图所示，分别用红色和蓝色表示两类训练数据，传统LR模型的拟合能力不足，无法找到非线性的分类面，而MLR模型用4个分片可以完美地拟合出数据中的菱形分类面。

![推荐系统_MLR模型对训练数据的拟合](..\..\整理后的文件\推荐系统 配图\推荐系统_MLR模型对训练数据的拟合.jpg)

### 1.9.2 LS-PLM模型的优点

LS-PLM模型适用于工业级的推荐、广告等大规模稀疏数据的场景，主要是因为其具有以下两个优势。

1. 端到端的非线性学习能力：LS-PLM具有样本分片的能力，因此能够挖掘出数据中蕴藏的非线性模式，省去了大量的人工样本处理和特征工程的过程，使LS-PLM算法可以端到端地完成训练，便于用一个全局模型对不同应用领域、业务场景进行统一建模。
2. 模型的稀疏性强：LS-PLM在建模时引入了L1和L2，L1范数，可以使最终训练出来的模型具有较高的稀疏度，使模型的部署更加轻量级。模型服务过程仅需使用权重非零特征，因此稀疏模型也使其在线推断的效率更高。

## 2.8 总结——深度学习推荐系统的前夜

| 模型名称 | 基本原理                                                     | 特点                                                         | 局限性                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 协同过滤 | 根据用户的行为历史生成用户-物品共现矩阵，利用用户相似性和物品相似性进行推荐 | 原理简单、直接，应用广泛                                     | 泛化能力差，处理稀疏矩阵的能力差，推荐结果头部效应比较明显   |
| 矩阵分解 | 将协同过滤算法中的共现矩阵分解为用户矩阵和物品矩阵，利用用户隐向量和物品隐向量的内积进行排序并推荐 | 相较协同过滤，泛化能力有所增强，对稀疏矩阵的处理能力有所增强 | 除了用户历史行为数据，难以利用其他用户、物品特征及上下文特征 |
| 逻辑回归 | 将推荐问题转化成类似CTR预估的二分类问题，将用户、物品、上下文等不同特征转换成特征向量，输入逻辑回归模型得到CTR，再按照预估CTR进行排序并推荐 | 能够融合多种类型的不同特征                                   | 模型不具备特征组合能力，表达能力较差                         |
| FM       | 在逻辑回归的基础上，在模型中加入二阶特征交叉的部分，为每一维特征训练得到相应特征隐向量，通过隐向量间的内积运算得到交叉特征权重 | 相比逻辑回归，具备了二阶特征交叉能力，模型的表达能力增强     | 由于组合爆炸的问题的限制，模型不易扩展到三阶特征交叉阶段     |
| FFM      | 在FM模型的基础上，加入“特征域”的概念，使每个特征在与不同域的特征交叉时采用不同的隐向量 | 相比FM，进一步加强了特征交叉的能力                           | 模型的训练开销达到了$O(n^2)$的量级，训练开销较大             |
| GBDT+LR  | 利用GBDT进行“自动化”的特征组合，将原始特征向量转换成离散型特征向量，并输入逻辑回归模型，进行最终的CTR预估 | 特征工程模型化，使模型具备了更高阶特征组合的能力             | GBDT无法进行完全并行的训练，更新所需的训练时长较长           |
| LS-PLM   | 首先对样本进行“分片”，在每个“分片”内部构建逻辑回归模型，将每个样本的各个“分片”概率与逻辑回归的得分进行加权平均，得到最终的预估值 | 模型结构类似三层神经网络，具备了较强的表达能力               | 模型结构相比深度学习模型仍比较简单，有进一步提高的空间       |

# 第3章 浪潮之巅——深度学习在推荐系统中的应用

在进入深度学习时代后，推荐系统主要在以下两方面取得了重大进展。

1. 与传统的机器学习模型相比，深度学习模型的表达能力更强，能够挖掘出更多数据中潜藏的模式。
2. 深度学习的模型结构非常灵活，能够根据业务场景和数据特点，灵活调整模型结构，使模型与应用场景完美契合。

## 3.1 深度学习推荐模型的演化关系图

以多层感知机（Multi-Layer Perception, MLP) 为核心，通过改变神经网络的结构，构建特点各异的深度学习推荐模型，其主要的演变方向如下：

![推荐系统_主流深度学习推荐模型的演化图谱](..\..\整理后的文件\推荐系统 配图\推荐系统_主流深度学习推荐模型的演化图谱.png)

1. **改变神经网络的复杂程度**：从最简单的单层神经网络模型AutoRec（自编码器推荐），到经典的深度神经网络结构Deep Crossing（深度特征交叉），其主要的进化方式在于——增加了深度神经网络的层数和结构复杂度。
2. **改变特征交叉方式**：这类模型的主要改变在于丰富了深度学习中特征交叉的方式。例如，改变了用户向量和物品向量互操作方式的NeuralCF（Neural Collaborative Filtering，神经网络协同过滤），定义了多种特征向量交叉操作的PNN（Product-based Neural Network，基于积操作的神经网络）模型。
3. **组合模型**：这类模型主要是指Wide&Deep模型及其后续变种Deep&Cross、DeepFM等，其思路是通过组合两种不同特点、优势互补的深度学习网络，提升模型的综合能力。
4. **FM模型的深度学习演化版本**：传统推荐模型FM在深度学习时代有了诸多后续版本，其中包括NFM（Neural Factorization Machine，神经网络因子分解机）、FNN（Factorization-machine supported Neural Network，基于因子分解机支持的神经网络）、AFM（Attention neural Factorization Machine，注意力因子分解机）等，它们对FM的改进方向各不相同。例如，NFM主要使用神经网络提升FM二阶部分的特征交叉能力，AFM是引入了注意力机制的FM模型，FNN利用FM的结果进行网络初始化。
5. **注意力机制与推荐模型的结合**：这类模型主要是将“注意力机制”应用于深度学习推荐模型中，主要包括结合了FM与注意力机制的AFM和引入了注意力机制的CTR预估模型DIN（Deep Interest Network，深度兴趣网络）。
6. **序列模型与推荐模型的结合**：这类模型的特点是使用序列模型模拟用户行为或用户兴趣的演化趋势，代表模型是DIEN（Deep Interest Evolution Network，深度兴趣进化网络）。
7. **强化学习与推荐模型的结合**：这类模型将强化学习应用于推荐领域，强调模型的在线学习和实时更新，其代表模型是DRN（Deep Reinforcement Learning Network，深度强化学习网络）。

## 3.2 AutoRec——单隐层神经网络推荐模型

2015年由澳大利亚国立大学提出单隐层神经网络推荐模型AutoRec。它将自编码（AutoEncoder）的思想和协同过滤结合，提出了一种单隐层神经网络推荐模型。因其简洁的网络结构和清晰易懂的模型原理，AutoRec非常适合作为深度学习推荐模型的入门模型来学习。

### 3.2.1 AutoRec模型的基本原理

AutoRec模型是一个标准的自编码器，它的基本原理是利用协同过滤中的共现矩阵，完成物品向量或者用户向量的自编码。再利用自编码的结果得到用户对物品的预估评分，进而进行推荐排序。

> **什么是自编码器**？
>
> 顾名思义，自编码器是指能够完成数据“自编码”的模型。无论是图像、音频，还是文本数据，都可以转换成向量的形式进行表达。假设其数据向量为$\boldsymbol r$, 自编码器的作用是将向量$\boldsymbol r$作为输入，通过自编码器后，得到的输出向量尽量接近其本身。
>
> 假设自编码器的重建函数为$h(\boldsymbol r;\theta)$，那么自编码器的目标函数如下所示
> $$
> \min_\theta \sum_{\boldsymbol r\in S}||\boldsymbol r - h(\boldsymbol r;\theta)||^2_2\\
> 其中，S是所有数量向量的集合。
> $$
> 在完成自编码器的训练后，就相当于在重建函数$h(\boldsymbol r;\theta)$中存储了所有数据向量的“精华”。一般来说，重建函数的参数数量远小于输入向量的维度数量，因此自编码器相当于完成了数据压缩和降维的工作。
>
> 经过自编码器生成的输出向量，由于经过了自编码器的“泛化”过程，不会完全等同于输入向量，也因此具备了一定的缺失维度的预测能力，这也是自编码器能用于推荐系统的原因。

假设有m个用户，n个物品，用户会对n个物品中的一个或几个进行评分，未评分的物品分值可用默认值或平均分值表示，则所有m个用户对物品的评分可形成一个$m \times n$维的评分矩阵，也就是协同过滤中的共现矩阵。

对一个物品i来说，所有m个用户对它的评分可形成一个m维的向量$\boldsymbol r^{(i)}=(R_{1i},\cdots,R_{mi})^T$，如“什么是自编码器”中介绍的，AutoRec要解决的问题是构建一个重建函数$h(\boldsymbol r;\theta)$，使所有该重建函数生成的评分向量与原评分向量的平方残差和最小，如自编码器目标函数所示。

在得到AutoSec模型的重建函数后，还要经过评分预估和排序的过程才能得到最终的推荐列表。下面介绍AutoRec模型的两个重点内容——重建函数的模型结构和利用重建函数得到最终推荐列表的过程。

### 3.2.2 AutoRec模型的结构

AutoRec使用单隐层神经网络的结构来解决构建重建函数的问题。从模型的结构图中可以看出，网络的输入层是物品的评分向量$\boldsymbol r$，输出层是一个多分类层。图中蓝色的神经元代表模型的k维单隐层，其中k<<m。

![推荐系统_AutoRec模型的结构图](..\..\整理后的文件\推荐系统 配图\推荐系统_AutoRec模型的结构图.png)

图中的$\boldsymbol V$和$\boldsymbol W$分别代表输入层到隐层，以及隐层到输出层的参数矩阵。该模型结构代表的重建函数的具体形式如下所示：
$$
h(\boldsymbol r;\theta)=f(\boldsymbol W \cdot g(\boldsymbol V \boldsymbol r +\mu)+b)\\
其中，f(\cdot),g(\cdot)分别为输出层神经元和隐层神经元的激活函数。
$$
为防止重构函数的过拟合，在加入L2正则化项后，AutoRec目标函数的具体形式如下：
$$
\min_\theta \sum_{i=1}^n||\boldsymbol r^{(i)} - h(\boldsymbol r^{(i)};\theta)||^2_0 + \frac{\lambda}{2}\cdot(||\boldsymbol W||^2_F+||V||^2_F)
$$
由于AutoRec模型是一个非常标准的三层神经网络，模型的训练应用梯度反向传播即可完成。

> **什么是神经元、神经网络和梯度反向传播**？
>
> 神经元（Neuron），又名感知机（Perception），在模型结构上与逻辑回归一致，这里以一个二维输入向量的例子对其进行进一步的解释。假设模型的输入向量是一个二维特征向量$(\boldsymbol x_1, x_2)$, 则单神经元的模型结构如下所示
>
> ~~~
> 输入	 |								   |  输出
> x_1 --|--> [x] ---\						|
>       |            |---> [+] ---> [ ] --|--> y
> x_2 --|--> [x] ---/						|
> 	  |									|
> ~~~
>
> 其中，输入输出中间的部分可以看作线性的加权求和，再加上一个常数偏置b的操作，最终得到输入如下。
> $$
> (x_1\cdot w_1)+(x_2\cdot w_2)+b
> $$
> 图中的输入输出中间的部分可以看作激活函数，它的主要作用是把一个无界输入映射到一个规范的、有界的值域上。常用的激活函数除了“1.4 逻辑回归”介绍的sigmoid函数，还包括tanh、ReLU等。单神经元由于受到简单结构的限制，拟合能力不强，因此在解决复杂问题时，经常会用多神经元组成一个网络，使之具备拟合任意复杂函数的能力，这就是我们常说的**神经网络**。下图展示了一个由输入层，两神经元隐层和单神经元输出层组成的简单神经网络 。
>
> ~~~mermaid
> graph LR
>     subgraph 输出层
>     o1((o1))
>     style o1 fill:#0BF
>     end
>     subgraph 隐层
>     h1((h1))-->o1
>     h2((h2))-->o1
>     style h1 fill:#0BF
>     style h2 fill:#0BF
>     end
>     subgraph 输入层
>     x1((x1))-->h1
>     x1-->h2
>     x2((x2))-->h1
>     x2-->h2
>     end
> ~~~
>
> 其中，隐层和输出层的神经元构造和上面所述的感知机的构造相同，h1和h2神经元的输入是由x1和x2组成的特征向量，而神经元o1的输入则是由h1和h2输出组成的输入向量。本例是最简单的神经网络，在深度学习的发展历程中，正是研究人员对神经元不同连接方式的探索，才衍生出各种不同特性的深度学习网络，让深度学习模型的家族树枝繁叶茂。
>
> 在清楚了神经网络的模型结构之后，重要的问题就是如何训练一个神经网络。这里需要用到神经网络的重要训练方法——**前向传播**（Forward Propagation）和**反向传播**。前向传播的目的是在当前网络参数的基础上得到模型对输入的预估值，也就是说常见的模型推断过程。在得到预估值之后，就可以利用损失函数（Loss Function）的定义计算模型的损失。对输出层神经元来说（图中的o1），可以直接利用梯度下降法计算神经元相关权重（即下图中的权重w5和w6）的梯度，从而进行权重更新，但对隐层神经元的相关参数（比如w1）,应该如何利用输出层的损失进行梯度下降呢？
>
> ~~~mermaid
> graph LR
>     subgraph 输出层
>     o1((o1))
>     style o1 fill:#0BF
>     end
>     subgraph 隐层
>     h1((h1))--w5-->o1
>     h2((h2))--w6-->o1
>     style h1 fill:#0BF
>     style h2 fill:#0BF
>     end
>     subgraph 输入层
>     体重--w1-->h1
>     体重--w3-->h2
>     身高--w2-->h1
>     身高--w4-->h2
>     end
> ~~~
>
> 利用求导过程中的链式法则（Chain Rule），可以解决梯度反向传播的问题。如下式所示，最终的损失函数到权重w1的梯度是由损失函数到神经元h1输出的偏导，以及神经元h1输出到权重w1的偏导相乘而来的。也就是说，最终的梯度逐层传导回来，“指导”权重w1的更新。
> $$
> \frac{\partial L_{o_1}}{\partial w_1}=\frac{\partial L_{o_1}}{\partial h_1}\cdot\frac{\partial L_{h_1}}{\partial w_1}
> $$
> 在具体的计算中，需要明确最终损失函数的形式，以及每层神经元激活函数的形式，再根据具体的函数形式进行偏导的计算。
>
> 总的来说，神经元是神经网络中的基础结构，其具体实现、数学形式和训练方式与逻辑回归模型一致。神经网络是通过将多个神经元以某种方式连接起来形成网络，神经网络的训练方法就是基于链式法则的梯度反向传播。

### 3.2.3 基于AutoRec模型的推荐过程

基于AutoRec模型的推荐过程并不复杂。当输入物品i的评分向量为$\boldsymbol r^{(i)}$时，模型的输出向量$h(\boldsymbol r^{(i)};\theta)$就是所有用户对物品i的评分预测。那么，其中的第u维就是用户u对物品i的预测$\hat R_{ui}$，如下式所示
$$
\hat R_{ui} = (h(\boldsymbol r^{(i)};\hat\theta))_u
$$
通过遍历输入物品向量就可以得到用户u对所有物品的评分预测，进而根据评分预测排序得到推荐列表。

与协同过滤算法一样，AutoRec也分为基于物品的AutoRec和基于用户的AutoRec。以上介绍的AutoRec输入向量是物品的评分向量，因此可称为I-AutoRec(Item based AutoRec)，如果换做把用户的评分向量作为输入向量，则得到U-AutoRec(User based AutoRec)。在进行推荐列表生成过程中，U-AutoRec相比I-AutoRec的优势在于仅需输入一次目标用户的用户向量，就可以重建用户对所有物品的评分向量。也就是说，得到用户的推荐列表仅需一次模型推断过程；其劣势是用户向量的稀疏性可能会影响模型效果。

### 3.2.4 AutoRec模型的特点和局限性

AutoRec模型从神经网络的角度出发，使用一个单隐层的AutoEncoder泛化用户或物品评分，使模型具有一定的泛化和表达能力。由于AutoRec模型的结构比较简单，使其存在一定的表达能力不足的问题。

在模型结构上，AutoRec模型和后来的词向量模型（Word2vec）完全一致，但优化目标和训练方法有所不同。

从深度学习的角度来说，AutoRec模型的提出，拉开了使用深度学习的思想解决推荐问题的序幕，为复杂深度学习网络的构建提供了思路。

## 3.3 Deep Crossing模型——经典的深度学习架构

如果说AutoRec模型是将深度学习的思想应用于推荐系统的初步尝试，那么微软于2016年提出的Deep Crossing模型就是一次深度学习架构在推荐系统中的完整应用。虽然自2014年以来，就陆续有公司透露在其推荐系统中应用了深度学习模型，但直到Deep Crossing模型发布的当年，才有正式的论文分享了完整的深度学习推荐系统的技术细节。相比AutoRec模型过于简单的网络结构带来的一些表达能力不强的问题，Deep Crossing模型完整地解决了从特征工程、稀疏向量稠密化、多层神经网络进行优化目标拟合等一系列深度学习在推荐系统中的应用问题，为后续的研究打下了良好的基础。

### 3.3.1 Deep Crossing模型的应用场景

Deep Crossing模型的应用场景是微软搜索引擎Bing中的搜索广告推荐场景。用户在搜索引擎中输入搜索词之后，搜索引擎除了会返回相关结果，还会返回与搜索词相关的广告，这也是大多数搜索引擎的主要赢利模式。尽可能地增加搜索广告地点击率，准确地预测广告点击率，并以此作为广告排序的指标之一，是非常重要的工作，也是Deep Crossing模型的优化目标。

针对该使用场景，微软使用的特征如下表所示，这些特征可以分为三类：

- 一类是可以被处理成one-hot或者multi-hot向量的类别型特征，包括用户搜索词（query）、广告关键词（keyword）、广告标题（title）、落地页（landing page）、匹配类型（match type）;
- 一类是数值型特征，微软称其为计数型（counting）特征，包括点击率、预估点击率（click prediction）；
- 一类是需要进一步处理的特征，包括广告计划（campaign）、曝光样例（impression）、点击样例（click）等。

严格地说，这些都不是独立的特征，而是一个特征的组别，需要进一步处理。例如，可以将广告计划中的预算（budget）作为数值型特征，而广告计划的id则可以作为类别型特征。

| 特征       | 特征含义                                                     |
| ---------- | ------------------------------------------------------------ |
| 搜索词     | 用户在搜索框中输入的搜索词                                   |
| 广告关键词 | 广告主为广告添加的描述其产品的关键词                         |
| 广告标题   | 广告标题                                                     |
| 落地页     | 点击广告后的落地页面                                         |
| 匹配类型   | 广告主选择的广告——搜索词匹配类型（包括精准匹配、短语匹配、语义匹配等） |
| 点击率     | 广告的历史点击率                                             |
| 预估点击率 | 另一个CTR模型的CTR预估值                                     |
| 广告计划   | 广告主创建的广告投放计划，包括预算、定向条件等               |
| 曝光样例   | 一个广告“曝光”的例子，该例子记录了广告在实际曝光场景中的相关信息 |
| 点击样例   | 一个广告“点击”的例子，该例子记录了广告在实际点击场景中的相关信息 |

类别型特征可以通过one-hot或multi-hot编码生成特征向量，数值型特征则可以直接拼接进特征向量中，在生成所有输入特征的向量表达后，Deep Crossing模型利用该特征向量进行CTR预估。深度学习网络的特点是可以根据需求灵活地对网络结构进行调整，从而达成从原始特征向量到最终的优化目标的端到端的训练目的。下面通过剖析Deep Crossing模型的网络结构，探索深度学习是如何通过对特征的层层处理，最终准确地预估点击率的。

### 3.3.2 Deep Crossing模型的网络结构

为完成端到端的训练，Deep Crossing模型要在其内部网络中解决如下问题。

1. 离散类特征编码后过于稀疏，不利于直接输入神经网络进行训练，如何解决稀疏特征向量稠密化的问题。
2. 如何解决特征自动交叉组合的问题。
3. 如何在输出层中达成问题设定的优化目标

Deep Crossing模型分别设置了不同的神经网络层来解决上述问题。如下图所示，其网络结构主要包括4层——Embedding层、Stacking层、Multiple Residual Units层和Scoring层。接下来，从下至上依次介绍各层的功能和实现。

~~~mermaid
graph TB
	target((优化目标))
	target-->score[Scoring层]
	score-->mru[Multiple Residual Units层]
	mru-->stack[Stacking层]
	stack-->embed1[Embedding #1]
	embed1-->feature1[Feature #1]
	stack--->feature2[Feature #2]
	stack-->embedn[Embedding #n]
	embedn-->featuren[Feature #n]
~~~

**Embedding层**：Embedding层的作用是将稀疏的类别型特征转换成稠密的Embedding向量。从上图可以看到，每一个特征（如Feature#1，这里指的是经one-hot编码后的稀疏特征向量）经过Embedding层后，会转换成对应的Embedding向量（如Embedding#1）。

Embedding层的结构以经典的全连接层（Fully Connected Layer）结构为主，但Embedding技术本身作为深度学习中研究非常广泛的话题，已经衍生出了Word2vec、Graph Embedding等多种不同的Embedding方法，第4章将对Embedding的主流方法做更详尽的介绍。

一般来说，Embedding向量的维度应远小于原始的稀疏特征向量，几十到上百维一般就能满足需求。这里补充一点，上图中的Feature#2实际上代表了数值型特征，可以看到，数值型特征不需要经过Embedding层，直接进入了Stacking层。

**Stacking层**：Stacking层（堆叠层）的作用比较简单，是把不同的Embedding特征和数值型特征拼接在一起，形成新的包含全部特征的特征向量，该层通常也被称为连接（concatenate）层。

**Multiple Residual Units层**：该层的主要结构是多层感知机，相比标准的以感知机为基本单元的神经网络，Deep Crossing模型采用了多层残差网络（Multi-Layer Residual Network）作为MLP的具体实现。在推荐模型中的应用，也是残差网络首次在图像识别领域之外的成功推广。

通过多层残差网络对特征向量各个维度进行充分的交叉组合，使模型能够抓取到更多的非线性特征和组合特征的信息，进而使深度学习模型在表达能力上较传统机器学习模型大为增强。

> **什么是残差神经网络，其特点是什么？**
>
> 残差神经网络就是由残差单元（Residual Unit）组成的神经网络。残差单元的具体结构如下所示。
>
> ~~~
>       ┌---------------------------------┐
>       |									|
>       |	  ┌---------┐	  ┌---------┐	|
>  x^i  |	  |			| ReLU|			|	↓    x^o
> ------┴---| w_0,b_0 |-----| w_1,b_1 |--(+)-------->
> 		  |			|	  |			|		ReLU
> 		  └---------┘	  └---------┘
> ~~~
>
> 与传统的感知机不同，残差单元的特点主要有两个：
>
> 1. 残差单元中包含了一个以ReLU为激活函数的全连接层。
> 2. 输入通过一个短路（shortcut）通路直接与ReLU全连接层输出进行元素加（element-wise plus）操作。
>
> 在这样的结构下，残差单元其实拟合的是输出和输入之间的“残差”（$\boldsymbol x^o-\boldsymbol x^i$），这就是残差神经网络名称的由来。
>
> 残差神经网络的诞生主要是为了解决两个问题：
>
> 1. 神经网络是不是越深越好？对于传统的基于感知机的神经网络，当网络加深之后，往往存在过拟合现象，即网络越深，在测试集上的表现越差。而在残差神经网络中，由于有输入向量短路的存在，很多时候可以越过两层ReLU网络，减少过拟合现象的发生。
> 2. 当神经网络足够深时，往往存在严重的梯度消失现象。梯度消失现象是指在梯度反向传播过程中，越靠近输入端，梯度的幅度越小，参数收敛的速度越慢。为了解决这个问题，残差单元使用了ReLU激活函数取代原来的sigmoid激活函数。此外，输入向量短路相当于直接把梯度毫无变化地传递到下一层，这也使残差网络的收敛速度更快。

**Scoring层**：Scoring层作为输出层，就是为了拟合优化目标而存在的。对于CTR预估这类二分类问题，Scoring层往往使用的是逻辑回归模型，而对于图像分类等多分类问题，Scoring层往往采用softmax模型。

以上是Deep Crossing的模型结构，在此基础上采用梯度反向传播的方法进行训练，最终得到基于Deep Crossing的CTR预估模型。

### 3.3.3 Deep Crossing模型对特征交叉方法的革命

从目前的时间节点上看，Deep Crossing模型是平淡无奇的，因为它没有引入任何诸如注意力机制、序列模型等特殊的模型结构，只是采用了常规的"Embedding+多层神经网络"的经典深度学习结构。但从历史的尺度看，Deep Crossing模型的出现是有革命意义的。Deep Crossing模型中没有任何人工特征工程的参与，原始特征经Embedding后输入神经网络层，将全部特征交叉的任务交给模型。相比之前介绍的FM、FFM模型只具备二阶特征交叉的能力，Deep Crossing模型可以通过调整神经网络的深度进行特征之间的“深度交叉”，这也是Deep Crossing名称的由来。

## 3.4 NeuralCF模型——CF与深度学习的结合

新加坡国立大学的研究人员于2017年提出了基于深度学习的协同过滤模型NeuralCF。

### 3.4.1 从深度学习的视角重新审视矩阵分解模型

在2.2节对Deep Crossing模型的介绍中提到，Embedding层的主要作用是将稀疏矩阵转化成稠密向量。事实上，如果从深度学习的视角看待矩阵分解模型，那么矩阵分解层的用户隐向量和物品隐向量完全可以看作一种Embedding方法。最终的“Scoring层”就是将用户隐向量和物品隐向量进行内积操作后得到“相似度”，这里的“相似度”就是对评分的预测。综上，利用深度学习网络图的方式来描述矩阵分解模型的架构。

~~~mermaid
graph BT
	subgraph input[输入层-稀疏]
	u[用户向量-u]
	i[物品向量-i]
	end
	subgraph embedding层
	u--P_MK=p_uk-->用户隐向量
	i--Q_NK=q_ik-->物品隐向量
	style 用户隐向量 fill:#0AF
	style 物品隐向量 fill:#0A7
	end
	subgraph 内积
	用户隐向量-->cdot((内积))
	物品隐向量-->cdot
	end
	subgraph 输出层
	打分((打分\hat y_ui))
	目标((目标y_ui))
	style 打分 fill:#F77
	end
	cdot-->打分
	目标--训练-->打分
~~~

在实际使用矩阵分解来训练和评估模型的过程中，往往会发现模型容易处于欠拟合的状态，究其原因是因为矩阵分解的模型结构比较简单，特别是“输出层”（也被称为“Scoring层”），无法对优化目标进行有效的拟合。这就要求模型有更强的表达能力，在此动机的启发下，新加坡国立大学的研究人员提出了NeuralCF模型。

### 3.4.2 NeuralCF模型的结构

NeuralCF用“多层神经网络+输出层”的结构替代了矩阵分解模型中简单的内积操作。这样做的收益是直观的：

- 一是让用户向量和物品向量做更充分的交叉、得到更多有价值的特征组合信息；
- 二是引入更多的非线性特征，让模型的表达能力更强。

以此类推，事实上，用户和物品向量的互操作层可以被任意的互操作形式所代替，这就是所谓的“广义矩阵分解”模型（Generalized Matrix Factorization）。

原始的矩阵分解使用“内积”的方式让用户和物品向量进行交互，为了进一步让向量在各维度上进行充分交叉，可以通过“元素积”（element-wise product，长度相同的两个向量的对应维相乘得到另一向量）的方式进行互操作，再通过逻辑回归等输出层拟合最终预测目标。NeuralCF利用神经网络拟合互操作函数的做法是广义的互操作形式。在介绍PNN模型、Deep&Cross模型的章节中，还会介绍更多可行的互操作形式。

再进一步，可以把通过不同互操作网络得到的特征向量拼接起来，交由输出层进行目标拟合。NeuralCF的论文中给出了整合两个网络的例子，如下图。可以看出，NeuralCF混合模型整合了上面提出的原始NeuralCF模型和以元素积为互操作的广义矩阵分解模型。这让模型具有了更强的特征组合和非线性能力。

~~~mermaid
graph BT
	subgraph input
	u[用户向量-u]
	i[物品向量-i]
	end
	subgraph 向量
	u-->MF用户向量
	u-->MLP用户向量
	i-->MF物品向量
	i-->MLP物品向量
	style MF用户向量 fill:#0AF
	style MLP用户向量 fill:#0AF
	style MF物品向量 fill:#0A7
	style MLP物品向量 fill:#0A7
	end
	subgraph neural
	MF用户向量--元素乘连接-->GMF层
	MLP用户向量--连接-->MLP第一层
	MF物品向量--元素乘连接-->GMF层
	MLP物品向量--连接-->MLP第一层
	MLP第一层--ReLU-->MLP第二层
	MLP第二层--ReLU-->MLP第x层
	MLP第x层--连接-->NeuralCF层
	GMF层--连接-->NeuralCF层
	end
	subgraph 输出层
	打分((打分\hat y_ui))
	目标((目标y_ui))
	style 打分 fill:#F77
	end
	NeuralCF层-->打分
	目标--训练损失函数-->打分
~~~

> **什么是softmax函数**？
>
> 在对Deep Crossing和NeuralCF模型进行介绍的过程中，曾多次提及将softmax函数作为模型的最终输出层，解决多分类问题的目标拟合问题。
>
> softmax函数的数学形式定义：给定一个n维向量，softmax函数将其映射为一个概率分布。标准的softmax函数$\sigma:\mathbb{R}^n\rightarrow\mathbb{R}^n$ 由下面的公式定义：
> $$
> \sigma(\boldsymbol X)_i = \frac{exp(x_i)}{\sum^n_{j=1}exp(x_j)},当i=1,\cdots，n且\boldsymbol X = [x_1,\cdots,x_n]^T \in \mathbb{R}^n
> $$
> 可以看到，softmax函数解决了从一个原始的n维向量，向一个n维的概率分布映射的问题。那么在多分类问题中，假设分类数是n，模型希望预测的就是某样本在n个分类上的概率分布。如果用深度学习模型进行建模，那么最后输出层的形式是由n个神经元组成的，再把n个神经元的输出结果作为一个n维向量输入最终的softmax函数，在最后的输出中得到最终的多分类概率分布。在一个神经网络中，softmax输出层的结构如下所示：
>
> ~~~mermaid
> graph BT
> 	subgraph 输出层神经元
> 	1((1))
> 	2((2))
> 	n((n))
> 	end
> 	1-->vec[x1, x2, ..., xn]
> 	2-->vec
> 	n-->vec
> 	vec-->softmax((softmax函数))
> 	softmax-->vec2[p1, p2, ..., pn]
> ~~~
>
> 在分类问题中，softmax函数往往和交叉熵(cross-entropy)损失函数一起使用：
> $$
> Loss_{Cross Entropy}=-\sum_i y_i\ln(\sigma(\boldsymbol x)_i)\\
> 其中，y_i是第i个分类的真实标签值，\sigma(\boldsymbol x)_i 代表softmax函数对第i个分类的预测值。
> $$
> 因为softmax函数把分类输出标准化成了多个分类的概率分布，而交叉熵正好刻画了预测分类和真实结果之间的相似度，所以softmax函数往往与交叉熵搭配使用。在采用交叉熵作为损失作为损失函数时，整个输出层的梯度下降形式变得异常简单。
>
> softmax函数的导数形式为
> $$
> \frac{\partial\sigma(\boldsymbol x)_i}{\partial x_j}=
> 	\begin{cases}
> 		\sigma(\boldsymbol x)_i(1-\sigma(\boldsymbol x)_j), &i=j\\
> 		-\sigma(\boldsymbol x)_i\cdot\sigma(\boldsymbol x)_j,& i\neq j
> 	\end{cases}
> $$
> 基于链式法则，交叉熵函数到softmax函数第j维输入$x_j$的导数形式为
> $$
> \frac{\partial Loss}{\partial x_j}=\frac{\partial Loss}{\partial \sigma(\boldsymbol x)}\cdot\frac{\partial \sigma(\boldsymbol x)}{\partial x_j}
> $$
> 在多分类问题中，真实值中只有一个维度是1，其余维度都为0。假设第k维是1，即$y_k=1$，那么交叉熵损失函数可以简化成如下形式：
> $$
> Loss_{Cross Entropy}=-\sum_i y_i \ln(\sigma(\boldsymbol x)_i)=-y_k\cdot\ln(\sigma(\boldsymbol x)_k)=-\ln(\sigma(\boldsymbol x)_k)
> $$
> 则有
> $$
> \frac{\partial Loss}{\partial x_j}=\frac{\partial(-\ln(\sigma(\boldsymbol x)_k))}{\partial\sigma(\boldsymbol x)_k}\cdot\frac{\partial\sigma(\boldsymbol x)_k}{\partial x_j}\\
> =-\frac{1}{\sigma(\boldsymbol x)_k}\cdot\frac{\partial\sigma(\boldsymbol x)_k}{\partial x_j}\\
> =\begin{cases}
> 		\sigma(\boldsymbol x)_j-1, &j=k\\
> 		\sigma(\boldsymbol x)_j, &j\neq k
> 	\end{cases}
> $$
> 可以看出，softmax函数和交叉熵的配合，不仅在数学含义上完美统一，而且在梯度形式上也非常简介。基于上式的梯度形式，通过梯度反向传播的方法，即可完成整个神经网络权重的更新。

### 3.4.3 NeuralCF模型的优势和局限性

NeuralCF模型实际上提出了一个模型框架，它基于用户向量和物品向量这两个Embedding层，利用不同的互操作层进入特征的交叉组合，并且可以灵活地进行不同互操作层的拼接。从这里可以看出深度学习构建推荐模型的优势——利用神经网络理论上能够拟合任意函数的能力，灵活地组合不同的特征，按需增加或减少模型的复杂度。

在实践中要注意：并不是模型结构越复杂、特征越多越好。一是要防止过拟合的风险，二是往往需要更多的数据和更长的训练时间才能使复杂的模型收敛，这需要算法工程师在模型的实用性、实时性和效果之间进行权衡。

NeuralCF模型也存在局限性。由于是基于协同过滤的思想进行构造的，所以NeuralCF模型并没有引入更多其他类型的特征，这在实际应用中无疑浪费了其他有价值的信息。此外，对于模型中互操作的种类并没有做进一步的探究和说明。这都需要后来者进行更深入的探索。

## 3.5 PNN模型——加强特征交叉能力

NeuralCF模型的主要思想是利用多层神经网络替代经典协同过滤的点积操作，加强模型的表达能力。广义上，任何向量之间的交互计算方式都可以用来替代协同过滤的内积操作，相应的模型可称为广义的矩阵分解模型。但NeuralCF模型只提到了用户向量和物品向量两组特征向量，如果加入多组特征向量又该如何设计特征交互的方法呢？2016年，上海交通大学的研究人员提出的PNN模型，给出了特征交互方式的几种设计思路。

### 3.5.1 PNN模型的网络架构

PNN模型的提出同样是为了解决CTR预估和推荐系统的问题，因此不再赘诉模型的应用场景，直接进入模型架构的部分。下图所示为模型结构图，相比Deep Crossing模型，PNN模型在输入、Embedding层、多层神经网络，以及最终的输出层部分并没有结构上的不同，唯一的区别在于PNN模型用乘积层（Product Layer）代替了DeepCrossing模型中的Stacking层。也就是说，不同特征的Embedding向量不再是简单的拼接，而是用Product操作进行两两交互，更有针对性地获取特征之间的交叉信息。

![推荐系统_PNN模型结构图](..\..\整理后的文件\推荐系统 配图\推荐系统_PNN模型结构图.png)

另外，相比NeuralCF，PNN模型的输入不仅包括用户和物品信息，还可以有更多不同形式、不同来源的特征，通过Embedding层的编码生成同样长度的稠密特征Embedding向量。针对特征的交叉方式，PNN模型也给出了更多具体的互操作方法。

### 3.5.2 Product层的多种特征交叉方式

PNN模型对于深度学习结构的创新主要在于乘积层的引入。具体地说，PNN模型的乘积层由线性操作部分（上图中乘积层的z部分，对各特征向量进行线性拼接）和乘积操作部分（上图中乘积层的p部分）组成。其中，乘积特征交叉部分又分为内积操作和外积操作，使用内积操作的PNN模型被称为IPNN（Inner Product-based Neural Network），使用外积操作的PNN模型被称为OPNN（Outer Product-based Neural Network）。

无论是内积操作还是外积操作，都是对不同的特征Embedding向量进行两两组合。为保证乘积操作能够顺利进行，各Embedding向量的维度必须相同。

内积操作就是经典的向量内积运算，假设输入特征向量分别为$\boldsymbol f_i,\boldsymbol f_j$，特征的内积互操作$g_{inner}(\boldsymbol f_i,\boldsymbol f_j)$的定义如下所示：
$$
g_{inner}(\boldsymbol f_i,\boldsymbol f_j) =  \langle\boldsymbol f_i,\boldsymbol f_j\rangle
$$
外积操作是对输入特征向量$\boldsymbol f_i,\boldsymbol f_j$的各维度进行两两交叉，生成特征交叉矩阵，外积互操作$g_{inner}(\boldsymbol f_i,\boldsymbol f_j)$的定义如下所示
$$
g_{inner}(\boldsymbol f_i,\boldsymbol f_j) = \boldsymbol f_i\boldsymbol f_j^T
$$
外积互操作生成的是特征向量$\boldsymbol f_i,\boldsymbol f_j$各维度两两交叉而成的一个 $M\times M$ 的方形矩阵（其中M是输入向量的维度）。这样的外积操作无疑会直接将问题的复杂度从原来的M提升到$M^2$，为了在一定程度上减小模型训练的负担，PNN模型的论文中介绍了一种降维的方法，就是把所有两两特征Embedding向量外积互操作的结果叠加（superposition），形成了一个叠加外积互操作矩阵$\boldsymbol p$,具体定义如下：
$$
\boldsymbol p = \sum^N_{i=1}\sum^N_{j=1}g_{inner}(\boldsymbol f_i,\boldsymbol f_j) = \sum^N_{i=1}\sum^N_{j=1}\boldsymbol f_i\boldsymbol f_j^T = \boldsymbol f_\sum\boldsymbol f_\sum^T ,\\
其中 \boldsymbol f_\sum=\sum^N_{i=1}\boldsymbol f_i
$$
从式子的最终形式看，叠加矩阵$\boldsymbol p$ 的最终形式类似于让所有特征Embedding向量通过一个平均池化层（Average Pooling）后，再进行外积互操作。

在实际应用中，还应对平均池化的操作谨慎对待。因为把不同特征对应维度进行平均，实际上是假设不同特征的对应维度有类似的含义。但显然，如果一个特征是“年龄”，一个特征是“地域”，那么这两个特征在经过各自的Embedding层后，二者的Embedding向量不在一个向量空间中，显然不具备任何可比性。这时，把两者平均起来，会模糊很多有价值的信息。平均池化的操作经常发生在同类Embedding上，例如，将用户浏览过的多个物品的Embedding进行平均。因此，PNN模型的外积池化操作也需要谨慎，在训练效率和模型效果上进行权衡。

事实上，PNN模型在经过对特征的线性和乘积操作后，并没有把结果直接送入上层的$L_1$全连接层，而是在乘积层内部又进行了局部全连接层的转换，分别将线性部分z，乘积部分p映射成了$D_1$维的输入向量$\boldsymbol l_z$和$\boldsymbol l_p$($D_1$为$L_1$隐层的神经元数量)，再将$\boldsymbol l_z$和$\boldsymbol l_p$叠加，输入$L_1$隐层。这部分操作不具备创新性，并且可以被其他转换操作完全替代，因此不再详细介绍。

### 3.5.3 PNN模型的优势和局限性

PNN的结构特点在于强调了特征Embedding向量之间的交叉方式是多样化的，相比于简单的交由全连接层进行无差别化的处理，PNN模型定义的内积和外积操作显然更有针对性地强调了不同特征之间的交互，从而让模型更容易捕获特征的交叉信息。

但PNN模型同样存在着一些局限性，例如在外积操作的实际应用中，为了优化训练效率进行了大量的简化操作。此外，对所有特征进行无差别的交叉，在一定程度上忽略了原始特征向量中包含的有价值信息。如何综合原始特征及交叉特征，让特征交叉的方式更加高效，后续的Wide&Deep模型和基于FM的各类深度学习模型将给出它们的解决方案。

## 3.6 Wide&Deep模型——记忆能力和泛化能力

本节介绍的是自提出以来就在业界发挥着巨大影响力的模型——谷歌于2016年提出的Wide&Deep模型。Wide&Deep模型的主要思路正如其名，是由单层的Wide部分和多层的Deep部分组成的混合模型。其中，Wide部分的主要作用是让模型具有较强的“记忆能力”（memorization）；Deep部分的主要作用是让模型具有“泛化能力”（generalization），正是这样的结构特点，使模型兼具了逻辑回归和深度神经网络的优点——能够快速处理并记忆大量历史行为特征，并且具有强大的表达能力，不仅在当时迅速成为业界争相应用的主流模型，而且衍生出了大量以Wide&Deep模型为基础结构的混合模型，影响力一直延续至今。

### 3.6.1 模型的记忆能力与泛化能力

Wide&Deep模型的设计初衷和其最大的价值在于同时具备较强的“记忆能力”和“泛化能力”。“记忆能力”是一个新的概念，“泛化能力”虽在之前的章节中屡有提及，但从没有给出详细的解释，本节就对这两个概念进行详细的解释。

**“记忆能力”可以被理解为模型直接学习并利用历史数据中物品或者特征的“共现频率”的能力**。一般来说，协同过滤、逻辑回归等简单模型有较强的“记忆能力”。由于这类模型的结构简单，原始数据往往可以直接影响推荐结果，产生类似于“如果点击过A，就推荐B”这类规则式的推荐，这就相当于模型直接记住了历史数据的分布特点，并利用这些记忆进行推荐。

因为在Wide&Deep是由谷歌应用商店（Google Play）推荐团队提出的，所以这里以App推荐的场景为例，解释什么是模型的“记忆能力”。

假设在Google Play推荐模型的训练过程中，设置如下组合特征：AND(user_installed_app=netflix, impression_app=pandora)(简称netflix&pandora)，它代表用户已经安装了netflix这款应用，而且曾在应用商店中看到过pandora这款应用。如果以“最终是否安装pandora”为数据标签（label），则可以轻而易举地统计出netflix&pandora这个特征和安装pandora这个标签之间的共现频率。假设二者的共现频率高达10%（全局的平均安装率为1%），这个特征如此之强，以至于在设计模型时，希望模型一发现有这个特征，就推荐pandora这款应用（就像一个深刻的记忆点一样印在脑海里），这就是所谓的模型的“记忆能力”。像逻辑回归这类简单模型，如果发现这样的“强特征”，则其相应的权重就会在模型训练过程中被调整得非常大，这样就实现了对这个特征的直接记忆。相反，对于多层神经网络，特征会被多层处理，不断与其他特征进行交叉，因此模型对这个强特征的记忆反而没有简单模型深刻。

**“泛化能力”可以被理解为模型传递特征的相关性，以及发掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力。**矩阵分解比协同过滤的泛化能力强，因为矩阵分解引入了隐向量这样的结构，使得数据稀少的用户或者物品也能生成隐向量，从而获得有数据支撑的推荐得分，这就是非常典型的将全局数据传递到稀疏物品上，从而提高泛化能力的例子。再比如，深度神经网络通过特征的多次自动组合，可以深度发掘数据中潜在的模式，即使是非常稀疏的特征向量输入，也能得到较稳定平滑的推荐概率，这就是简单模型所缺乏的“泛化能力”。

### 3.6.2 Wide&Deep模型的结构



# 第4章 Embedding技术在推荐系统中的应用



# 第5章 多角度审视推荐系统

## 5.1 推荐系统的特征工程

"Garbage in garbage out(垃圾进，垃圾出)"是算法工程师经常提到的一句话。机器学习模型的能力边界在于对数据的拟合和泛化，那么数据及表达数据的特征本身就决定了机器学习模型效果的上限。因此，特征工程对推荐系统效果提升的作用是无法替代的。为了构建一个“好”的特征工程，需要依次解决三个问题：

1. 构建特征工程应该遵循的基本原则是什么？
2. 有哪些常用的特征类别？
3. 如何在原始特征的基础上进行特征处理，生成可供推荐系统训练和推断用的特征向量？

### 5.1.1 构建推荐系统特征工程的原则

在推荐系统中，**特征的本质其实是对某个行为过程相关信息的抽象表达**。推荐过程中某个行为必须转换成某种数学形式才能被机器学习模型所学习，因此为了完成这种转换，就必须将这些行为过程中的信息以特征的形式抽取出来，用多维度上的特征表达这一行为。

从具体的行为转化成抽象的特征，这一过程必然涉及信息的损失。

- 一是因为具体的推荐行为和场景中包含大量原始的场景、图片和状态信息，保存所有信息的存储空间过大，无法在现实中满足；
- 二是因为具体的推荐场景中包含大量冗余的、无用的信息，都考虑进来甚至会损害模型的泛化能力。

搞清楚这两点后，就可以顺利成章地提出构建**推荐系统特征工程的原则**：

尽可能地让特征工程抽取出的一组特征能够保留推荐环境及用户行为过程中的所有有用信息，尽量摒弃冗余信息。



举例来说，在一个电影推荐的场景下，应该如何抽取特征才能代表“用户点击某个电影”这一行为呢？

为了回答这个问题，我们可以想象自己选择点击某个电影过程受什么因素影响？

1. 自己对电影类型的兴趣偏好
2. 该电影是否是流行的大片。
3. 该影片中是否有自己喜好的演员和导演。
4. 电影的海报是否有吸引力。
5. 自己是否看过该影片。
6. 自己当时的心情。

秉着“**保留行为过程中的所有有用信息**”的原则，从电影推荐场景中抽取特征时，应该让特征能够尽量保留上述6个要素的信息。因此，要素、有用信息和数据抽取出的特征的对应关系如下表所示

| 要素                               | 有用信息和数据           | 特征                                            |
| ---------------------------------- | ------------------------ | ----------------------------------------------- |
| 自己对电影类型的兴趣偏好           | 历史观看影片序列         | 影片id序列特征，或进一步抽取出兴趣Embedding特征 |
| 该电影是否是流行的大片             | 影片的流行分数           | 流行度特征                                      |
| 该影片中是否有自己喜好的演员和导演 | 影片的元数据，即相关信息 | 元数据标签类特征                                |
| 电影的海报是否有吸引力             | 影片海报的图像           | 图像内容类特征                                  |
| 自己是否看过该影片                 | 用户观看历史             | 是否观看的布尔型特征                            |
| 自己当时的心情                     | 无法抽取                 | 无                                              |

值得注意的是，在抽取特征的过程中，必然存在着信息的损失，例如，“自己当时的心情”这个要素被无奈地舍弃了。再比如，用用户观看历史推断用户的“兴趣偏好”也一定会存在信息丢失的情况。因此，在已有的、可获得的数据基础上，“尽量”保留有用信息是一个现实的工程上的原则。

### 5.1.2 推荐系统中的常用特征

在推荐系统特征工程原则的基础上，本节列出在推荐系统中常用的特征类别，供读者在构建自己的特征工程时参考。

#### 1. 用户行为数据

用户行为数据是推荐系统最常用，也是最关键的数据。

