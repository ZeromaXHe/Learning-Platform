# 第1章 导论

## 1.3 全面的性能调优

本书关注于如何以最佳方式利用JVM和Java平台API，让程序运行得更快。但除了这两点，还有许多外在的因素影响性能。书中这些因素时不时会出现，但因为它们不只影响Java，所以不会深入讨论。JVM和Java平台的性能只是高性能主题中的一小部分。

本书会覆盖一些外部因素，这些因素的重要性不亚于Java的性能调优。本书中基于Java的调优方法可以和这些因素相互补充，但这些因素多数已经超过了本书讨论的范围。

### 1.3.1 编写更好的算法

### 1.3.2 编写更少的代码

### 1.3.3 老调重弹的过早优化

“过早优化”一词公认是由高德纳发明的，开发人员常常据此宣称：只有在运行时才能知道代码的性能有多要紧。但你可能从来没注意到，完整的原话是“我们不应该把大量时间都耗费在那些小的性能改进上；过早考虑优化是所有噩梦的根源”。

这句名言的重点是，最终你应该编写清晰、直接、易读和易理解的代码。这里的“优化”应该理解为虽然算法和设计改变了复杂程序的结构，但是提供了更好的性能。那些真正的优化最好留到以后，等到性能分析表明这些措施有巨大收益的时候才进行。

而这里所指的过早优化，并不包括避免那些已经知道对性能不好的代码结构。每行代码，如果有两种简单、直接的编程方式，那就应该选择性能更好的那种。

### 1.3.4 其他：数据库很可能就是瓶颈

本书并不关注整体系统的性能。对于整体系统，我们需要采取结构化方法针对系统的所有方法分析性能。CPU使用率、I/O延迟、系统整体的吞吐量都必须测量和分析。只有到那时，我们才能判定到底是哪个组件导致了性能瓶颈。

另一方面，不要忽视初步分析。如果数据库是瓶颈（提示：的确是的话），那么无论怎么优化访问数据库的Java应用，都无助于整体性能；实际上可能适得其反。作为一般性原则，系统负载增加越大，系统性能就会越糟糕。如果更改了Java应用使得它更有效，这只会增加已经过载的数据库的负载，整体性能实际反而会下降。导致的风险是，可能会得出错误结论，即认为不应该改进JVM。

增加系统某个组件的负载从而导致整个系统性能变慢，这项原则不仅限于数据库。CPU密集型的应用服务器增加负载，或者越来越多线程试图获取已经有线程等待的锁，还有许多其他场景，也都适用这项原则。第9章展示了一个仅涉及JVM的极端例子。

### 1.3.5 常见的优化

# 第2章 性能测试方法

## 2.1 原则1：测试真实应用

第1条原则就是，应该在产品实际使用的环境进行性能测试。性能测试大体上可以分为3种，每种都有其优点和不足，只有适用于实际应用的才能取得最好的效果。

### 2.1.1 微基准测试

第1种是微基准测试。微基准测试用来测量微小代码单元的性能，包括调用同步方法的用时与非同步方法的用时比较，创建线程的代价与使用线程池的代价，执行某种算法的耗时与其替代实现的耗时，等等。

微基准测试看起来很好，但要写对却很困难。考虑以下代码，被测的方法是计算出第50个斐波那契数，这段代码试图用微基准测试来测试不同实现的性能：

~~~java
public void doTest() {
    // 主循环
    double l;
    long then = System.currentTimeMillis();
    for (int i = 0; i < nLoops; i++) {
        l = fibImpl1(50);
    }
    long now = System.currentTimeMillis();
    System.out.println("Elapsed time: " + (now - then));
}
...
private double fibImpl1(int n) {
    if(n < 0) throw new IllegalArgumentException("Must be > 0");
    if(n == 0) return 0d;
    if(n == 1) return 1d;
    double d = fibImpl1(n - 2) + fibImpl(n - 1);
    if(Double.isInfinite(d)) throw new ArithmeticException("Overflow");
    return d;
}
~~~

代码看起来简单，却存在很多问题。

#### 1. 必须使用被测的结果

这段代码的最大问题是，实际上它永远都不会改变程序的任何状态。因为斐波那契的计算结果从来没有被使用，所以编译器可以很放心地去除计算结果。智能的编译器（包括当前的Java 7和Java 8）最终执行的是以下代码：

~~~java
long then = System.currentTimeMillis();
long now = System.currentTimeMillis();
System.out.println("Elapsed time: " + (now - then));
~~~

结果是，无论计算斐波那契的方法如何实现，循环执行了多少次，实际的流逝时间其实只有几毫秒。循环如何被消除的细节请参见第4章。

有个方法可以解决这个问题，即确保读取被测结果，而不只是简单地写。实际上，将局部变量l地定义改为实例变量（并用关键字volatile声明）就能测试这个方法的性能了。（实例变量l必须声明为volatile的原因请参见第9章。）

> **多线程微基准测试**
>
> 即便本示例是单线程微基准测试，也必需使用volatile变量。
>
> 编写多线程微基准测试时务必深思熟虑。当若干个线程同时执行小段代码时，极有可能会产生同步瓶颈（以及其他线程问题）。所以，如果我们过多依赖多线程基准测试的结果，就常常会将大量时间花费在优化那些真实场景中很少出现的同步瓶颈上，而不是性能需求更迫切的地方。
>
> 考虑这样的微基准测试，即有两个线程同时调用同步方法。由于基准测试的代码量相对于被测方法来说比较少，所以多数时间都是在执行同步方法。假设执行同步方法的时间只占整个微基准测试的50%，即便少到只有两个线程，同时执行同步代码的概率仍然很高。因此基准测试运行得很慢，并且随着线程数的增加，竞争所导致的性能问题将愈演愈烈。最终结果就是，测试衡量的是JVM如何处理竞争，而不是微基准测试的本来目的。

#### 2. 不要包括无关的操作

即使使用了被测结果，依然还有隐患。上述代码只有一个操作：计算第50个斐波那契数。可想而知，其中有些迭代操作是多余的。如果编译器足够智能的话，就能发现这个问题，从而只执行一遍循环——至少可以少几次迭代，因为那些迭代是多余的。

另外，fibImpl(1000) 的性能可能与fibImpl(1)相差很大。如果目的是为了比较不同实现的性能，测试的输入就应该考虑用一系列数据。

也就是说，解决这个问题，需要给fibImpl传入不同的参数。可以使用随机值，但仍然必须小心。

下面是种简单方法，即在循环中使用随机数生成器：

~~~java
for(int i = 0; i < nLoops; i++) {
    l = fibImpl1(random.nextInteger());
}
~~~

可以看到，循环中包括了计算随机数，所以测试的总时间是计算斐波那契数列的时间，加上生成一组随机数的时间。这可不是我们的目的。

微基准测试中的输入值必须事先计算好，比如：

~~~java
int[] input = new int[nLoops];
for(int i = 0; i < nLoops; i++){
    input[i] = random.nextInt();
}
long then = System.currentTimeMillis();
for(int i = 0; i < nLoopsl; i++){
    try {
        l = fibImpl1(input[i]);
    } catch (IllegalArgumentException iae){
        
    }
}
long now = System.currentTimeMillis();
~~~

#### 3. 必须输入合理的参数

此处还有第3个隐患，就是测试的输入值范围：任意选择的随机输入值对于这段被测代码的用法来说并不具有代表性。

> **热身期**
>
> Java的一个特点就是代码执行的越多性能越好，第4章将会覆盖这个主题。基于这点，微基准测试应该包括热身期，使得编译器能生成优化的代码。
>
> 本章后续将深入讨论热身期的优缺点。微基准测试需要热身期，否则测量的是编译而不是被测代码的性能了。

综合所有因素，正确的微基准测试代码看起来应该是这样：

~~~java
package net.sdo;

import java.util.Random;

public class FibonacciTest {
    private volatile double l;
    private int nLoops;
    private int[] input;
    
    public static void main(String[] args) {
        FibonacciTest ft = new FibonacciTest(Integer.parseInt(args[0]));
        ft.doTest(true);
        ft.doTest(false);
    }
    
    private FibonacciTest(int n){
        nLoops = n;
        input = new Random();
        Random r = new Random();
        for(int i = 0; i < nLoops; i++){
            input[i] = r.nextInt(100);
        }
    }
    
    private void doTest(boolean isWarmup) {
        long then = System.currentTimeMillis();
        for(int i = 0; i < nLoops; i++){
            l = fibImpl1(input[i]);
        }
        if(!isWarmup){
            long now = System.currentTimeMillis();
            System.out.println("Elapsed time:" + (now - then));
        }
    }
    
    private double fibImpl1(int n) {
        if(n < 0) throw new IllegalArgumentException("Must be > 0");
        if(n == 0) return 0d;
        if(n == 1) return 1d;
        double d = fibImpl1(n - 2) + fibImpl(n - 1);
        if(Double.isInfinite(d)) throw new ArithmeticException("Overflow");
        return d;
    }
}
~~~

甚至这个微基准测试的测量结果中仍然有一些与计算斐波那契数没有太大关系：调用fibImpl1()的循环和方法开销，将每个结果都写到volatile变量中也会有额外的开销。

此外还需要留意编译效应。编译器编译方法时，会依据代码的性能分析反馈来决定所使用的最佳优化策略。性能分析反馈基于以下因素：频繁调用的方法、调用时的栈深度、方法参数的实际类型（包括子类）等，它还依赖于代码实际运行的环境。编译器对于相同代码的优化在微基准测试中和实际应用中经常有所不同。如果用相同的测试测量斐波那契方法的其他实现，就能看到各种编译效应，特别是当这个实现与当前的实现处在不同的类中时。

最终，还有探讨微基准测试实际意味着什么。比如这里讨论的基准测试，它有大量的循环，整体时间以秒计，但每轮循环迭代通常是纳秒级。没错，纳秒累计起来，“积少成多”就会成为频繁出现的性能问题。特别是在做回归测试的时候，追踪级别设为纳秒很有意义。

微基准测试难于编写，真正管用的又很有限。所以，应该了解这些相关的隐患后再做出决定，是微基准测试合情合理值得做，还是关注宏观的测试更好。

### 2.1.2 宏基准测试

假设业务处理的算法有所改进，处理量达到了200 RPS，系统能承受的负载也相应增加。LDAP系统可以处理这些增加的负载：目前为止一切都好，数据将以200 RPS的速率注入业务处理模块，而它也将以200 RPS的速率输出。

但数据库只能以100 RPS的速率装载数据。虽然向数据库发送请求的速率为200 RPS，输出到其他模块的速率却只有100 RPS。即便业务逻辑处理的效率加倍，系统整体的吞吐量仍然只能达到100 RPS。所以，除非花时间改善环境其他方面的效率，否则业务逻辑做再多改进也是无效的。

> **多JVM时的全系统测试**
>
> 全应用测试有个很重要的场景，就是同一台机器上同时运行多个应用。许多JVM的默认调优都是默认假定整个机器的资源都归JVM使用。如果单独测试，优化效果很好。如果在其他应用（包括但不限于Java程序）运行的时候进行测试，性能会有很大的不同。

本例子中，优化业务处理并不完全是浪费时间：在系统其他性能瓶颈上曾经付出的努力，终究会有好处。进一步说，这中间有个优先顺序：不进行整体应用的测试，就不可能知道哪部分的优化会产生回报。

### 2.1.3 介基准测试

我的调优工作包括Java SE和EE，每种都会有一组类似微基准测试的测试。对于Java SE工程师来说，这个术语意思是样本甚至比2.1.1节的还要小：测量很小的东西。Java EE工程师则将这个术语用于其他地方：测量某方面性能的基准测试，但仍然要执行大量代码。

介基准测试并不局限于Java EE：它是一个术语，我用来表示做一些实际工作，但不是完整应用的基准测试。

### 2.1.4 代码示例

贯穿全书的许多例子都来自于一个示例应用，计算某只股票在一段时间内的“历史”最高价和最低价，以及标准差。因为所有数据皆为虚构，价格和股票代码也是随机生成，所以这里的历史标上了引号。

基本接口StockPrice表示某股票某天的价格区间：

~~~java
public interface StockPrice {
    String getSymbol();
    Date getDate();
    BigDecimal getClosingPrice();
    BigDecimal getHigh();
    BigDecimal getLow();
    BigDecimal getOpeningPrice();
    boolean isYearHigh();
    boolean isYearLow();
    Collection<? extends StockOptionPrice> getOptions();
}
~~~

通常，那些示例应用都是对一组股价进行处理，这些股价表示一段时间内的股票历史（比如1年或25年，取决于具体的示例）：

~~~java
public interface StockPriceHistory {
    StockPrice getPrice(Date d);
    Collection<StockPrice> getPrices(Date startDate, Date endDate);
    Map<Date, StockPrice> getAllEntries();
    Map<BigDecimal, ArrayList<Date>> getHistogram();
    BigDecimal getAveragePrice();
    Date getFirstDate();
    BigDecimal getHighPrice();
    Date getLastDate();
    BigDecimal getLowPrice();
    BigDecimal getStdDev();
    String getSymbol();
}
~~~

这个接口的基本实现是从数据库载入股价：

~~~java
public class StockPriceHistoryImpl implements StockPriceHistory {
    ...
    public stockPriceHistoryImpl (String s, Date startDate, Date endDate, EntityManager em) {
        Date curDate = new Date(startDate.getTime());
        symbol = s;
        while(!curDate.after(endDate)){
            stockPriceImpl sp = em.find(StockPriceImpl.class, new StockPricePK(s, (Date) curDate.clone()));
            if(sp != null) {
                Date d = (Date) curDate.clone();
                if(firstDate == null){
                    firstDate = d;
                }
                prices.put(d, sp);
                lastDate = d;
            }
            curDate.setTime(curDate.getTime() + msPerDay);
        }
    }
}
~~~

计算标准差需要知晓BigDecimal数的平方根。标准Java API不支持这个函数，示例将采用以下方法。

~~~java
public static BigDecimal sqrtB(BigDecimal bd) {
    BigDecimal initial = bd;
    BigDecimal diff;
    do {
        BigDecimal sDivX = bd.divide(initial, 8, RoundingMode.FLOOR);
        BigDecimal sum = sDivX.add(initial);
        BigDecimal div = sum.divide(TWO, 8, RoundingMode.FLOOR);
        diff =  div.substract(initial).abs();
        diff.setScale(8, RoundingMode.FLOOR);
        initial = div;
    } while(diff.compareTo(error) > 0);
    return initial;
}
~~~

这是巴比伦平方根计算法的实现。它不是最有效的实现，特别是初始值可以估算得更好，可以少几轮迭代。这是经过深思熟虑的，因为计算需要花费一些时间（模拟业务逻辑）

## 2.2 原则2：理解批处理流逝时间、吞吐量和响应时间

### 2.2.1 批处理流逝时间

虚拟机会花几分钟（或更长时间）全面优化代码并以最高性能执行。由于这个（以及其他）原因，研究Java的性能优化就要密切注意代码优化的热身期：大多数时候，应该在运行代码执行足够长时间，已经编译并优化之后再测量性能。

> **其他影响应用热身的因素**
>
> 通常认为的应用热身，指的就是等待编译器优化运行代码，不过基于代码的运行时长还有其他一些影响性能的因素。
>
> 例如，JPA通常都会缓存从数据库读取的数据。与此类似，应用程序读文件时，操作系统就会将文件载入内存。

### 2.2.2 吞吐量测试

吞吐量测试是基于一段时间内所能完成的工作量。

客户端常常有多个线程在处理，所以吞吐量就是所有客户端所完成的操作总量。通常这个数字就是每秒完成的操作量，而不是测量期间的总操作量。这个指标常常被称作每秒事务数（TPS）、每秒请求数（RPS）或每秒操作次数（OPS）。

### 2.2.3 响应时间测试

最后一个常用的测试指标是响应时间：从客户端发送请求至收到响应之间的流逝时间。

响应时间测试和吞吐量测试（假设后者是基于客户端-服务端模式）之间的差别是，响应时间测试中的客户端线程会在操作之间休眠一段时间。这被称为思考时间。

> **思考时间和吞吐量**
>
> 有两种方法
>
> 另外一种方法是周期时间（Cycle Time）

衡量响应时间有两种方法。响应时间可以报告为平均值：请求时间的总和除以请求数。响应时间也可以报告为百分位请求，例如第90百分位响应时间。

两种方法的一个区别在于，平均值会受离群值影响。

## 2.3 原则3：用统计方法应对性能的变化

学生t检验（Student's t-test，以下称t检验），这是一种针对一组数据及其变化的统计分析。顺便说一句，”学生“是首次发表该检验的科学家（即威廉·戈斯特）的笔名。t检验计算出的p值，是指原假设（null hypothesis）成立时的概率。（有一些程序和类库可以计算t检验，本节的结果是用Apache Commons Mathematics类库中的TTest计算的。）

> **统计学及其语义**
>
> 正确表述t检验结果的语句应该像这样：试样与基线有差别的可能性为57%，差别预计最大有25%。
>
> 不过通常会这么描述：结果改善25%的置信度（confidence level）为57%。确切地说，这种说法与前面并不一致，也会让统计学家们抓狂，不过这种说法简短而易于为人接受，也不算太离谱。

t检验通常与α值一起使用，α值是一个点（有点随意），如果结果达到这个点那就是统计显著性（statistical significance）。通常α值设置为0.1——意思是说，如果试样和基线只在10%（0.1）的时间里相同（或反过来讲，90%的时间里试样和基线有差异），那结果就被认为是统计显著。其他常用的α值还有0.05（置信度95%）或0.01（置信度为99%）。如果测试的p值小于1-α值，则被认为是统计显著。

> **统计学中的显著性与重要性**
>
> 显著性差异并不意味着统计结果对我们更重要。

## 2.4 原则4：尽早频繁测试

理想情况下，在代码提交到中心源代码仓库前，性能测试就应该作为过程的一部分允许，如果代码引入了性能衰减，提交就会被阻止。

遵循以下准则，可以使得尽早频繁测试变得最有用

自动化一切

测试一切

在真实系统上运行

# 第3章 Java性能调优工具箱

## 3.1 操作系统的工具与分析

实际上性能分析的起点与Java无关：它是一组操作系统自带的基本监控工具。在基于Unix的系统上，有sar（System Accounting Report）及其组成工具，例如vmstat、iostat、prstat等。在WIndows上，有图形化资源监视器以及像typeperf这样的命令行工具。

### 3.1.1 CPU使用率

通常CPU使用率可以分为两类：用户态时间和系统态时间（Windows上被称作privileged time）。用户态时间是CPU执行应用代码所占时间，而系统态时间则是CPU执行内核代码所占时间的百分比。任何使用底层系统资源的操作，都会导致应用占用更多的系统态时间。

性能调优的目的是，在尽可能短的时间让CPU使用率尽可能地高。这听起来有点不合常理。

#### 1.Java和单CPU的使用率

#### 2.Java和多CPU的使用率

另外在多线程多CPU下，需要重点考虑以下CPU空闲的情形：即便有事可做，CPU仍然空闲。这在程序没有更多线程可用的时候可能会出现。

### 3.1.2 CPU运行队列

Windows和Unix系统都可以监控可运行（意味着没有被I/O阻塞、休眠等）的线程数。Unix系统称之为运行队列（run queue）

如果试图运行的线程数超过了可用的CPU，性能就会下降。一般来说，Windows的处理器队列长度最好为0，小于或等于Unix系统CPU的数目。

### 3.1.3 磁盘使用率

监控磁盘使用率有两个目的。第一个目的与应用本身有关：如果应用正在做大量的磁盘I/O操作，那I/O就很容易成为瓶颈。

监控磁盘使用率的第二个理由是——即使预计应用不会有很高的I/O——有助于监控系统是否在进行内存交换。

### 3.1.4 网络使用率

## 3.2 Java监控工具

- jcmd
  它用来打印Java进程所涉及的基本类、线程和VM信息。
- jconsole
  提供JVM活动的图形化视图，包括线程的使用、类的使用和GC活动。
- jhat
  读取内存堆转储，并有助于分析。这是事后使用的工具。
- jmap
  提供堆转储和其他JVM内存使用的信息。可以适用于脚本，但堆转储必须在事后分析工具中使用。
- jinfo
  查看JVM的系统属性，可以动态设置一些系统属性。可适用于脚本。
- jstack
  转储Java进程的栈信息。可适用于脚本。
- jstat
  提供GC和类装载活动的信息。可适用于脚本。
- jvisualvm
  监视JVM的GUI工具，可用来剖析运行的应用，分析JVM堆转储（事后活动，虽然jvisualvm也可以实时抓取程序的堆转储）。

### 3.2.1 基本的VM信息

**运行时间**

此命令可以查看JVM运行的时长：

~~~
% jcmd process_id VM.uptime
~~~

**系统属性**

以下命令可以显示System.getProperties()的各个条目。

~~~
% jcmd process_id VM.system_properties
~~~

或者

~~~
% jinfo -sysprops process_id
~~~

这包括通过命令行-D标志设置的所有属性，应用动态添加的所有属性和JVM的默认属性。

**JVM版本**

用以下方式获取JVM版本：

~~~
% jcmd process_id VM.version
~~~

**JVM命令行**

jconsole的“VM摘要”页可以显示程序所用的命令行，或者用jcmd显示：

~~~
% jcmd process_id VM.command_line
~~~

**JVM调优标志**

可用以下方式获得对应用生效的JVM调优标志

~~~
% jcmd process_id VM.flags [-all]
~~~

#### 调优标志

JVM可以设置许多调优标志，本书就关注了其中很多标志。追踪这些标志及其默认值有点让人崩溃。上面最后两个jcmd示例对于获取这类信息很有用。command_line显示直接在命令行指定的标志。flags显示命令行设置的标志，以及JVM直接设置的标志（因为它们的值是通过自动优化决定的）。该命令加上all时，可以列出JVM内部所有的标志。

想知道特定平台所设置的标志是什么，可以执行以下命令：

~~~
% java other_options -XX:+PrintFlagsFinal -version
……几百行输出，包括……
uintx InitialHeapSize	:=	4169431040	{product}
intx InlineSmallCode	=	2000		{pd product}
~~~

这些命令的标志数据以上述两种方式之一显示。输出第1行中的冒号表示标志使用的是非默认值。发生这种情况，可能是以下原因导致。

1. 标志值直接在命令行指定。
2. 其他标志间接改变了该标志的值。
3. JVM自动优化计算出来的默认值。

第2行（没有冒号）表示，值是这个JVM版本的默认值。某些标志的默认值在不同平台上可能会不同，输出的最右列会指示。product表示在所有平台上的默认设置都是一致的。pd product表示标志的默认值是独立于平台的。

最后一列可能的值还有manageable（运行时可以动态更改标志的值）和 C2 diagnostic（为编译器工程师提供诊断输出，帮助理解编译器正以什么方式运作）。

还有另一种查看运行中的应用的此类信息的工具，叫做jinfo。jinfo的好处在于，它允许程序在执行时更改某个标志的值。

以下是如何获取进程中所有标志的值：

~~~
% jinfo -flags process_id
~~~

jinfo带有-flags时可以提供所有标志的信息，否则只打印命令行所指定的标志。这两种数据都不像-XX:+Printflagsfinal 那样易读，但jinfo有其他值得注意的特性。

jinfo可以检查单个标志的值：

~~~
% jinfo -flag PrintGCDetails process_id
-XX:+PrintGCDetails
~~~

虽然jinfo本身不会显示是否manageable，但manageable（如Printflagsfinal输出中所标识的）的标志可以通过jinfo开启或关闭：

~~~
% jinfo -flag -PrintGCDetails process_id # turns off PrintGCDetails
% jinfo -flag PrintGCDetails process_id
-XX:-PrintGCDetails
~~~

需要当心的是，jinfo可以更改任意标志的值，但并不意味着JVM会响应更改。所以这个技术只会对那些在Printflagfinal输出中标记为manageable的标志有效。

### 3.2.2 线程信息

jconsole和jvisualvm可以实时显示应用中运行的线程的数量。

查看运行线程的栈信息，对于判断线程是否被阻塞很有用。可以通过jstack获取栈信息：

~~~
% jstack process_id
……显示了每个线程的栈的众多输出……
~~~

也可以通过jcmd获取栈信息

~~~
% jcmd process_id Thread.print
~~~

### 3.2.3 类信息

jconsole或jstat可以提供应用已使用类的个数。jstat还能提供类编译相关的信息。

### 3.2.4 实时GC分析

几乎所有的监控工具都能报告一些GC活动的信息。jconsole可以用实时图显示堆的使用情况。jcmd可以执行GC操作。jmap可以打印堆的概况、永久代信息或者创建堆转储。jstat可以为垃圾收集器正在执行的操作生成许多视图。

### 3.2.5 事后堆转储

jvisualvm的GUI界面可以捕获堆转储，也可以用命令行jcmd或jmap生成。堆转储是堆使用情况的快照，可以用不同的工具进行分析，包括jvisualvm和jhat。传统上，第三方处理堆转储的工具都领先于JDK，所以第7章使用第三方工具——Eclipse Memory Analyzer Tool——为例，展示如何在事后处理堆转储。

## 3.3 性能分析工具

### 3.3.1 采样分析器

性能分析有两种模式：数据采样或数据探查。

### 3.3.2 探查分析器

探查分析器相比于采样分析器，侵入性更强，但它们可以给出关于程序内部所发生的更有价值的信息。

### 3.3.3 阻塞方法和线程时间线

### 3.3.4 本地分析器

本地性能分析工具是指分析JVM自身性能的工具。

## 3.4 Java任务控制

商业版Java 7（从7u40开始）和Java 8包含了称为Java Mission Control（以下称JMC）的监控新特性。JMC不是开源版Java的一部分，并且只有通过商业许可才可用。

### 3.4.1 Java飞行记录器

JMC的关键特性是Java飞行记录器（Java Flight Recorder，JFR）。正像它名字所暗示的，JFR数据是JVM的历史事件，这些可以用来诊断JVM的历史性能和操作。

### 3.4.2 开启JFR

### 3.4.3 选择JFR事件

# 第4章 JIT编译器

即时（Just-In-Time, JIT）编译器是Java虚拟机的核心。对JVM性能影响最大的莫过于编译器，而选择编译器是运行Java程序时首先要做的选择之一——无论你是Java开发人员还是最终用户。幸运的是，在绝大多数情况下，只需要对编译器做一些基本的调优。

## 4.1 JIT编译器：概览

计算机——更具体说是CPU——只能执行相对少而特定的指令，这被称为汇编码或者二进制码。因此，CPU所执行的所有程序都必须翻译成这种指令。

像C++和Fortran这样的语言被称为编译型语言，因为它们的程序都以二进制（编译后的）形式交付：先写程序，然后用编译器静态生成二进制文件。这个二进制文件中的汇编码是针对特定CPU的。只要是兼容的CPU，都可以执行相同的二进制代码：比如，AMD和Intel CPU共享一个基本的、常用的汇编语言指令集，新版本的CPU几乎总是能执行与老版本CPU相同的指令集。但反过来并不总是成立，新版本的CPU时常会引入一些指令，这些指令无法在老版本CPU上运行。

另外还有一些像PHP和Perl这样的语言，则是解释型的。只要机器上有合适的解释器（即称为php或perl的程序），相同的程序代码可以在任何CPU上运行。执行程序时，解释器会将相应代码转换成二进制代码。

每种语言类型都各有长处和不足。解释型语言的程序可移植：相同的代码你丢到任何有适当解释器的机器上，它都能运行。但是它运行起来可能就慢了。

好的编译器在生成二进制代码时需要考虑许多因素。一个简单例子是二进制代码中语句顺序：生成的汇编语言指令与执行时的顺序并不完全相同。执行两个寄存器值相加语句可能只需要一个时钟周期，但（从主存储器）获取加法所需要的数据可能需要好几个周期。

因此，好的编译器生成二进制代码需要包括装载数据、执行其他指令，然后——当数据准备好时——执行加法。而一次只能看一行的解释器就没有足够的信息生成这样的代码了。它会请求内存数据，然后一直等到数据准备好之后再执行加法。稍差点的编译器也这么干，而且顺便说一句，即便是最好的编译器偶尔也需要等待指令完成。

由于这些（或其他的）原因，解释型代码几乎总是比编译型代码要慢：编译器有足够的程序信息，这些信息可用来大量优化二进制代码，这些是简单解释器无法做到的。

Java试图走一条中间路线。Java的应用会被编译——但不是编译成特定CPU所专用的二进制代码，而是被编译成一种理想化的汇编语言。然后该汇编语言（称为Java字节码）可以用java运行（与php解释运行PHP脚本是相同的道理）。这使得Java成为一门平台独立的解释型语言。因为java程序运行的是理想化的二进制代码，所以它能在代码执行时将其编译成平台特定的二进制代码。由于这个编译是在程序执行时进行的，因此被称为“即时编译”（即JIT）。

Java虚拟机在执行时编译代码的这种方式是本章关注的重点。

### 热点编译

如第1章讨论的那样，本书中的Java实现是Oracle的HotSpot JVM。HotSpot的名字来自于它看待代码编译的方式。对于程序来说，通常只有一部分代码被经常执行，而应用的性能就取决于这些代码执行得有多快。这些关键代码段被称为应用的热点，代码执行得越多就被认为是越热。

因此JVM执行代码时，并不会立即编译代码。有两个基本理由。第一，如果代码只执行一次，那编译完全就是浪费精力。对于只执行一次的代码，解释执行Java字节码比先编译然后执行的速度快。

但如果代码是经常被调用的方法，或者是运行很多次迭代的循环，编译就值得了：编译的代码更快，多次执行累计节约的时间超过了编译所花费的时间。这种权衡是编译器先解释执行代码的原因之一——编译器可以找出哪个方法被调用得足够频繁，可以进行编译。

第二个理由是为了优化：JVM执行特定方法或者循环的次数越多，它就会越了解这段代码。这使得JVM可以在编译代码时进行大量优化。

本章后面将讨论这些大量的优化（以及影响它们的方法），先考虑一个简单的例子，即equals()方法。这个方法存在于每个Java对象中（既然所有类都继承自Object类），并且经常被子类重写。当解释器遇到b = obj1.equals(obj) 语句时，为了知道该执行哪个equals()， 必须先查找obj1的类型（类）。这个动态查找的过程有点消耗时间。

> **寄存器和主内存**
>
> 编译器最重要的优化包括何时使用主内存中的值，以及何时在寄存器中贮存值。
>
> 如果每次循环迭代都从主内存获取（或保存）sum的值，性能就比较糟糕了。编译器不会这么做，它会将sum的初始值装入寄存器，用寄存器中的值执行循环，然后（在某个不确定的时刻）将最终的结果从寄存器写回到主内存。
>
> 这种优化非常高效，但这意味着线程同步的语义（参见第9章）对应用行为非常重要。一个线程无法看到另一个线程所用寄存器中保存变量的值，同步机制使得从寄存器写回主内存其他线程可以准确地读到这个值。
>
> 使用寄存器是编译器普遍采用的优化方法，当开启逃逸分析（escape analysis）时（参见本章末尾），寄存器的使用更为频繁。

比如说，随着时间的流逝，JVM发现每次执行这条语句时，obj1的类型都是java.lang.String。于是JVM就可以生成直接调用String.equals()的编译代码。现在代码更快了，不仅是因为被编译，也是因为跳过了查找该调用哪个方法的步骤。

不过没那么简单。下次执行代码时，obj1完全有可能是别的类型而不是String，所以JVM必须生成编译代码处理这种可能。尽管如此，由于跳过了方法查找的步骤，这里的编译代码整体性能仍然要快（至少和obj1一直是String时同样快）。这种优化只有在代码运行一段时间观察它如何做之后才能使用：这是为何JIT编译器等待代码编译的第二个原因。

## 4.2 调优入门：选择编译器类型（Client、Server或二者同用）

有两种“口味”的JIT编译器，选择哪种常常是应用运行时所需做的仅有的编译器调优。事实上，甚至在安装Java之前就必须考虑如何选择编译器，因为不同的Java安装包包含了不同的编译器。我们来逐步分析。首先找出何种环境下该用哪种编译器。

这两种编译器被称为client和server。名字来自于命令行上用于选择编译器的参数（例如-client或-server）。JVM开发者（甚至一些工具）通常称这些编译器为C1（编译器1，client编译器）和C2（编译器2，server编译器）。

> **与众不同的编译器标志**
>
> 分层编译（tiered compilation）意味着必须使用server编译器。与client编译器的选择冲突。

两种编译器的最主要的差别在于编译代码的时机不同。client编译器开启编译比server编译器要早。意味着在代码执行的开始阶段，client编译器比server编译器要快，因为它的编译代码相比server编译器而言要多。

此处最明显的问题是，为什么需要人来做这种选择？为什么JVM不能在启动时用client编译器，然后随着代码变热使用server编译器？这种技术被称为分层编译。代码先由client编译器编译，随着代码变热，由server编译器重新编译。

Java 8 中，分层编译默认为开启。

### 4.2.1 优化启动