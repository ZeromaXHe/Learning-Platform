# 第1章 绪论

## 1.1 引言

本书用“模型”泛指从数据中学得的结果。有文献用“模型”指全局性结果（例如一棵决策树），而用“模式”指局部性结果（例如一条规则）。

## 1.2 基本术语

每对括号内是一条记录，“=”意思是“取值为”。

这组记录的集合称为一个“数据集”（data set），其中每条记录是关于一个事件或对象（这里是一个西瓜）的描述，称为一个“示例”（instance）或“样本”（sample）。反映事件或对象在某方面的表现或性质的事项，称为“属性”（attribute）或“特征”（feature）；属性上的取值，称为“属性值”（attribute value）。属性张成的空间称为“属性空间”（attribute space）、“样本空间”（sample space）或“输入空间”。由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个“特征向量”（feature vector）。

一般地，令$D=\{x_1,x_2,\dots,x_m\}$表示包含m个示例的数据集，每个示例由d个属性描述（例如上面的西瓜数据使用了3个属性），则每个示例$x_i=(x_{i1};x_{i2};\dots;x_{id})$是d维样本空间 $\chi$ 中的一个向量，$x_i\in \chi$，其中 $x_{ij}$ 是 $x_i$ 在第j个属性上的取值，d称为样本 $x_i$ 的“维数”（dimensionality）。

从数据中学得模型的过程称为“学习”（learning）或“训练”（training），这个过程通过执行某个学习算法来完成。训练过程中使用的数据称为“训练数据”（training data），其中每个样本称为一个“训练样本”（training sample），训练样本组成的集合称为“训练集”（training set）。学得模型对应了关于数据的某种潜在的规律，因此亦称“假设”（hypothesis）；这种潜在规律自身，则称为“真相”或“真实”（ground-truth），学习过程是就是为了找出或逼近真相。本书有时将模型称为“学习器”（learner），可看作学习算法在给定数据和参数空间上的实例化。

若我们欲预测的是离散值，此类学习任务称为“分类”（classification）；若欲预测的是连续值，此类学习任务称为“回归”（regression）。对只涉及两个类别的“二分类”（binary classification）任务，通常称其中一个类为“正类”（positive class），另一个类为“反类”（negative class）；涉及多个类别时，则称为“多分类”（multi-class classification）任务。

根据训练数据是否拥有标记信息，学习任务可大致划分为两大类：“监督学习”（supervised learning）和“无监督学习”（unsupervised learning），分类和回归是前者的代表，而聚类则是后者的代表。

学得模型适用于新样本的能力，称为“泛化”（generalization）能力。

## 1.3 假设空间

归纳（induction）和演绎（deduction）是科学推理的两大基本手段。前者是从特殊到一般的“泛化”（generalization）过程，即从具体的事实归结出一般性规律；后者则是从一般到特殊的“特化”（specialization）过程，即从基础原理推演出具体状况。

我们可以把学习过程看作一个在所有假设(hypothesis) 组成的空间中进行搜索的过程，搜索目标是找到与训练集"匹配"但（fit） 的假设，即能够将训练集中的瓜判断正确的假设.

需注意的是，现实问题中我们常面临很大的假设空间?但学习过程是基于有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与训练集一致的"假设集合"，我们称之为"版本空间" (version space).

## 1.4 归纳偏好

机器学习算法在学习过程中对某种类型假设的偏好，称为"归纳偏好" (inductive bias) , 或简称为"偏好"

也就是说，无论学习算法$\xi_a$多聪明、学习算法$\xi_b$多笨拙，它们的期望性能竟然相同!这就是"没有免费的午餐"定理 (No Free Lunch Theorem，简称 NFL定理)

所以， NFL 定理最重要的寓意?是让我们清楚地认识到，脱离具体问题，空泛地谈论"什么学习算法更好"毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好.要谈论算法的相对优劣，必须要针对具体的学习问题;在某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用.

## 1.5 发展历程

机器学习是人工智能(artificial intelligence) 研究发展到一定阶段的必然产物.二十世纪五十年代到七十年代初，人工智能研究处于"推理期"，那时人们以为只要能赋予机器逻辑推理能力，机器就能具有智能.这一阶段的代表性工作主要有 A. Newell H. Simon 的"逻辑理论家" (Logic Theorist) 程序以及此后的"通用问题求解" (General Problem Solving) 程序等。A. Newell H. Simon 因为这方面的工作获得了 1975 年圈灵奖。

然而，随着研究向前发展，人们逐渐认识到，仅具有逻辑推理能力是远远实现不了人工智能的。E. A. Feigenbau 等人认为，要使机器具有智能，就必须设法使机器拥有知识。在他们的倡导下，从二十世纪七十年代中期开始，人工智能研究进入了"知识期"在这一时期，大量专家系统问世，在很多应用领域取得了大量成果。E.A.Feigenbaum 作为"知识工程"之父在 1994 年获得图灵奖。但是，人们逐渐认识到，专家系统面临"知识工程瓶颈"，简单地说，就是由人来把知识总结出来再教给计算机是相当困难的.于是，一些学者想到，如果机器自己能够学习知识该多好!

事实上，图灵在 1950 年关于图灵测试的文章中，就曾提到了机器学习的可能;二十世纪五十年代初已有机器学习的相关研究，例如 A. Samucl 著名的跳棋程序.五十年代中后期 基于神经网络的"连接主义" (conncctionism) 学习开始出现，代表性工作有 F. Rosenblatt 的感知机(Perceptron) B. Widrow的Adaline 等.在六七十年代，基于逻辑表示的"符号主义" (symbolism) 学习技术蓬勃发展，代表性工作有 P. Winston 的"结构学习系统"、R. S. Michalski 等人的"基于逻辑的归纳学习系统'、E. B. Hunt 等人的"概念学习系统"等;以决策理论为基础的学习技术以及强化学习技术等也得到发展，代表性工作有 N. J. Nilson 的"学习机器"等；二十多年后红极一时的统计学习理论的一些奠基性结果也是在这个时期取得的。

总的来看，二十世纪八十年代是机器学习成为一个独立的学科领域、各种机器学习技术百花初绽的时期.

二十世纪八十年代以来，被研究最多、应用最广的是"从样例中学习" (也就是广义的归纳学习) ，它涵盖了监督学习、无监督学习等，本书大部分内容均属此范畴。下面我们对这方面主流技术的演进做一个简单回顾.

在二十世纪八十年代，"从样例中学习"的一大主流是符号主义学习，其代表包括决策树(decision tree) 和基于逻辑的学习.典型的决策树学习以信息论为基础，以信息娟的最小化为目标，直接模拟了人类对概念进行判定的树形流程.基于逻辑的学习的著名代表是归纳逻辑程序设计(Inductive Logic Programming，简称 ILP) ，可看作机器学习与逻辑程序设计的交叉，它使用一阶逻辑(即谓词逻辑)来进行知识表示，通过修改和扩充逻辑表达式(例如 Prolog表达式)来完成对数据的归纳

二十世纪九十年代中期之前，"从样例中学习"的另一主流技术是基于神经网络的连接主义学习.连接主义学习在二十世纪五十年代取得了大发展，但因为早期的很多人工智能研究者对符号表示有特别偏爱，例如图灵奖得主Simon 曾断言人工智能是研究"对智能行为的符号化建模"，所以当时连接主义的研究未被纳入主流人工智能研究范畴.尤其是连接主义自身也遇到了很大的障碍，正如图灵奖得主 M. Minsky 11 S. Papert 1969 年指出， (当时的)神经网络只能处理线性分类 甚至对"异或"这么简单的问题都处理不了.1983 年，J. J. Hopfield 利用神经网络求解"流动推销员问题"这个著名的 NP 难题取得重大进展，使得连接主义重新受到人们关注. 1986 年， D. E. Rumelhart 等人重新发明了著名的 BP 算法，产生了深远影响.

二十世纪九十年代中期"统计学习" (statistical learning) 闪亮登场并迅速占据主流舞台，代表性技术是支持向量机(Support Vector Machine ，简称SVM) 以及更一般的"核方法" (kernel methods). 这方面的研究早在二十世纪六七十年代就已开始，统计学习理论 [Vapnik 1998] 在那个时期也已打下了基础，例如V. N. Vapnik 1963 年提出了"支持向量"概念，他和 A. J. Chervonenkis 在 1968 年提出 VC 维，在 1974 年提出了结构风险最小化原则等.但直到九十年代中期统计学习才开始成为机器学习的主流，一方面是由于有效的支持向量机算法在九十年代初才被提出，其优越性能到九十年代中期在文本分类应用中才得以显现；另一方面，正是在连接主义学习技术的局限性凸显之后，人们才把目光转向了以统计学习理论为直接支撑的统计学习技术.

有趣的是，二十一世纪初，连接主义学习又卷土重来，掀起了以"深度学习"为名的热潮.所谓深度学习，狭义地说就是"很多层"的神经网络.在若干测试和竞赛上，尤其是涉及语音、图像等复杂对象的应用中，深度学习技术取得了优越性能.以往机器学习技术在应用中要取得好性能，对使用者的要求较高;而深度学习技术涉及的模型复杂度非常高，以至于只要下工夫"调参"，把参数调节好，性能往往就好.

## 1.6 应用现状

# 第2章 模型评估与选择

## 2.1 经验误差与过拟合

通常我们把分类错误的样本数占样本总数的比例称为"错误率" (error rate) 。学习器在训练集上的误差称为"训练误差" (training error) 或"经验误差" (empirical error) ，在新样本上的误差称为"泛化误差" (generalization error)。

然而，当学习器把训练样本学得"太好"了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降这种现象在机器学习中称为"过拟合" (overfitting). 与"过拟合"相对的是"欠拟合" (underfitting) ，这是指对训练样本的一般性质尚未学好.

关于这一点，可大致这样理解:机器学习面临的问题通常是 NP 难甚至更难，而有效的学习算法必然是在多项式时间内运行完 ，若可彻底避免过拟合， 则通过经验误差最小化就能获最优解，这就意味着我们构造性地证明了“P=NP” ;因此 只要相信 “P≠NP”，过拟合就不可避免。

## 2.2 评估方法

通常， 我们可通过实验测试来对学习器的泛化误差进行评估并进而做出选择。为此， 需使用一个 "测试集 (testing set) 测试学习器对新样本的判别能力，然后以测试集上的"测试误差" (testing error) 作为泛化误差的近似。

### 2.2.1 留出法

"留出法" (hold-out) 直接将数据集 D 划分为两个互斥的集合，其中一个集合作为训练集 S，另一个作为测试集 T。在 S 上训练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计.

### 2.2.2 交叉验证法

"交叉验证法" (cross alidation) 将数据集D划分为k个大小相似的互斥子集，每个子集$D_i$都尽可能保持数据分布的一致性，即从D中通过分层采样得到。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可以进行k次训练和测试，最后返回的是这k个测试结果的均值。显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，为强调这一点，通常把交叉验证法称为“k折交叉验证”（k-fold cross validation）。

### 2.2.3 自助法

“自助法”（bootstrapping）是一个比较好的解决方案，它直接以自助采样法（bootstrap sampling）为基础。给定包含m个样本的数据集D，我们对它进行采样产生数据集D'：每次随机从D中挑选一个样本，将其拷贝放入D'，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行m次后，我们就得到了包含m个样本的数据集D'，这就是自助采样的结果。显然，D中有一部分样本会在D’中多次出现，而另一部分样本不出现。

自助法在数据集较小、难以有效划分训练/测试集时很有用

### 2.2.4 调参与最终模型

大多数学习算法都要些参数（parameter）需要设定，参数配置不同，学得模型的性能往往有显著差别。因此，在进行模型评估与选择时，除了要对适用学习算法进行选择，还需对算法参数进行设定，这就是通常所说的“参数调节”或简称“调参”（parameter tuning）。

## 2.3 性能度量