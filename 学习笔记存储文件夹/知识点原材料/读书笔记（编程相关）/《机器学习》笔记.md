# 第1章 绪论

## 1.1 引言

本书用“模型”泛指从数据中学得的结果。有文献用“模型”指全局性结果（例如一棵决策树），而用“模式”指局部性结果（例如一条规则）。

## 1.2 基本术语

每对括号内是一条记录，“=”意思是“取值为”。

这组记录的集合称为一个“数据集”（data set），其中每条记录是关于一个事件或对象（这里是一个西瓜）的描述，称为一个“示例”（instance）或“样本”（sample）。反映事件或对象在某方面的表现或性质的事项，称为“属性”（attribute）或“特征”（feature）；属性上的取值，称为“属性值”（attribute value）。属性张成的空间称为“属性空间”（attribute space）、“样本空间”（sample space）或“输入空间”。由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个“特征向量”（feature vector）。

一般地，令$D=\{x_1,x_2,\dots,x_m\}$表示包含m个示例的数据集，每个示例由d个属性描述（例如上面的西瓜数据使用了3个属性），则每个示例$x_i=(x_{i1};x_{i2};\dots;x_{id})$是d维样本空间 $\chi$ 中的一个向量，$x_i\in \chi$，其中 $x_{ij}$ 是 $x_i$ 在第j个属性上的取值，d称为样本 $x_i$ 的“维数”（dimensionality）。

从数据中学得模型的过程称为“学习”（learning）或“训练”（training），这个过程通过执行某个学习算法来完成。训练过程中使用的数据称为“训练数据”（training data），其中每个样本称为一个“训练样本”（training sample），训练样本组成的集合称为“训练集”（training set）。学得模型对应了关于数据的某种潜在的规律，因此亦称“假设”（hypothesis）；这种潜在规律自身，则称为“真相”或“真实”（ground-truth），学习过程是就是为了找出或逼近真相。本书有时将模型称为“学习器”（learner），可看作学习算法在给定数据和参数空间上的实例化。

若我们欲预测的是离散值，此类学习任务称为“分类”（classification）；若欲预测的是连续值，此类学习任务称为“回归”（regression）。对只涉及两个类别的“二分类”（binary classification）任务，通常称其中一个类为“正类”（positive class），另一个类为“反类”（negative class）；涉及多个类别时，则称为“多分类”（multi-class classification）任务。

根据训练数据是否拥有标记信息，学习任务可大致划分为两大类：“监督学习”（supervised learning）和“无监督学习”（unsupervised learning），分类和回归是前者的代表，而聚类则是后者的代表。

学得模型适用于新样本的能力，称为“泛化”（generalization）能力。

## 1.3 假设空间

归纳（induction）和演绎（deduction）是科学推理的两大基本手段。前者是从特殊到一般的“泛化”（generalization）过程，即从具体的事实归结出一般性规律；后者则是从一般到特殊的“特化”（specialization）过程，即从基础原理推演出具体状况。

我们可以把学习过程看作一个在所有假设(hypothesis) 组成的空间中进行搜索的过程，搜索目标是找到与训练集"匹配"但（fit） 的假设，即能够将训练集中的瓜判断正确的假设.

需注意的是，现实问题中我们常面临很大的假设空间?但学习过程是基于有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与训练集一致的"假设集合"，我们称之为"版本空间" (version space).

## 1.4 归纳偏好

机器学习算法在学习过程中对某种类型假设的偏好，称为"归纳偏好" (inductive bias) , 或简称为"偏好"

也就是说，无论学习算法$\xi_a$多聪明、学习算法$\xi_b$多笨拙，它们的期望性能竟然相同!这就是"没有免费的午餐"定理 (No Free Lunch Theorem，简称 NFL定理)

所以， NFL 定理最重要的寓意?是让我们清楚地认识到，脱离具体问题，空泛地谈论"什么学习算法更好"毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好.要谈论算法的相对优劣，必须要针对具体的学习问题;在某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法自身的归纳偏好与问题是否相配，往往会起到决定性的作用.

## 1.5 发展历程

