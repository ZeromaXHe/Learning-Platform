# 前言

## 本书特色

本书借助数据仓库实现一套用户画像系统的方案。从实际工程案例出发，结合多业务场景，内容涵盖开发离线批处理计算的标签及流式计算标签，为读者的分析、开发、搭建用户画像系统，并借助该用户画像系统为运营人员制定运营用户的策略提供端到端的解决方案。

一套好的解决方案需要包括一下几个层面。

1）架构层：在画像系统的架构层，本书首先介绍了画像数据仓库的架构，进一步介绍了数据存储的技术选型，在什么场景下使用Hive、MySQL、HBase、ElasticSearch等工具存储数据，用户标签开发、人群计算开发等相应数据开发层面的内容，以及整个项目的开发流程和各阶段的关键产出。

2）流量层：介绍整个方案是如何运作起来的。本书主要涉及画像系统的作业流程调度、数据仓库和各业务系统的打通。

3）业务层：包括系统的前后端交互以及如何把这套系统应用在业务服务层面。本书通过用户画像产品化介绍了产品端和画像系统的“代码”层面是如何进行交互操作的。

4）方案价值：包括系统上线后如何服务于各业务场景产生业务价值以及有待进一步完善的地方。

我在学习数据仓库的时候学过Kimball的《数据仓库工具箱》，其中关于数据仓库的34个子系统的介绍对我影响很大，其对于如何解决特定问题并形成结构化思维有着系统的方法论与解决方案。虽然面对具体问题的处理方式是灵活且丰富多样的，但是固定的结构化思维有利于快速找到突破口，形成良好的开端。

# 第1章 用户画像基础

## 1.1 用户画像是什么

### 1.1.1 画像简介

用户画像，即用户信息标签化，通过收集用户的社会属性、消费习惯、偏好特征等各个维度的数据，进而对用户或者产品特征属性进行刻画，并对这些特征进行分析、统计，挖掘潜在价值信息，从而抽象出用户的信息全貌。用户画像可看作企业应用大数据的根基，是定向广告投放与个性化推荐的前置条件，为数据驱动运营奠定了基础。

数据应用体系的层级划分：

| 层级|功能内容|
|------|---------|
|5.战略决策|决策支持|
|4.精细化运营工具|用户行为分析、用户画像、数据挖掘、个性化推荐|
|3.产品运营与分析|自助提取数据、报表分析工具|
|2.报表与可视化|可配置数据报表以及报表的可视化展现|
|1.基础平台搭建|数据平台建设、数据仓库建设、统一SDK|

### 1.1.2 标签类型

用户画像建模其实就是对用户“打标签”，从对用户打标签的方式来看，一般分为3种类型：
①统计类标签；
②规则类标签；
③机器学习挖掘类标签。

下面我们介绍这3种类型的标签的区别：

1.统计类标签

这类标签是最基础也最常见的标签类型，例如，对于某个用户来说，其性别、年龄、城市、星座、近7日活跃时长、近7日活跃天数、近7日活跃次数等字段可以从用户注册数据、用户访问、消费数据中统计得出。该类标签构成了用户画像的基础。

2.规则类标签

该类标签基于用户行为及确定的规则产生。例如，对平台上“消费活跃”的用户这一口径的定义为“近30天交易次数≥2”。在实际开发画像的过程中，由于运营人员对业务更为熟悉，而数据人员对数据的结构、分布、特征更为熟悉，因此规则类标签的规则由运营人员和数据人员共同协商确定；

3.机器学习挖掘类标签

这类标签通过机器学习挖掘产生，用于对用户的某些属性或某些行为进行预测判断。例如，根据一个用户的行为习惯判断该用户是男性还是女性、根据一个用户的消费习惯判断其对某商品的偏好程度。该类标签需要通过算法挖掘产生。

在项目工程实践中，一般统计类和规则类的标签即可以满足应用需求，在开发中占有较大比例。机器学习挖掘类标签多用于预测场景，如判断用户性别、用户购买商品偏好、用户流失意向等。一般地，机器学习标签开发周期较长，开发成本较高，因此其开发所占比例较小。

## 1.2 数据架构

在整个工程化方案中，系统依赖的基础设施包括Spark、Hive、HBase、Airflow、MySQL、Redis、ElasticSearch。除去基础设施外，系统主体还包括Spark Streaming、ETL、产品端3个重要组成部分。

> ETL，是英文Extract-Transform-Load的缩写，用来描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程。ETL一词较常用在数据仓库，但其对象并不限于数据仓库。

~~~
画像产品端管理
⬆           
①MySQL （标签元数据管理 BI报表展示数据 监控状态数据）
②ElasticSearch(人群计算/分析)
③HBase（个性化推荐数据 线上实时数据）
④FTP（文件传输）
⬆
Hive数据仓库
用户画像主题建模
（用户属性、用户行为、用户偏好、ID-MAP、购买品类、风险控制、群体偏好...） 
⬆                                                  ⬆
（Hive离线批处理/Spark实时处理）                       （Spark Streaming流式处理）
Hive数据仓库                                        Kafka
ETL作业
（DW、ODS、DM⬅业务数据、日志数据、埋点数据、外部数据）
~~~

下方为常见的数据仓库ETL加工流程，也就是将每日的业务数据、日志数据、埋点数据等经过ETL过程，加工到数据仓库对应的ODS层、DW层、DM层中。

中间即为用户画像建模的主要环节，用户画像不是产生数据的源头，而是对基于数据仓库ODS层、DW层、DM层中与用户相关数据的二次建模加工。在ETL过程中将用户标签计算结果写入Hive，由于不同数据库有不同的应用场景，后续需要进一步将数据同步到MySQL、HBase、Elasticsearch等数据库中。

- Hive：存储用户标签计算结果、用户人群计算结果、用户特征库计算结果。
- MySQL：存储标签元数据，监控相关数据，导出到业务系统的数据。
- HBase：存储线上接口实时调用类数据。
- Elasticsearch：支持海量数据的实时查询分析，用于存储用户人群计算、用户群透视分析所需的用户标签数据（由于用户人群计算、用户群透视分析的条件转化成的SQL语句多条件嵌套较为复杂，使用Impala执行也需花费大量时间）

> Impala是Cloudera公司主导开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase中的PB级大数据。已有的Hive系统虽然也提供了SQL语义，但由于Hive底层执行使用的是MapReduce引擎，仍然是一个批处理过程，难以满足查询的交互性。

用户标签数据在Hive中加工完成后，部分标签通过Sqoop同步到MySQL数据库，提供用于BI报表展示的数据、多维透视分析数据、圈人服务数据；另一部分标签同步到HBase数据库用于产品的线上个性化推荐。

> Sqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。

## 1.3 主要覆盖模块

搭建一套用户画像方案整体来说需要考虑8个模块的建设。

- 用户画像基础：需要了解、明确用户画像是什么，包含哪些模块，数据仓库架构是什么样子，开发流程，表结构设计，ETL设计等。这些都是框架，大方向的规划，只有明确了方向后续才能做好项目的排期和人员投入预算。这对于评估每个开发阶段重要指标的关键产出非常重要，重点可看1.4节。
    - 用户画像是什么
        - 画像简介
        - 标签类型
    - 数据架构
    - 开发流程
    - 常见表结构设计
        - 日增量数据
        - 日全量数据
- 数据指标体系：根据业务线整理，包括用户属性、用户行为、风险控制等维度的指标体系。
    - 用户属性维度标签
        - 常见用户属性
        - 用户性别
    - 用户行为维度标签
    - 用户消费维度标签
    - 风险控制维度标签
    - 标签命名方式
- 标签数据存储：标签相关数据可存储在Hive、MySQL、HBase、Elasticsearch等数据库中，不同存储方式适用于不同的应用场景。
    - Hive存储
        - 分区插入数据
        - 标签ID-Mapping
    - MySQL存储
        - 元数据管理
        - 标签量级监控
        - 结果集存储
    - HBase存储
    - ES存储
- 标签数据开发：用户画像工程化的重点模块，包含统计类、规则类、挖掘类、流式计算类的开发，以及人群计算功能的开发，打通画像数据和各业务系统之间的通路，提供接口服务等开发内容。
    - 统计类标签开发
    - 规则类标签开发
        - 数据调研
        - 确定业务规则
    - 挖掘类标签开发
        - 读取Kafka数据
        - 标签开发
        - 上线工程化
    - 打通数据服务层
- 开发性能调优：标签加工、人群计算等脚本上线调度后，为了缩短调度时间、保障数据的稳定性等，需要对开发的脚本进行迭代重构、调优。
    - 数据倾斜调优
    - Spark读取小文件调优
    - 使用Spark缓存
    - 减少 Shuffle类算子
    - ID-Mapping映射
    - 开发中间表
- 作业流程调度：标签加工、人群计算、同步数据到业务系统、数据监控预警等脚本开发完成后，需要调度工具把整套流程调度起来。本书讲解了Airflow这款开源ETL工具在调度画像相关任务脚本上的应用。
    - Crontab命令调度
    - Airflow工作平台
        - Airflow服务构成
        - 主要功能模块
        - 工作流调度
        - 常用命令
    - 标签数据监控预警
    - ETL异常排查
- 用户画像产品化：为了能让用户数据更好地服务于业务方，需要以产品化的形态应用在业务上。产品化的模块主要包括标签视图、用户标签查询、用户分群、透视分析等。
    - 标签视图查询
    - 标签编辑管理
    - 自定义配置查询
    - 多维透视分析
    - 目标人群固定
- 用户画像应用：画像的应用场景包括用户特征分析、短信、邮件、站内信、Push消息的精准推送、客服针对用户的不同话术、针对高价值用户的极速退货退款等VIP服务应用。
    - 经营分析
        - 商品分析
        - 用户分析
        - 流量分析
    - 精装营销
        - 短信/邮件营销
        - ROI效果分析
    - 个性化推荐与服务
        - Push消息
        - 相关商品推荐
        - 用户个性化服务

## 1.4 开发阶段流程

### 1.4.1 开发上线流程
~~~
目标解读
任务分解与需求调研
需求场景讨论与明确
应用场景与数据口径确认
特征选取与模型数据落表
线下模型数据验收与测试
线上模型发布与效果追踪（迭代优化，回到需求场景讨论与明确）
~~~

第一阶段：目标解读

第二阶段：任务分解与需求调研

第三阶段：需求场景讨论与明确

第四阶段：应用场景与数据口径确认

第五阶段：特征选取与模型数据落表

第六阶段：线下模型数据验收与测试

第七阶段：线上模型发布与效果追踪

### 1.4.2 各阶段关键产出

- 标签开发：根据业务需求和应用场景梳理指标体系，调研业务上定义的数据口径，确认数据来源，开发相应的标签。标签开发在整个画像周期中占有较大比重。
- ETL调度开发：梳理需要调度的各任务之间的依赖关系，开发调度脚本及调度监控告警脚本，上线调度系统。
- 打通服务层接口：为了让画像数据走出数据仓库，应用到用户身上，需要打通数据仓库和各业务系统的接口。
- 画像产品化：需要产品经理与业务人员、技术开发人员一起对接业务需求点和产品功能实现形式，画产品原型，确定工作排期。Java Web端开发完成后，需要数据开发人员向对应的库表中灌入数据。
- 开发调优：在画像的数据和产品端搭建好架构、能提供稳定服务的基础上，为了让调度任务执行起来更加高效、提供服务更加稳健，需要对标签计算脚本、调度脚本、数据同步脚本等相关计算任务进行重构优化。
- 面向业务方推广应用：用户画像最终的价值产出点是业务方应用画像数据进行用户分析，多渠道触达运营用户，分析ROI，提升用户活跃度或营收。因此，面向业务人员推广画像系统的使用方式、提供针对具体业务场景的解决方案显得尤为重要。在该阶段，相关人员需要撰写画像的使用文档，提供业务支持。

## 1.5 画像应用的落地

## 1.6 某用户画像案例

### 1.6.1 案例背景介绍

### 1.6.2 相关元数据

### 1.6.3 画像表结构设计

## 1.7 定性类画像

# 第2章 数据指标体系

数据指标体系是建立用户画像的关键环节，也是在标签开发前要进行的工作，具体来说就是需要结合企业的业务情况设定相关的指标。

互联网相关企业在建立用户画像时一般除了基于用户维度（userid）建立一套用户标签体系外，还会基于用户使用设备维度（cookieid）建立相应的标签体系。基于cookieid维度的标签应用也很容易理解，当用户没有登陆账户而访问设备时，也可以基于用户在设备上的行为对该设备推送相关的广告、产品和服务。

建立的用户标签按标签类型可以分为统计类、规则类和机器学习挖掘类，相关内容在1.1.2节中有详细介绍。从建立的标签维度来看，可以将其分为用户属性类、用户行为类、用户消费类和风险控制类等常见类型。

## 2.1 用户属性维度

### 2.1.1 常见用户属性

用户属性是刻画用户的基础。常见用户属性指标包括：用户的年龄、性别、安装时间、注册状态、城市、省份、活跃登陆地、历史购买状态、历史购买金额等。

### 2.1.2 用户性别

## 2.2 用户行为维度

## 2.3 用户消费维度

## 2.4 风险控制维度

## 2.5 社交属性维度

## 2.6 其他常见标签划分方式

- 用户属性：包括用户的年龄、性别、设备型号、安装/注册状态、职业等刻画用户静态特征的属性。
- 用户行为：包括用户的消费行为、购买后行为、近N日的访问、收藏、下单、购买、售后等相关行为。
- 偏好细分：用户对于商品品类、商品价格段、各营销渠道、购买的偏好类型、不同营销方式等方面的偏好特征；
- 风险控制：对用户从征信风险、使用设备的风险、在平台消费过程中产生的问题等维度考量其风险程度；
- 业务专用：应用在各种业务上的标签，如A/B测试标签、Push系统标签等；
- 营销场景：以场景化进行分类，根据业务需要构建一系列营销场景，激发用户的潜在需求，如差异化客服、场景用户、再营销用户等；
- 地域细分：标识用户的常住城市、居住商圈、工作商圈等信息，应用在基于用户地理位置进行推荐的场景中；
- 用户分层：对用户按生命周期、RFM、消费水平类型、活跃度类型等进行分层划分。

## 2.7 标签命名方式

|标签主题|用户维度|标签类型|一级归类|
|-------|------|------|------|
|ATTRIBUTE：人口属性<br/>ACTION：行为属性<br/>CONSUME：用户消费<br/>RISKMANAGE：风险控制<br/>...|C:cookieid<br/>U:userid|统计型<br/>规则型<br/>算法型|自然性别<br/>购物性别<br/>年龄<br/>地域<br/>...|

- 标签主题：用于刻画属于哪种类型的标签，如人口属性、行为属性、用户消费、风险控制等多种类型，可分别用ATTRIBUTE、ACTION、CONSUME、RISKMANAGE等单词表示各标签主题。
- 用户维度：用于刻画该标签是打在用户唯一标识（userid）上，还是打在用户使用的设备（cookieid）上。可用U、C等字母分别标识userid和cookieid维度。
- 标签类型：类型可划分为统计型、规则型和算法型。其中统计型开发可直接从数据仓库中各主题表建模加工而成，规则型需要结合公司业务和数据情况，算法型开发需要对数据做机器学习的算法处理得到对应的标签。
- 一级维度：在每个标签主题大类下面，进一步细分维度来刻画用户。

参照上面的命名维度和命名方式，下面通过几个例子来讲述如何命名标签。

对于用户的性别标签，标签主题是人口属性，用户维度为userid，标签类型属于算法型。给男性用户打上标签“ATTRIBUTE_U_01_001”，给女性用户打上标签“ATTRIBUTE_U_01_002”，其中“ATTRIBUTE”为人口属性主题，“`_`”后面的“U”为userid维度，“`_`”后面“01”为一级归类，最后面的“001”和“002”为该一级标签下的标签明细，如果是划分高中低活跃用户的，对应一级标签下的明细可划分为“001”、“002”、“003”。

标签统一命名后，维护一张码表记录标签id名称、标签含义及标签口径等主要信息，后期方便元数据的维护和管理。本节介绍的标签命名方式可作为开发标签过程中的一种参考方式。

# 第3章 标签数据存储

## 3.1 Hive存储

### 3.1.1 Hive数据仓库

