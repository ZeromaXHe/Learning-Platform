# 前言

一般认为，推荐系统这个研究领域源于协同过滤算法的提出。这么说来，推荐系统诞生快20年了。

本书希望将这20年间诞生的典型方法进行总结。但由于方法太多，这些方法的归类有很多不同的方式。比如，
- 可以按照数据分成协同过滤、内容过滤、社会化过滤，
- 也可以按照算法分成基于邻域的算法、基于图的算法、基于矩阵分解或者概率模型的算法。

# 第1章 好的推荐系统

## 1.1 什么是推荐系统

随着信息技术和互联网的发展，人们逐渐从信息匮乏的时代走入了信息过载（information overload）的时代。在这个时代，无论是信息消费者还是信息生产者都遇到了很大的挑战：作为信息消费者，如何从大量信息中找到自己感兴趣的信息是一件非常困难的事情；作为信息生产者，如何让自己生产的信息脱颖而出，受到广大用户的关注，也是一件非常困难的事情。推荐系统就是解决这一矛盾的重要工具。推荐系统的任务就是联系用户和信息，一方面帮助用户发现对自己有价值的信息，另一方面让信息能够展现在对它感兴趣的用户面前，从而实现信息消费者和信息生产者的双赢（如图1-1所示）。（本书后面将信息统称为“物品”，即可以供用户消费的东西。）

从物品的角度出发，推荐系统可以更好地发掘物品的长尾（long tail）。
主流商品往往代表了绝大多数用户的需求，而长尾商品往往代表了一小部分用户的个性化需求。因此，如果要通过发掘长尾提高销售额，就必须充分研究用户的兴趣，而这正是个性化推荐系统主要解决的问题。推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。

- 向朋友咨询。我们也许会打开聊天工具，找几个经常看电影的好朋友，问问他们有没有什么电影可以推荐。甚至，我们可以打开微博，发表一句“我要看电影”，然后等待热心人推荐电影。这种方式在推荐系统中称为社会化推荐（social recommendation），即让好友给自己推荐物品。
- 我们一般都有喜欢的演员和导演，有些人可能会打开搜索引擎，输入自己喜欢的演员名，然后看看返回结果中还有什么电影是自己没有看过的。比如我非常喜欢周星驰的电影，于是就去豆瓣搜索周星驰，发现他早年的一部电影我还没看过，于是就会看一看。这种方式是寻找和自己之前看过的电影在内容上相似的电影。推荐系统可以将上述过程自动化，通过分析用户曾经看过的电影找到用户喜欢的演员和导演，然后给用户推荐这些演员或者导演的其他电影。这种推荐方式在推荐系统中称为基于内容的推荐（content-based filtering）。
- 我们还可能查看排行榜，比如著名的IMDB电影排行榜，看看别人都在看什么电影，别人都喜欢什么电影，然后找一部广受好评的电影观看。这种方式可以进一步扩展：如果能找到和自己历史兴趣相似的一群用户，看看他们最近在看什么电影，那么结果可能比宽泛的热门排行榜更能符合自己的兴趣。这种方式称为基于协同过滤（collaborative filtering）的推荐。

通过这一节的讨论，我们可以发现推荐系统就是自动联系用户和物品的一种工具，它能够在信息过载的环境中帮助用户发现令他们感兴趣的信息，也能将信息推送给对它们感兴趣的用户。

## 1.2 个性化推荐系统的应用

尽管不同的网站使用不同的推荐系统技术，但总地来说，几乎所有的推荐系统应用都是由前台的展示页面、后台的日志系统以及推荐算法系统3部分构成的。因此，本节在介绍不同的个性化推荐系统应用时，都尽量围绕这3个不同的部分进行。

### 1.2.1 电子商务

### 1.2.2 电影和视频网站

### 1.2.3 个性化音乐网络电台

个性化推荐的成功应用需要两个条件。第一是存在信息过载，因为如果用户可以很容易地从所有物品中找到喜欢的物品，就不需要个性化推荐了。第二是用户大部分时候没有特别明确的需求，因为用户如果有明确的需求，可以直接通过搜索引擎找到感兴趣的物品。

- **物品空间大**：物品数很多，物品空间很大，这主要是相对于书和电影而言。
- **消费每首歌的代价很小**：对于在线音乐来说，音乐都是免费的，不需要付费。
- **物品种类丰富**： 音乐种类丰富，有很多的流派。 
- **听一首歌耗时很少**： 听一首音乐的时间成本很低，不太浪费用户的时间，而且用户大都把音乐作为背景声音，同时进行其他工作。
- **物品重用率很高**： 每首歌用户会听很多遍，这和其他物品不同，比如用户不会反复看一个电影，不会反复买一本书。
- **用户充满激情**： 用户很有激情，一个用户会听很多首歌。 
- **上下文相关**： 用户的口味很受当时上下文的影响，这里的上下文主要包括用户当时的心情（比如沮丧的时候喜欢听励志的歌曲）和所处情境（比如睡觉前喜欢听轻音乐）。
- **次序很重要**： 用户听音乐一般是按照一定的次序一首一首地听。
- **很多播放列表资源**： 很多用户都会创建很多个人播放列表。
- **不需要用户全神贯注**： 音乐不需要用户全神贯注地听，很多用户将音乐作为背景声音。
- **高度社会化**： 用户听音乐的行为具有很强的社会化特性，比如我们会和好友分享自己喜
欢的音乐。

上面这些特点决定了音乐是一种非常适合用来推荐的物品。因此，尽管现在很多推荐系统都是作为一个应用存在于网站中，比如亚马逊的商品推荐和Netflix的电影推荐，唯有音乐推荐可以支持独立的个性化推荐网站，比如Pandora、Last.fm和豆瓣网络电台。

### 1.2.4 社交网络

### 1.2.5 个性化阅读

### 1.2.6 基于位置的服务

### 1.2.7 个性化邮件

### 1.2.8 个性化广告

广告是互联网公司生存的根本。很多互联网公司的盈利模式都是基于广告的，而广告的CPC、CPM直接决定了很多互联网公司的收入。目前，很多广告都是随机投放的，即每次用户来了，随机选择一个广告投放给他。这种投放的效率显然很低，比如给男性投放化妆品广告或者给女性投放西装广告多半都是一种浪费。因此，很多公司都致力于广告定向投放（Ad Targeting）的研究，即如何将广告投放给它的潜在客户群。个性化广告投放目前已经成为了一门独立的学科——计算广告学——但该学科和推荐系统在很多基础理论和方法上是相通的，比如它们的目的都是联系用户和物品，只是在个性化广告中，物品就是广告。

个性化广告投放和狭义个性化推荐的区别是，个性化推荐着重于帮助用户找到可能令他们感兴趣的物品，而广告推荐着重于帮助广告找到可能对它们感兴趣的用户，即一个是以用户为核心，而另一个以广告为核心。目前的个性化广告投放技术主要分为3种。

- 上下文广告 通过分析用户正在浏览的网页内容，投放和网页内容相关的广告。代表系统是谷歌的Adsense。 
- 搜索广告 通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放和用户目的相关的广告。
- 个性化展示广告 我们经常在很多网站看到大量展示广告（就是那些大的横幅图片），它们是根据用户的兴趣，对不同用户投放不同的展示广告。雅虎是这方面研究的代表。

广告的个性化定向投放是很多互联网公司的核心技术，很多公司都秘而不宣。不过，雅虎公司是个例外，它发表了大量个性化广告方面的论文。

在个性化广告方面最容易获得成功的无疑是Facebook，因为它拥有大量的用户个人资料，可以很容易地获取用户的兴趣，让广告商选择自己希望对其投放广告的用户。Facebook的广告系统界面允许广告商选择自己希望的用户群，然后Facebook会根据广告商的选择告诉他们这些限制条件下广告将会覆盖的用户数量。

## 1.3 推荐系统评测

什么才是好的推荐系统？这是推荐系统评测需要解决的首要问题。一个完整的推荐系统一般存在3个参与方：用户、物品提供者和提供推荐系统的网站。以图书推荐为例，首先，推荐系统需要满足用户的需求，给用户推荐那些令他们感兴趣的图书。其次，推荐系统要让各出版社的书都能够被推荐给对其感兴趣的用户，而不是只推荐几个大型出版社的书。最后，好的推荐系统设计，能够让推荐系统本身收集到高质量的用户反馈，不断完善推荐的质量，增加用户和网站的交互，提高网站的收入。因此在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。

在推荐系统的早期研究中，很多人将好的推荐系统定义为能够作出准确预测的推荐系统。比如，一个图书推荐系统预测一个用户将来会购买《C++ Primer中文版》这本书，而用户后来确实购买了，那么这就被看做一次准确的预测。预测准确度是推荐系统领域的重要指标（没有之一）。这个指标的好处是，它可以比较容易地通过离线方式计算出来，从而方便研究人员快速评价和选择不同的推荐算法。

但是，很多研究表明，准确的预测并不代表好的推荐。比如说，该用户早就准备买《C++ Primer中文版》了，无论是否给他推荐，他都准备购买，那么这个推荐结果显然是不好的，因为它并未使用户购买更多的书，而仅仅是方便用户购买一本他本来就准备买的书。那么，对于用户来说，他会觉得这个推荐结果很不新颖，不能令他惊喜。同时，对于《C++ Primer中文版》的出版社来说，这个推荐也没能增加这本书的潜在购买人数。所以，这是一个看上去很好，但其实却很失败的推荐。举一个更极端的例子，某推测系统预测明天太阳将从东方升起，虽然预测准确率是100%，却是一种没有意义的预测。

所以，好的推荐系统不仅仅能够准确预测用户的行为，而且能够扩展用户的视野，帮助用户发现那些他们可能会感兴趣，但却不那么容易发现的东西。同时，推荐系统还要能够帮助商家将那些被埋没在长尾中的好商品介绍给可能会对它们感兴趣的用户。这也正是《长尾理论》的作者在书中不遗余力介绍推荐系统的原因。

为了全面评测推荐系统对三方利益的影响，本章将从不同角度出发，提出不同的指标。这些指标包括准确度、覆盖度、新颖度、惊喜度、信任度、透明度等。这些指标中，有些可以离线计算，有些只有在线才能计算，有些只能通过用户问卷获得。下面各节将会依次介绍这些指标的出发点、含义，以及一些指标的计算方法。

### 1.3.1 推荐系统实验方法

在介绍推荐系统的指标之前，首先看一下计算和获得这些指标的主要实验方法。在推荐系统中，主要有3种评测推荐效果的实验方法，即离线实验（offline experiment）、用户调查（user study）和在线实验（online experiment）。下面将分别介绍这3种实验方法的优缺点。

1. 离线实验

离线实验的方法一般由如下几个步骤构成：

- (1) 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；
- (2) 将数据集按照一定的规则分成训练集和测试集；
- (3) 在训练集上训练用户兴趣模型，在测试集上进行预测；
- (4) 通过事先定义的离线指标评测算法在测试集上的预测结果。

从上面的步骤可以看到，推荐系统的离线实验都是在数据集上完成的，也就是说它不需要一个实际的系统来供它实验，而只要有一个从实际系统日志中提取的数据集即可。这种实验方法的好处是不需要真实用户参与，可以直接快速地计算出来，从而方便、快速地测试大量不同的算法。

它的主要缺点是无法获得很多商业上关注的指标，如点击率、转化率等，而找到和商业指标非常相关的离线指标也是很困难的事情。表1-2简单总结了离线实验的优缺点。

表1-2 离线实验的优缺点

|优点     |缺点     |
|--------|---------|
|不需要有对实际系统的控制权|无法计算商业上关心的指标|
|不需要用户参与实验|离线实验的指标和商业指标存在差距|
|速度快，可以测试大量算法||

2. 用户调查

注意，离线实验的指标和实际的商业指标存在差距，比如预测准确率和用户满意度之间就存在很大差别，高预测准确率不等于高用户满意度。因此，如果要准确评测一个算法，需要相对比较真实的环境。最好的方法就是将算法直接上线测试，但在对算法会不会降低用户满意度不太有把握的情况下，上线测试具有较高的风险，所以在上线测试前一般需要做一次称为用户调查的测试。

用户调查需要有一些真实用户，让他们在需要测试的推荐系统上完成一些任务。在他们完成任务时，我们需要观察和记录他们的行为，并让他们回答一些问题。最后，我们需要通过分析他们的行为和答案了解测试系统的性能。

用户调查是推荐系统评测的一个重要工具，很多离线时没有办法评测的与用户主观感受有关的指标都可以通过用户调查获得。比如，如果我们想知道推荐结果是否很令用户惊喜，那我们最好直接询问用户。

但是，用户调查也有一些缺点。
- 首先，用户调查成本很高，需要用户花大量时间完成一个个任务，并回答相关的问题。有些时候，还需要花钱雇用测试用户。因此，大多数情况下很难进行大规模的用户调查，而对于参加人数较少的用户调查，得出的很多结论往往没有统计意义。因此，我们在做用户调查时，一方面要控制成本，另一方面又要保证结果的统计意义。
- 此外，测试用户也不是随便选择的。需要尽量保证测试用户的分布和真实用户的分布相同，比如男女各半，以及年龄、活跃度的分布都和真实用户分布尽量相同。
- 此外，用户调查要尽量保证是双盲实验，不要让实验人员和用户事先知道测试的目标，以免用户的回答和实验人员的测试
受主观成分的影响。

用户调查的优缺点也很明显。
它的优点是可以获得很多体现用户主观感受的指标，相对在线实验风险很低，出现错误后很容易弥补。
缺点是招募测试用户代价较大，很难组织大规模的测试用户，因此会使测试结果的统计意义不足。此外，在很多时候设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同，因而在测试环境下收集的测试指标可能在真实环境下无法重现。

3. 在线实验

在完成离线实验和必要的用户调查后，可以将推荐系统上线做AB测试，将它和旧的算法进行比较。

AB测试是一种很常用的在线评测算法的实验方法。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同组用户的各种不同的评测指标比较不同算法，比如可以统计不同组用户的点击率，通过点击率比较不同算法的性能。对AB测试感兴趣的读者可以浏览一下网站http://www.abtests.com/，该网站给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。

AB测试的优点是可以公平获得不同算法实际在线时的性能指标，包括商业上关注的指标。AB测试的缺点主要是周期比较长，必须进行长期的实验才能得到可靠的结果。因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。

其次，一个大型网站的AB测试系统的设计也是一项复杂的工程。一个大型网站的架构分前端和后端，从前端展示给用户的界面到最后端的算法，中间往往经过了很多层，这些层往往由不同的团队控制，而且都有可能做AB测试。如果为不同的层分别设计AB测试系统，那么不同的AB测试之间往往会互相干扰。比如，当我们进行一个后台推荐算法的AB测试，同时网页团队在做推荐页面的界面AB测试，最终的结果就是你不知道测试结果是自己算法的改变，还是推荐界面的改变造成的。因此，切分流量是AB测试中的关键，不同的层以及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，而不同层之间的流量应该是正交的。

图1-23是一个简单的AB测试系统。用户进入网站后，流量分配系统决定用户是否需要被进行AB测试，如果需要的话，流量分配系统会给用户打上在测试中属于什么分组的标签。然后用户浏览网页，而用户在浏览网页时的行为都会被通过日志系统发回后台的日志数据库。此时，如果用户有测试分组的标签，那么该标签也会被发回后台数据库。在后台，实验人员的工作首先是配置流量分配系统，决定满足什么条件的用户参加什么样的测试。其次，实验人员需要统计日志数据库中的数据，通过评测系统生成不同分组用户的实验报告，并比较和评测实验结果。

一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验。
- 首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。
- 然后，需要通过用户调查确定它的用户满意度不低于现有的算法。
- 最后，通过在线的AB测试确定它在我们关心的指标上优于现有的算法。

介绍完3种主要的实验方法后，下一节将开始介绍推荐系统常用的实验指标，这些指标大部分都可以通过本节介绍的3种实验方法获得。

### 1.3.2 评测指标

#### 1.用户满意度

用户作为推荐系统的重要参与者，其满意度是评测推荐系统的最重要指标。但是，用户满意度没有办法离线计算，只能通过用户调查或者在线实验获得。

#### 2.预测准确度

预测准确度度量一个推荐系统或者推荐算法预测用户行为的能力。这个指标是最重要的推荐系统离线评测指标，从推荐系统诞生的那一天起，几乎99%与推荐相关的论文都在讨论这个指标。这主要是因为该指标可以通过离线实验计算，方便了很多学术界的研究人员研究推荐算法。

在计算该指标时需要有一个离线的数据集，该数据集包含用户的历史行为记录。然后，将该数据集通过时间分成训练集和测试集。最后，通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为，并计算预测行为和测试集上实际行为的重合度作为预测准确度。

由于离线的推荐算法有不同的研究方向，因此下面将针对不同的研究方向介绍它们的预测准确度指标。

【评分预测】

很多提供推荐服务的网站都有一个让用户给物品打分的功能。那么，如果知道了用户对物品的历史评分，就可以从中习得用户的兴趣模型，并预测该用户在将来看到一个他没有评过分的物品时，会给这个物品评多少分。预测用户对物品评分的行为称为评分预测。

评分预测的预测准确度一般通过均方根误差（RMSE）和平均绝对误差（MAE）计算。对于测试集中的一个用户u和物品i，令 $r_\omega$ 是用户u对物品i的实际评分，而 $\hat{r}_\omega$ 是推荐算法给出的预测评分，那么RMSE的定义为：
$$
RMSE = \frac{\sqrt{\sum_{u,i\in T}{(r_\omega-\hat{r}_\omega)^2}}}{\vert T\vert}
$$
MAE采用绝对值计算预测误差，它的定义为：
$$
MAE = \frac{\sum_{u,i\in T}|r_\omega-\hat{r}_\omega|}{|T|}
$$
假设我们用一个列表records存放用户评分数据，令 $records[i] = [u,i,rui,pui]$，其中 rui 是用户u对物品i的实际评分，pui 是算法预测出来的用户u对物品i的评分，那么下面的代码分别实现了RMSE和MAE的计算过程。

~~~python
def RMSE(records): 
	return math.sqrt(\ 
		sum([(rui-pui)*(rui-pui) for u,i,rui,pui in records])\ 
		/ float(len(records))) 
def MAE(records): 
	return sum([abs(rui-pui) for u,i,rui,pui in records])\ 
		/ float(len(records))
~~~

关于RMSE和MAE这两个指标的优缺点， Netflix认为RMSE加大了对预测不准的用户物品评分的惩罚（平方项的惩罚），因而对系统的评测更加苛刻。研究表明，如果评分系统是基于整数建立的（即用户给的评分都是整数），那么对预测结果取整会降低MAE的误差。

【TopN推荐】

网站在提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做TopN推荐。TopN推荐的预测准确率一般通过准确率（precision）/召回率（recall）度量。

令*R*(*u*)是根据用户在训练集上的行为给用户作出的推荐列表，而*T*(*u*)是用户在测试集上的行为列表。那么，推荐结果的召回率定义为：
$$
Recall = \frac{\sum_{u\in U}|R(u)\cap T(u)|}{\sum_{u\in U}|T(u)|}
$$
推荐结果的准确率定义为：
$$
Precision = \frac{\sum_{u\in U}|R(u)\cap T(u)|}{\sum_{u\in U}|R(u)|}
$$
下面的Python代码同时计算出了一个推荐算法的准确率和召回率：

~~~python
def PrecisionRecall(test, N): 
	hit = 0 
 	n_recall = 0 
 	n_precision = 0 
 	for user, items in test.items(): 
 		rank = Recommend(user, N) 
 		hit += len(rank & items) 
 		n_recall += len(items) 
 		n_precision += N 
 	return [hit / (1.0 * n_recall), hit / (1.0 * n_precision)] 
~~~

有的时候，为了全面评测TopN推荐的准确率和召回率，一般会选取不同的推荐列表长度*N*，计算出一组准确率/召回率，然后画出准确率/召回率曲线（precision/recall curve）。

【关于评分预测和topN推荐的讨论】

评分预测一直是推荐系统研究的热点，绝大多数推荐系统的研究都是基于用户评分数据的评分预测。这主要是因为，一方面推荐系统的早期研究组GroupLens的研究主要就是基于电影评分数据MovieLens进行的，其次，Netflix大赛也主要面向评分预测问题。因而，很多研究人员都将研究精力集中在优化评分预测的RMSE上。

对此，亚马逊前科学家Greg Linden有不同的看法。2009年, 他在Communications of the ACM网站发表了一篇文章，指出电影推荐的目的是找到用户最有可能感兴趣的电影，而不是预测用户看了电影后会给电影什么样的评分。因此，TopN推荐更符合实际的应用需求。也许有一部电影用户看了之后会给很高的分数，但用户看的可能性非常小。因此，预测用户是否会看一部电影，应该比预测用户看了电影后会给它什么评分更加重要。因此，本书主要也是讨论TopN推荐。

#### 3.覆盖率

覆盖率（coverage）描述一个推荐系统对物品长尾的发掘能力。覆盖率有不同的定义方法，最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。假设系统的用户集合为*U*，推荐系统给每个用户推荐一个长度为*N*的物品列表*R*(*u*)。那么推荐系统的覆盖率可以通过下面的公式计算：
$$
Coverage = \frac{|U_{u\in U}R(u)|}{|I|}
$$
从上面的定义可以看到，覆盖率是一个内容提供商会关心的指标。以图书推荐为例，出版社可能会很关心他们的书有没有被推荐给用户。覆盖率为100%的推荐系统可以将每个物品都推荐给至少一个用户。此外，从上面的定义也可以看到，热门排行榜的推荐覆盖率是很低的，它只会推荐那些热门的物品，这些物品在总物品中占的比例很小。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。

但是上面的定义过于粗略。覆盖率为100%的系统可以有无数的物品流行度分布。为了更细致地描述推荐系统发掘长尾的能力，需要统计推荐列表中不同物品出现次数的分布。如果所有的物品都出现在推荐列表中，且出现的次数差不多，那么推荐系统发掘长尾的能力就很好。因此，可以通过研究物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力。如果这个分布比较平，那么说明推荐系统的覆盖率较高，而如果这个分布较陡峭，说明推荐系统的覆盖率较低。在信息论和经济学中有两个著名的指标可以用来定义覆盖率。第一个是信息熵：
$$
H=-\sum_{i=1}^n p(i)\log p(i)
$$
这里*p*(*i*)是物品*i*的流行度除以所有物品流行度之和。

第二个指标是基尼系数（Gini Index）：
$$
G=\frac{1}{n-1}\sum_{j=1}^n (2j-n-1)p(i_j)
$$
这里，$i_j$ 是按照物品流行度*p*()从小到大排序的物品列表中第*j*个物品。下面的代码可以用来计算给定物品流行度分布后的基尼系数：

~~~python
def GiniIndex(p): 
	j = 1
	n = len(p) 
	G = 0 
	for item, weight in sorted(p.items(), key=itemgetter(1)): 
		G += (2 * j - n - 1) * weight 
	return G / float(n - 1) 
~~~

> 基尼系数的计算原理
>
> 首先，我们将物品按照热门程度从低到高排列，那么右图中的黑色曲线表示最不热门的x%物品的总流行度占系统的比例y%。这条曲线肯定是在y=x曲线之下的，而且和y=x曲线相交在(0,0)和(1,1)。 
>
> 令SA是*A*的面积，SB是*B*的面积，那么基尼系数的形象定义就是SA / (SA + SB)，从定义可知，基尼系数属于区间[0,1]。
>
> 如果系统的流行度很平均，那么SA就会很小，从而基尼系数很小。如果系统物品流行度分配很不均匀，那么SA就会很大，从而基尼系数也会很大。

社会学领域有一个著名的马太效应，即所谓强者更强，弱者更弱的效应。如果一个系统会增大热门物品和非热门物品的流行度差距，让热门的物品更加热门，不热门的物品更加不热门，那么这个系统就有马太效应。比如，首页的热门排行榜就有马太效应。进入排行榜的都是热门的物品，但它们因为被放在首页的排行榜展示有了更多的曝光机会，所以会更加热门。相反，没有进入排行榜的物品得不到展示，就会更不热门。搜索引擎的PageRank算法也具有一定的马太效应，如果一个网页的某个热门关键词排名很高，并因此被展示在搜索结果的第一条，那么它就会获得更多的关注，从而获得更多的外链，PageRank排名也越高。

那么，推荐系统是否有马太效应呢？推荐系统的初衷是希望消除马太效应，使得各种物品都能被展示给对它们感兴趣的某一类人群。但是，很多研究表明现在主流的推荐算法（比如协同过滤算法）是具有马太效应的。评测推荐系统是否具有马太效应的简单办法就是使用基尼系数。如果*G*1是从初始用户行为中计算出的物品流行度的基尼系数，*G*2是从推荐列表中计算出的物品流行度的基尼系数，那么如果*G*2 > *G*1，就说明推荐算法具有马太效应。

#### 4.多样性

用户的兴趣是广泛的，在一个视频网站中，用户可能既喜欢看《猫和老鼠》一类的动画片，也喜欢看成龙的动作片。那么，为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。多样性推荐列表的好处用一句俗话表述就是“不在一棵树上吊死”。尽管用户的兴趣在较长的时间跨度中是一样的，但具体到用户访问推荐系统的某一刻，其兴趣往往是单一的，那么如果推荐列表只能覆盖用户的一个兴趣点，而这个兴趣点不是用户这个时刻的兴趣点，推荐列表就不会让用户满意。反之，如果推荐列表比较多样，覆盖了用户绝大多数的兴趣点，那么就会增加用户找到感兴趣物品的概率。因此给用户的推荐列表也需要满足用户广泛的兴趣，即具有多样性。

多样性描述了推荐列表中物品两两之间的不相似性。因此，多样性和相似性是对应的。假设 $s(i, j)\in[0,1]$ 定义了物品*i*和*j*之间的相似度，那么用户*u*的推荐列表*R*(*u*)的多样性定义如下：
$$
Diversity = 1-\frac{\sum_{i,j\in R(u),i\neq j}s(i,j)}{\frac{1}{2}|R(u)|(|R(u)|-1)}
$$
而推荐系统的整体多样性可以定义为所有用户推荐列表多样性的平均值：
$$
Diversity = \frac{1}{|U|}\sum_{u\in U}Diversity(R(u))
$$
从上面的定义可以看到，不同的物品相似度度量函数s(*i*, *j*)可以定义不同的多样性。如果用内容相似度描述物品间的相似度，我们就可以得到内容多样性函数，如果用协同过滤的相似度函数描述物品间的相似度，就可以得到协同过滤的多样性函数。

关于推荐系统多样性最好达到什么程度，可以通过一个简单的例子说明。假设用户喜欢动作片和动画片，且用户80%的时间在看动作片，20%的时间在看动画片。那么，可以提供4种不同的推荐列表：A列表中有10部动作片，没有动画片；B列表中有10部动画片，没有动作片；C列表中有8部动作片和2部动画片；D列表有5部动作片和5部动画片。在这个例子中，一般认为C列表是最好的，因为它具有一定的多样性，但又考虑到了用户的主要兴趣。A满足了用户的主要兴趣，但缺少多样性，D列表过于多样，没有考虑到用户的主要兴趣。B列表即没有考虑用户的主要兴趣，也没有多样性，因此是最差的。

#### 5.新颖性

新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。在一个网站中实现新颖性的最简单办法是，把那些用户之前在网站中对其有过行为的物品从推荐列表中过滤掉。比如在一个视频网站中，新颖的推荐不应该给用户推荐那些他们已经看过、打过分或者浏览过的视频。但是，有些视频可能是用户在别的网站看过，或者是在电视上看过，因此仅仅过滤掉本网站中用户有过行为的物品还不能完全实现新颖性。

O’scar Celma在博士论文“Music Recommendation and Discovery in the Long Tail” 中研究了新颖度的评测。评测新颖度的最简单方法是利用推荐结果的平均流行度，因为越不热门的物品越可能让用户觉得新颖。因此，如果推荐结果中物品的平均热门程度较低，那么推荐结果就可能有比较高的新颖性。

但是，用推荐结果的平均流行度度量新颖性比较粗略，因为不同用户不知道的东西是不同的。因此，要准确地统计新颖性需要做用户调查。

最近几年关于多样性和新颖性的研究越来越受到推荐系统研究人员的关注。ACM的推荐系统会议在2011年有一个专门的研讨会讨论推荐的多样性和新颖性。该研讨会的组织者认为，通过牺牲精度来提高多样性和新颖性是很容易的，而困难的是如何在不牺牲精度的情况下提高多样性和新颖性。关心这两个指标的读者可以关注一下这个研讨会最终发表的论文。

#### 6.惊喜度

惊喜度（serendipity）是最近这几年推荐系统领域最热门的话题。但什么是惊喜度，惊喜度与新颖性有什么区别是首先需要弄清楚的问题。注意，这里讨论的是惊喜度和新颖度作为推荐指标在意义上的区别，而不是这两个词在中文里的含义区别（因为这两个词是英文词翻译过来的，所以它们在中文里的含义区别和英文词的含义区别并不相同），所以我们首先要摒弃大脑中关于这两个词在中文中的基本含义。

可以举一个例子说明这两种指标的区别。假设一名用户喜欢周星驰的电影，然后我们给他推荐了一部叫做《临歧》的电影（该电影是1983年由刘德华、周星驰、梁朝伟合作演出的，很少有人知道这部有周星驰出演的电影），而该用户不知道这部电影，那么可以说这个推荐具有新颖性。但是，这个推荐并没有惊喜度，因为该用户一旦了解了这个电影的演员，就不会觉得特别奇怪。但如果我们给用户推荐张艺谋导演的《红高粱》，假设这名用户没有看过这部电影，那么他看完这部电影后可能会觉得很奇怪，因为这部电影和他的兴趣一点关系也没有，但如果用户看完电影后觉得这部电影很不错，那么就可以说这个推荐是让用户惊喜的。这个例子的原始版本来自于Guy Shani的论文，他的基本意思就是，如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果。

目前并没有什么公认的惊喜度指标定义方式，这里只给出一种定性的度量方式。上面提到，令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度。前面也曾提到，用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。也就是说，如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合*A*，然后给用户推荐一个不属于集合*A*的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。因此提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度。

惊喜度的问题最近几年获得了学术界的一定关注，但这方面的工作还不是很成熟。相关工作可以参考Yuan Cao Zhang等的论文和Tomoko Murakami等的论文，本书就不对该问题进一步展开讨论了。

#### 7.信任度

如果你有两个朋友，一个人你很信任，一个人经常满嘴跑火车，那么如果你信任的朋友推荐你去某个地方旅游，你很有可能听从他的推荐，但如果是那位满嘴跑火车的朋友推荐你去同样的地方旅游，你很有可能不去。这两个人可以看做两个推荐系统，尽管他们的推荐结果相同，但用户却可能产生不同的反应，这就是因为用户对他们有不同的信任度。

对于基于机器学习的自动推荐系统，同样存在信任度（trust）的问题，如果用户信任推荐系统，那就会增加用户和推荐系统的交互。特别是在电子商务推荐系统中，让用户对推荐结果产生信任是非常重要的。同样的推荐结果，以让用户信任的方式推荐给用户就更能让用户产生购买欲，而以类似广告形式的方法推荐给用户就可能很难让用户产生购买的意愿。

度量推荐系统的信任度只能通过问卷调查的方式，询问用户是否信任推荐系统的推荐结果。因为本书后面的章节不太涉及如何提高推荐系统信任度的问题，因此这里简单介绍一下如何提高用户对推荐结果的信任度，以及关于信任度的一些研究现状。

提高推荐系统的信任度主要有两种方法。首先需要增加推荐系统的透明度（transparency），而增加推荐系统透明度的主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。其次是考虑用户的社交网络信息，利用用户的好友信息给用户做推荐，并且用好友进行推荐解释。这是因为用户对他们的好友一般都比较信任，因此如果推荐的商品是好友购买过的，那么他们对推荐结果就会相对比较信任。

关于推荐系统信任度的研究主要集中在评论网站Epinion的推荐系统上。这是因为Epinion创建了一套用户之间的信任系统来建立用户之间的信任关系，帮助用户判断是否信任当前用户对某一个商品的评论。当用户在Epinion上浏览一个商品时，他会通过用户评论判断是否购买该商品。Epinion为了防止垃圾评论或者广告评论影响用户的决策，在每条用户评论的右侧都显示了评论作者的信息，并且让用户判断是信任该评论人还是将他加入黑名单。如果网站具有Epinion的用户信任系统，那么可以在给用户做推荐时，尽量推荐他信任的其他用户评论过的物品

#### 8.实时性

在很多网站中，因为物品（新闻、微博等）具有很强的时效性，所以需要在物品还具有时效性时就将它们推荐给用户。比如，给用户推荐昨天的新闻显然不如给用户推荐今天的新闻。因此，在这些网站中，推荐系统的实时性就显得至关重要。

推荐系统的实时性包括两个方面。

- 首先，推荐系统需要实时地更新推荐列表来满足用户新的行为变化。比如，当一个用户购买了iPhone，如果推荐系统能够立即给他推荐相关配件，那么肯定比第二天再给用户推荐相关配件更有价值。很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行为相应的实时性，可以通过推荐列表的变化速率来评测。如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高。
- 实时性的第二个方面是推荐系统需要能够将新加入系统的物品推荐给用户。这主要考验了推荐系统处理物品冷启动的能力。关于如何将新加入系统的物品推荐给用户，本书将在后面的章节进行讨论，而对于新物品推荐能力，我们可以利用用户推荐列表中有多大比例的物品是当天新加的来评测。

#### 9.健壮性

任何一个能带来利益的算法系统都会被人攻击，这方面最典型的例子就是搜索引擎。搜索引擎的作弊和反作弊斗争异常激烈，这是因为如果能让自己的商品成为热门搜索词的第一个搜索果，会带来极大的商业利益。推荐系统目前也遇到了同样的作弊问题，而健壮性（即robust,鲁棒性）指标衡量了一个推荐系统抗击作弊的能力。

2011年的推荐系统大会专门有一个关于推荐系统健壮性的教程。作者总结了很多作弊方法，其中最著名的就是行为注入攻击（profile injection attack）。众所周知，绝大部分推荐系统都是通过分析用户的行为实现推荐算法的。比如，亚马逊有一种推荐叫做“购买商品A的用户也经常购买的其他商品”。它的主要计算方法是统计购买商品A的用户购买其他商品的次数。那么，我们可以很简单地攻击这个算法，让自己的商品在这个推荐列表中获得比较高的排名，比如可以注册很多账号，用这些账号同时购买A和自己的商品。还有一种攻击主要针对评分系统，比如豆瓣的电影评分。这种攻击很简单，就是雇用一批人给自己的商品非常高的评分，而评分行为是推荐系统依赖的重要用户行为。

算法健壮性的评测主要利用模拟攻击。首先，给定一个数据集和一个算法，可以用这个算法给这个数据集中的用户生成推荐列表。然后，用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。最后，通过比较攻击前后推荐列表的相似度评测算法的健壮性。如果攻击后的推荐列表相对于攻击前没有发生大的变化，就说明算法比较健壮。

在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法。

- 设计推荐系统时尽量使用代价比较高的用户行为。比如，如果有用户购买行为和用户浏览行为，那么主要应该使用用户购买行为，因为购买需要付费，所以攻击购买行为的代价远远大于攻击浏览行为。
- 在使用数据前，进行攻击检测，从而对数据进行清理。

#### 10.商业目标

很多时候，网站评测推荐系统更加注重网站的商业目标是否达成，而商业目标和网站的盈利模式是息息相关的。一般来说，最本质的商业目标就是平均一个用户给公司带来的盈利。不过这种指标不是很难计算，只是计算一次需要比较大的代价。因此，很多公司会根据自己的盈利模式设计不同的商业目标。

不同的网站具有不同的商业目标。比如电子商务网站的目标可能是销售额，基于展示广告盈利的网站其商业目标可能是广告展示总数，基于点击广告盈利的网站其商业目标可能是广告点击总数。因此，设计推荐系统时需要考虑最终的商业目标，而网站使用推荐系统的目的除了满足用户发现内容的需求，也需要利用推荐系统加快实现商业上的指标。

#### 11.总结

本节提到了很多指标，其中有些指标可以离线计算，有些只能在线获得。但是，离线指标很多，在线指标也很多，那么如何优化离线指标来提高在线指标是推荐系统研究的重要问题。关于这个问题，目前仍然没有什么定论，只是不同系统的研究人员有不同的感性认识。

表1-3 获取各种评测指标的途径

|            | 离线实验 | 问卷调查 | 在线实验 |
| ---------- | -------- | -------- | -------- |
| 用户满意度 | ×        | √        | ⚪        |
| 预测准确度 | √        | √        | ×        |
| 覆盖率     | √        | √        | √        |
| 多样性     | ⚪        | √        | ⚪        |
| 新颖性     | ⚪        | √        | ⚪        |
| 惊喜度     | ×        | √        | ×        |

对于可以离线优化的指标，我个人的看法是应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。用一个数学公式表达，离线实验的优化目标是：

~~~
最大化预测准确度
使得 覆盖率 > A
	多样性 > B
	新颖性 > C
~~~

其中，*A*、*B*、*C*的取值应该视不同的应用而定。

### 1.3.3 评测维度

上一节介绍了很多评测指标，但是在评测系统中还需要考虑评测维度，比如一个推荐算法，虽然整体性能不好，但可能在某种情况下性能比较好，而增加评测维度的目的就是知道一个算法在什么情况下性能最好。这样可以为融合不同推荐算法取得最好的整体性能带来参考。

一般来说，评测维度分为如下3种。

- 用户维度 主要包括用户的人口统计学信息、活跃度以及是不是新用户等。
- 物品维度 包括物品的属性信息、流行度、平均分以及是不是新加入的物品等。
- 时间维度 包括季节，是工作日还是周末，是白天还是晚上等。

如果能够在推荐系统评测报告中包含不同维度下的系统评测指标，就能帮我们全面地了解推荐系统性能，找到一个看上去比较弱的算法的优势，发现一个看上去比较强的算法的缺点。

# 第2章 利用用户行为数据

基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法称为协同过滤算法。顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。

## 2.1 用户行为数据简介

本章提到的个性化推荐算法都是基于用户行为数据分析设计的，因此本节将首先介绍用户行为数据。

用户行为数据在网站上最简单的存在形式就是日志。网站在运行过程中都产生大量原始日志（raw log），并将其存储在文件系统中。很多互联网业务会把多种原始日志按照用户行为汇总成会话日志（session log），其中每个 会话表示一次用户行为和对应的服务。比如，在搜索引擎和搜索广告系统中，服务会为每次查询生成一个展示日志（impression log），其中记录了查询和返回结果。如果用户点击了某个结果，这个点击信息会被服务器截获并存储在点击日志（click log）中。一个并行程序会周期性地归并展示日志和点击日志，得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。类似地，推荐系统和电子商务网站也会汇总原始日志生成描述用户行为的会话日志。会话日志通常存储在分布式数据仓库中，如支持离线分析的 Hadoop Hive和支持在线分析的Google Dremel。这些日志记录了用户的各种行为，如在电子商务网站中这些行为主要包括网页浏览、购买、点击、评分和评论等。

用户行为在个性化推荐系统中一般分两种——显性反馈行为（explicit feedback）和隐性反馈行为（implicit feedback）。显性反馈行为包括用户明确表示对物品喜好的行为。图2-2显示了不同网站收集显性反馈的方式。可以看到，这里的主要方式就是评分和喜欢/不喜欢。很多网站都使用了5分的评分系统来让用户直接表达对物品的喜好，但也有些网站使用简单的“喜欢”或者“不喜欢”按钮收集用户的兴趣。这些不同的显性反馈方式各有利弊。YouTube最早是用5分评分系统收集显性反馈的，但后来他们的研究人员统计了不同评分的评分数，结果发现，用户最常用的评分是5分，其次是1分，其他的分数很少有用户打。因此，后来YouTube就把评分系统改成了两档评分系统（喜欢/不喜欢）。当然，我们举这个例子并不是试图说明一种评分系统比另一种好，而是要说明不同的网站需要根据自己的特点设计评分系统，而不是一味照搬其他网站的设计。YouTube的用户主要将精力放在看视频上，因此他们只有在特别不满或者特别满意时才会评分，因此二级评分系统就足够了。但如果是评论网站，用户主要将精力放在评论上，这时多级评分系统就是必要的。

和显性反馈行为相对应的是隐性反馈行为。隐性反馈行为指的是那些不能明确反应用户喜好的行为。最具代表性的隐性反馈行为就是页面浏览行为。用户浏览一个物品的页面并不代表用户一定喜欢这个页面展示的物品，比如可能因为这个页面链接显示在首页，用户更容易点击它而已。相比显性反馈，隐性反馈虽然不明确，但数据量更大。在很多网站中，很多用户甚至只有隐性反馈数据，而没有显性反馈数据。表2-1从几个不同方面比较了显性反馈数据和隐性反馈数据。

表2-1 显性反馈数据和隐性反馈数据的比较

|       |显性反馈数据|隐性反馈数据  |
|-------|----------|------------|
|用户兴趣 |明确      |不明确       |
|数量    |较少      |庞大         |
|存储    |数据库     |分布式文件系统|
|实时读取 |实时      |有延迟       |
|正负反馈 |都有      |只有正反馈    |

按照反馈的明确性分，用户行为数据可以分为显性反馈和隐性反馈，但按照反馈的方向分，又可以分为正反馈和负反馈。正反馈指用户的行为倾向于指用户喜欢该物品，而负反馈指用户的行为倾向于指用户不喜欢该物品。在显性反馈中，很容易区分一个用户行为是正反馈还是负反馈，而在隐性反馈行为中，就相对比较难以确定。

为了更好地说明什么数据是显性反馈数据，什么是隐性反馈数据，表2-2列举了各个领域的网站中这两种行为的例子。

表2-2 各代表网站中显性反馈数据和隐性反馈数据的例子

|          |显性反馈           |隐性反馈                        |
|----------|-----------------|-------------------------------|
|视频网站    |用户对视频的评分    |用户观看视频的日志、浏览视频页面的日志|
|电子商务网站 |用户对商品的评分    |购买日志、浏览日志                |
|门户网站    |用户对新闻的评分    |阅读新闻的日志                   |
|音乐网站    |用户对音乐/歌手/专辑的评分|听歌的日志                  |

互联网中的用户行为有很多种，比如浏览网页、购买商品、评论、评分等。要用一个统一的方式表示所有这些行为是比较困难的。表2-3给出了一种表示方式，它将一个用户行为表示为6部分，即产生行为的用户和行为的对象、行为的种类、产生行为的上下文、行为的内容和权重。

表2-3 用户行为的统一表示

- user id 产生行为的用户的唯一标识
- item id 产生行为的对象的唯一标识
- behavior type 行为的种类（比如是购买还是浏览）
- context 产生行为的上下文，包括时间和地点等
- behavior weight 行为的权重（如果是观看视频的行为，那么这个权重可以是观看时长；如果是打分行为，这个权重可以是分数）
- behavior content 行为的内容（如果是评论行为，那么就是评论的文本；如果是打标签的行为，就是标签）

当然，在很多时候我们并不使用统一结构表示所有行为，而是针对不同的行为给出不同表示。而且，有些时候可能会忽略一些信息（比如上下文）。当然，有些信息是不能忽略的，比如产生行为的用户和行为的对象就是所有行为都必须包含的。一般来说，不同的数据集包含不同的行为，目前比较有代表性的数据集有下面几个。

- **无上下文信息的隐性反馈数据集** 每一条行为记录仅仅包含用户ID和物品ID。Book-Crossing就是这种类型的数据集。
- **无上下文信息的显性反馈数据集** 每一条记录包含用户ID、物品ID和用户对物品的评分。
- **有上下文信息的隐性反馈数据集** 每一条记录包含用户ID、物品ID和用户对物品产生行为的时间戳。Lastfm数据集就是这种类型的数据集。
- **有上下文信息的显性反馈数据集** 每一条记录包含用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳。Netflix Prize提供的就是这种类型的数据集。

本章使用的数据集基本都是第一种数据集，即无上下文信息的隐性反馈数据集。

## 2.2 用户行为分析

### 2.2.1 用户活跃度和物品流行度的分布

很多关于互联网数据的研究发现，互联网上的很多数据分布都满足一种称为Power Law的分布，这个分布在互联网领域也称长尾分布。
$$
f(x)=\alpha x^k
$$

长尾分布其实很早就被统计学家注意到了。1932年，哈佛大学的语言学家Zipf在研究英文单词的词频时发现，如果将单词出现的频率按照由高到低排列，则每个单词出现的频率和它在热门排行榜中排名的常数次幂成反比。这个分布称为Zipf定律。这个现象表明，在英文中大部分词的词频其实很低，只有很少的词被经常使用。

很多研究人员发现，用户行为数据也蕴含着这种规律。令 $f_u(k)$为对*k*个物品产生过行为的用户数，令 $f_i(k)$ 为被*k*个用户产生过行为的物品数。那么，和$f_u(k)$ 和 $f_i(k)$ 都满足长尾分布。也就是说：
$$
f_i(k)=\alpha_i k^{\beta_i}\\
f_u(k)=\alpha_u k^{\beta_u}
$$

### 2.2.2 用户活跃度和物品流行度的关系

一般来说，不活跃的用户要么是新用户，要么是只来过网站一两次的老用户。那么，不同活跃度的用户喜欢的物品的流行度是否有差别？一般认为，新用户倾向于浏览热门的物品，因为他们对网站还不熟悉，只能点击首页的热门物品，而老用户会逐渐开始浏览冷门的物品。

仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法。学术界对协同过滤算法进行了深入研究，提出了很多方法，比如基于邻域的方法（neighborhood-based）、隐语义模型（latent factor model）、基于图的随机游走算法（random walk on graph）等。在这些方法中，最著名的、在业界得到最广泛应用的算法是基于邻域的方法，而基于邻域的方法主要包含下面两种算法。

- 基于用户的协同过滤算法 这种算法给用户推荐和他兴趣相似的其他用户喜欢的物品。
- 基于物品的协同过滤算法 这种算法给用户推荐和他之前喜欢的物品相似的物品。

下面几节将首先介绍上面两种算法，然后再简单介绍隐语义模型和基于图的模型。

## 2.3 实验设计和算法评测

前文说过，评测推荐系统有3种方法——离线实验、用户调查和在线实验。本节将通过离线实验方法评测提到的算法。首先介绍用到的数据集，然后介绍采用的实验方法和评测指标。

### 2.3.1 数据集

本章采用GroupLens提供的MovieLens数据集介绍和评测各种算法。 MovieLens数据集有3个不同的版本，本章选用中等大小的数据集。该数据集包含6000多用户对4000多部电影的100万条评分。该数据集是一个评分数据集，用户可以给电影评5个不同等级的分数（1～5分）。本章着重研究隐反馈数据集中的TopN推荐问题，因此忽略了数据集中的评分记录。也就是说，TopN推荐的任务是预测用户会不会对某部电影评分，而不是预测用户在准备对某部电影评分的前提下会给电影评多少分。

### 2.3.2 实验设计

协同过滤算法的离线实验一般如下设计。首先，将用户行为数据集按照均匀分布随机分成M份（本章取M=8），挑选一份作为测试集，将剩下的M-1份作为训练集。然后在训练集上建立用户兴趣模型，并在测试集上对用户行为进行预测，统计出相应的评测指标。为了保证评测指标并不是过拟合的结果，需要进行M次实验，并且每次都使用不同的测试集。然后将M次实验测出的评测指标的平均值作为最终的评测指标。

下面的Python代码描述了将数据集随机分成训练集和测试集的过程：
~~~python
def SplitData(data, M, k, seed): 
	test = [] 
 	train = [] 
 	random.seed(seed) 
 	for user, item in data: 
 		if random.randint(0,M) == k: 
 			test.append([user,item]) 
 		else: 
 			train.append([user,item]) 
 	return train, test
~~~

这里，每次实验选取不同的*k*（0≤*k*≤*M*-1）和相同的随机数种子seed，进行*M*次实验就可以得到*M*个不同的训练集和测试集，然后分别进行实验，用*M*次实验的平均值作为最后的评测指标。这样做主要是防止某次实验的结果是过拟合的结果（over fitting），但如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次实验。

### 2.3.3 评测指标

对用户*u*推荐*N*个物品（记为*R*(*u*)），令用户*u*在测试集上喜欢的物品集合为*T*(*u*)，然后可以通过准确率/召回率评测推荐算法的精度：
$$
Recall = \frac{\sum_u|R(u)\cap T(u)|}{\sum_u|T(u)|}\\
Precision = \frac{\sum_{u}|R(u)\cap T(u)|}{\sum_{u}|R(u)|}
$$
召回率描述有多少比例的用户—物品评分记录包含在最终的推荐列表中，而准确率描述最终的推荐列表中有多少比例是发生过的用户—物品评分记录。下面两段代码给出了召回率和准确率的计算方法。

~~~python
def Recall(train, test, N): 
 	hit = 0 
 	all = 0 
 	for user in train.keys(): 
 		tu = test[user] 
 		rank = GetRecommendation(user, N) 
 		for item, pui in rank: 
 			if item in tu: 
 				hit += 1 
 			all += len(tu) 
 	return hit / (all * 1.0) 
def Precision(train, test, N): 
 	hit = 0 
 	all = 0 
 	for user in train.keys(): 
 		tu = test[user] 
 		rank = GetRecommendation(user, N) 
 		for item, pui in rank: 
 			if item in tu: 
 				hit += 1 
 		all += N 
 	return hit / (all * 1.0)
~~~

除了评测推荐算法的精度，本章还计算了算法的覆盖率，覆盖率反映了推荐算法发掘长尾的能力，覆盖率越高，说明推荐算法越能够将长尾中的物品推荐给用户。这里，我们采用最简单的覆盖率定义：
$$
Coverage=\frac{\cup_{u\in U}|R(u)|}{|I|}
$$
该覆盖率表示最终的推荐列表中包含多大比例的物品。如果所有的物品都被推荐给至少一个用户，那么覆盖率就是100%。如下代码可以用来计算推荐算法的覆盖率：

~~~python
def Coverage(train, test, N): 
 	recommend_items = set() 
 	all_items = set() 
 	for user in train.keys(): 
 		for item in train[user].keys(): 
 			all_items.add(item) 
 		rank = GetRecommendation(user, N) 
 		for item, pui in rank: 
 			recommend_items.add(item) 
 	return len(recommend_items) / (len(all_items) * 1.0) 
~~~

最后，我们还需要评测推荐的新颖度，这里用推荐列表中物品的平均流行度度量推荐结果的新颖度。如果推荐出的物品都很热门，说明推荐的新颖度较低，否则说明推荐结果比较新颖。

~~~python
def Popularity(train, test, N): 
 	item_popularity = dict() 
 	for user, items in train.items(): 
 		for item in items.keys() 
 			if item not in item_popularity: 
 				item_popularity[item] = 0 
 			item_popularity[item] += 1 
 	ret = 0 
 	n = 0 
 	for user in train.keys(): 
 		rank = GetRecommendation(user, N) 
 		for item, pui in rank: 
 			ret += math.log(1 + item_popularity[item]) 
 			n += 1 
 	ret /= n * 1.0 
 	return ret
~~~

这里，在计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度分布满足长尾分布，在取对数后，流行度的平均值更加稳定。

## 2.4 基于邻域的算法

基于邻域的算法是推荐系统中最基本的算法，该算法不仅在学术界得到了深入研究，而且在业界得到了广泛应用。

基于邻域的算法分为两大类

- 一类是基于用户的协同过滤算法，
- 另一类是基于物品的协同过滤算法。

### 2.4.1 基于用户的协同过滤算法

基于用户的协同过滤算法是推荐系统中最古老的算法。可以不夸张地说，这个算法的诞生标志了推荐系统的诞生。该算法在1992年被提出，并应用于邮件过滤系统，1994年被GroupLens用于新闻过滤。在此之后直到2000年，该算法都是推荐系统领域最著名的算法。

#### 1. 基础算法

那么，在一个在线个性化推荐系统中，当一个用户A需要个性化推荐时，可以先找到和他有相似兴趣的其他用户，然后把那些用户喜欢的、而用户A没有听说过的物品推荐给A。这种方法称为基于用户的协同过滤算法。

从上面的描述中可以看到，基于用户的协同过滤算法主要包括两个步骤。

(1) 找到和目标用户兴趣相似的用户集合。

(2) 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。

步骤(1)的关键就是计算两个用户的兴趣相似度。这里，协同过滤算法主要利用行为的相似度计算兴趣的相似度。给定用户u和用户v，令*N*(*u*)表示用户u曾经有过正反馈的物品集合，令*N*(*v*)为用户v曾经有过正反馈的物品集合。那么，我们可以通过如下的Jaccard公式简单地计算u和v的兴趣相似度：
$$
w_{uv}=\frac{|N(u)|\cap|N(v)|}{|N(u)|\cup|N(v)|}
$$
或者通过余弦相似度计算：
$$
w_{uv}=\frac{|N(u)\cap N(v)|}{\sqrt{|N(u)||N(v)|}}
$$
以余弦相似度为例，实现该相似度可以利用如下的伪码

~~~python
def UserSimilarity(train): 
 	W = dict() 
 	for u in train.keys():
        for v in train.keys(): 
 			if u == v: 
 				continue 
 			W[u][v] = len(train[u] & train[v]) 
 			W[u][v] /= math.sqrt(len(train[u]) * len(train[v]) * 1.0) 
 	return W
~~~

该代码对两两用户都利用余弦相似度计算相似度。这种方法的时间复杂度是 $O(|U|*|U|)$，这在用户数很大时非常耗时。事实上，很多用户相互之间并没有对同样的物品产生过行为，即很多时候 $|N(u)\cap N(v)|=0$ 。上面的算法将很多时间浪费在了计算这种用户之间的相似度上。如果换一个思路，我们可以首先计算出 $|N(u)\cap N(v)|\ne 0$ 的用户对(*u*,*v*)，然后再对这种情况除以分母 $\sqrt{|N(u)||N(v)|}$ 。

为此，可以首先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户列表。令稀疏矩阵 $C[u][v]=|N(u)\cap N(v)|$ 。那么，假设用户u和用户v同时属于倒排表中*K*个物品对应的用户列表，就有 $C[u][v]=K$ 。从而，可以扫描倒排表中每个物品对应的用户列表，将用户列表中的两两用户对应的 $C[u][v]$ 加1，最终就可以得到所有用户之间不为0的 $C[u][v]$ 。下面的代码实现了上面提到的算法： 

~~~python
def UserSimilarity(train): 
 	# build inverse table for item_users 
 	item_users = dict() 
 	for u, items in train.items(): 
 		for i in items.keys(): 
 			if i not in item_users: 
 				item_users[i] = set() 
 			item_users[i].add(u) 
 
 	#calculate co-rated items between users 
 	C = dict() 
 	N = dict() 
 	for i, users in item_users.items(): 
 		for u in users: 
 			N[u] += 1 
 			for v in users: 
 				if u == v: 
 					continue 
 				C[u][v] += 1 
 	
    #calculate finial similarity matrix W 
 	W = dict() 
 	for u, related_users in C.items(): 
 		for v, cuv in related_users.items(): 
 			W[u][v] = cuv / math.sqrt(N[u] * N[v]) 
 	return W
~~~

同样以图2-6中的用户行为为例解释上面的算法。首先，需要建立物品—用户的倒排表（如图2-7所示）。然后，建立一个4×4的用户相似度矩阵*W*，对于物品a，将$W[A][B]$ 和 $W[B][A]$ 加1，对于物品b，将 $W[A][C]$ 和 $W[C][A]$ 加1，以此类推。扫描完所有物品后，我们可以得到最终的*W*矩阵。这里的*W*是余弦相似度中的分子部分，然后将*W*除以分母可以得到最终的用户兴趣相似度。

图2-7 物品-用户倒排表

~~~
A:	a	b	d		a:	A	B
B:	a	c			b:	A	C
C:	b	e		-->	c:	B	D
D:	c	d	e		d:	A	D
					e:	C	D
	A	B	C	D
A	0	1	1	1
B	1	0	0	1
C	1	0	0	1
D	1	1	1	0
~~~

得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的*K*个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品*i*的感兴趣程度：
$$
p(u,i)=\sum_{v\in S(u,K)\cap N(i)}w_{uv}r_{vi}
$$
其中，*S*(*u*, *K*)包含和用户u兴趣最接近的*K*个用户，*N*(*i*)是对物品*i*有过行为的用户集合，$w_{uv}$ 是用户u和用户v的兴趣相似度，$r_{vi}$ 代表用户v对物品i的兴趣，因为使用的是单一行为的隐反馈数据，所以所有的 $r_{vi}=1$。

如下代码实现了上面的UserCF推荐算法：

~~~python
def Recommend(user, train, W): 
 	rank = dict() 
 	interacted_items = train[user] 
 	for v, wuv in sorted(W[u].items, key=itemgetter(1), \ 
 		reverse=True)[0:K]: 
 		for i, rvi in train[v].items: 
 			if i in interacted_items: 
 				#we should filter items user interacted before 
 				continue 
 			rank[i] += wuv * rvi 
 	return rank
~~~

利用上述算法，可以给图2-7中的用户A进行推荐。选取K=3，用户A对物品c、e没有过行为，因此可以把这两个物品推荐给用户A。根据UserCF算法，用户A对物品c、e的兴趣是：
$$
p(A,c)=w_{AB}+w_{AD}=0.7416\\
p(A,e)=w_{AC}+w_{AD}=0.7416
$$
表2-4通过MovieLens数据集上的离线实验来评测基础算法的性能。UserCF只有一个重要的参数*K*，即为每个用户选出*K*个和他兴趣最相似的用户，然后推荐那*K*个用户感兴趣的物品。因此离线实验测量了不同*K*值下UserCF算法的性能指标。

表2-4 MovieLens数据集中UserCF算法在不同K参数下的性能

| K    | 准确率 | 召回率 | 覆盖率 | 流行度   |
| ---- | ------ | ------ | ------ | -------- |
| 5    | 16.99% | 8.21%  | 51.33% | 6.813293 |
| 10   | 20.59% | 9.95%  | 41.49% | 6.978854 |
| 20   | 22.99% | 11.11% | 33.17% | 7.10162  |
| 40   | 24.50% | 11.83% | 25.87% | 7.203149 |
| 80   | 25.20% | 12.17% | 20.29% | 7.289817 |
| 160  | 24.90% | 12.03% | 15.21% | 7.369063 |

为了反映该数据集上离线算法的基本性能，表2-5给出了两种基本推荐算法的性能。表中，Random算法每次都随机挑选10个用户没有产生过行为的物品推荐给当前用户，MostPopular算法则按照物品的流行度给用户推荐他没有产生过行为的物品中最热门的10个物品。这两种算法都是非个性化的推荐算法，但它们代表了两个极端。如表2-5所示，MostPopular算法的准确率和召回率远远高于Random算法，但它的覆盖率非常低，结果都非常热门。可见，Random算法的准确率和召回率很低，但覆盖度很高，结果平均流行度很低。

表2-5 两种基础算法在MovieLens数据集下的性能

|             | 准确率 | 召回率 | 覆盖率 | 流行度 |
| ----------- | ------ | ------ | ------ | ------ |
| Random      | 0.631% | 0.305% | 100%   | 4.3855 |
| MostPopular | 12.79% | 6.18%  | 2.60%  | 7.7244 |

如表2-4和表2-5所示，UserCF的准确率和召回率相对MostPopular算法提高了将近1倍。同时，UserCF的覆盖率远远高于MostPopular，推荐结果相对MostPopular不太热门。同时可以发现参数*K* 是UserCF的一个重要参数，它的调整对推荐算法的各种指标都会产生一定的影响。

- **准确率和召回率** 可以看到，推荐系统的精度指标（准确率和召回率）并不和参数*K*成线性关系。在MovieLens数据集中，选择*K*=80左右会获得比较高的准确率和召回率。因此选择合适的*K*对于获得高的推荐系统精度比较重要。当然，推荐结果的精度对*K*也不是特别敏感，只要选在一定的区域内，就可以获得不错的精度。
- **流行度** 可以看到，在3个数据集上*K*越大则UserCF推荐结果就越热门。这是因为*K*决定了UserCF在给你做推荐时参考多少和你兴趣相似的其他用户的兴趣，那么如果*K*越大，参考的人越多，结果就越来越趋近于全局热门的物品。
- **覆盖率** 可以看到，在3个数据集上，*K*越大则UserCF推荐结果的覆盖率越低。覆盖率的降低是因为流行度的增加，随着流行度增加，UserCF越来越倾向于推荐热门的物品，从而对长尾物品的推荐越来越少，因此造成了覆盖率的降低。

#### 2. 用户相似度计算的改进

上一节介绍了计算用户兴趣相似度的最简单的公式（余弦相似度公式），但这个公式过于粗糙，本节将讨论如何改进该公式来提高UserCF的推荐性能。

首先，以图书为例，如果两个用户都曾经买过《新华字典》，这丝毫不能说明他们兴趣相似，因为绝大多数中国人小时候都买过《新华字典》。但如果两个用户都买过《数据挖掘导论》，那可以认为他们的兴趣比较相似，因为只有研究数据挖掘的人才会买这本书。换句话说，两个用户对冷门物品采取过同样的行为更能说明他们兴趣的相似度。因此，John S. Breese在论文中提出了如下公式，根据用户行为计算用户的兴趣相似度：
$$
w_{uv}=\frac{\sum_{i\in N(u)\cap N(v)}\frac{1}{\log1+|N(i)|}}{\sqrt{|N(u)||N(v)|}}
$$
可以看到，该公式通过 $\frac{1}{\log1+|N(i)|}$ 惩罚了用户*u*和用户*v*共同兴趣列表中热门物品对他们相似度的影响。

本书将基于上述用户相似度公式的UserCF算法记为User-IIF算法。下面的代码实现了上述用户相似度公式。

~~~python
def UserSimilarity(train): 
 	# build inverse table for item_users 
 	item_users = dict() 
 	for u, items in train.items(): 
 		for i in items.keys(): 
 			if i not in item_users: 
 				item_users[i] = set() 
 			item_users[i].add(u) 
 
 	#calculate co-rated items between users 
 	C = dict() 
 	N = dict() 
 	for i, users in item_users.items(): 
 		for u in users: 
 			N[u] += 1 
 			for v in users: 
 				if u == v: 
 					continue 
 				C[u][v] += 1 / math.log(1 + len(users)) 
 
	#calculate finial similarity matrix W 
 	W = dict() 
 	for u, related_users in C.items(): 
 		for v, cuv in related_users.items(): 
 			W[u][v] = cuv / math.sqrt(N[u] * N[v]) 
 	return W
~~~

同样，本节将通过实验评测UserCF-IIF的推荐性能，并将其和UserCF进行对比。在上一节的实验中，*K*=80时UserCF的性能最好，因此这里的实验同样选取*K*=80。

如表2-6所示，UserCF-IIF在各项性能上略优于UserCF。这说明在计算用户兴趣相似度时考虑物品的流行度对提升推荐结果的质量确实有帮助。

表2-6 MovieLens数据集中UserCF算法和User-IIF算法的对比

|            | 准确率 | 召回率 | 覆盖率 | 流行度   |
| ---------- | ------ | ------ | ------ | -------- |
| UserCF     | 25.20% | 12.17% | 20.29% | 7.289817 |
| UserCF-IIF | 25.34% | 12.24% | 21.29% | 7.261551 |

#### 3. 实际在线系统使用UserCF的例子

相比我们后面要讨论的基于物品的协同过滤算法（ItemCF）， UserCF在目前的实际应用中使用并不多。其中最著名的使用者是Digg，它在2008年对推荐系统进行了新的尝试

### 2.4.2 基于物品的协同过滤算法

基于物品的协同过滤（item-based collaborative filtering）算法是目前业界应用最多的算法。无论是亚马逊网，还是Netflix、Hulu、YouTube，其推荐算法的基础都是该算法。本节将从基础的算法开始介绍，然后提出算法的改进方法，并通过实际数据集评测该算法。

#### 1. 基础算法

基于用户的协同过滤算法在一些网站（如Digg）中得到了应用，但该算法有一些缺点。

- 首先，随着网站的用户数目越来越大，计算用户兴趣相似度矩阵将越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似于平方关系。

- 其次，基于用户的协同过滤很难对推荐结果作出解释。

因此，著名的电子商务公司亚马逊提出了另一个算法——基于物品的协同过滤算法。

基于物品的协同过滤算法（简称ItemCF）给用户推荐那些和他们之前喜欢的物品相似的物品。

基于物品的协同过滤算法可以利用用户的历史行为给推荐结果提供推荐解释，比如给用户推荐《天龙八部》的解释可以是因为用户之前喜欢《射雕英雄传》。

基于物品的协同过滤算法主要分为两步。

- (1) 计算物品之间的相似度。

- (2) 根据物品的相似度和用户的历史行为给用户生成推荐列表。

图2-9上亚马逊显示相关物品推荐时的标题是“Customers Who Bought This Item Also Bought”（购买了该商品的用户也经常购买的其他商品）。从这句话的定义出发，我们可以用下面的公式定义物品的相似度：
$$
w_{ij}=\frac{|N(i)\cap N(j)|}{|N(i)|}
$$
这里，分母|*N*(*i*)|是喜欢物品*i*的用户数，而分子 $|N(i)\cap N(j)|$ 是同时喜欢物品i和物品j的用户数。因此，上述公式可以理解为喜欢物品i的用户中有多少比例的用户也喜欢物品j。

上述公式虽然看起来很有道理，但是却存在一个问题。如果物品j很热门，很多人都喜欢，那么 $W_{ij}$ 就会很大，接近1。因此，该公式会造成任何物品都会和热门的物品有很大的相似度，这对于致力于挖掘长尾信息的推荐系统来说显然不是一个好的特性。为了避免推荐出热门的物品，可以用下面的公式：
$$
w_{ij}=\frac{|N(i)\cap N(j)|}{\sqrt{|N(i)||N(j)|}}
$$
这个公式惩罚了物品j的权重，因此减轻了热门物品会和很多物品相似的可能性。 

从上面的定义可以看到，在协同过滤中两个物品产生相似度是因为它们共同被很多用户喜欢，也就是说每个用户都可以通过他们的历史兴趣列表给物品“贡献”相似度。这里面蕴涵着一个假设，就是每个用户的兴趣都局限在某几个方面，因此如果两个物品属于一个用户的兴趣列表，那么这两个物品可能就属于有限的几个领域，而如果两个物品属于很多用户的兴趣列表，那么它们就可能属于同一个领域，因而有很大的相似度。

和UserCF算法类似，用ItemCF算法计算物品相似度时也可以首先建立用户—物品倒排表（即对每个用户建立一个包含他喜欢的物品的列表），然后对于每个用户，将他物品列表中的物品两两在共现矩阵*C*中加1。详细代码如下所示：

~~~python
def ItemSimilarity(train): 
 	#calculate co-rated users between items 
 	C = dict() 
 	N = dict() 
 	for u, items in train.items(): 
 		for i in users: 
 			N[i] += 1 
 			for j in users: 
 				if i == j: 
 					continue 
 				C[i][j] += 1 
 	#calculate finial similarity matrix W 
 	W = dict() 
 	for i,related_items in C.items(): 
 		for j, cij in related_items.items(): 
 			W[u][v] = cij / math.sqrt(N[i] * N[j]) 
 	return W
~~~

图2-11是一个根据上面的程序计算物品相似度的简单例子。图中最左边是输入的用户行为记录，每一行代表一个用户感兴趣的物品集合。然后，对于每个物品集合，我们将里面的物品两两加一，得到一个矩阵。最终将这些矩阵相加得到上面的*C*矩阵。其中 $C[i][j]$ 记录了同时喜欢物品i和物品j的用户数。最后，将*C*矩阵归一化可以得到物品之间的余弦相似度矩阵*W*。 

图2-11 一个计算物品相似度的简单例子

~~~
a,b,d	-->	  a b c d e
			a   1   1
			b 1
			c			-----
			d 1				|
			e				|
b,c,e	-->   a b c d e		|
			a				|
			b     1   1		|
			c   1		----|
			d				|
			e   1			|
c,d		-->   a b c d e		|		  a b c d e
			a				|		a   1   2
			b				|		b 1   2 1 1
			c       1	----|--->	c   2   2
			d     1			|		d 2 1 2
			e				|		e   1
b,c,d	-->   a b c d e		|
			a				|
			b     1 1		|
			c   1   1	----|
			d   1 1			|
			e				|
a,d		-->   a b c d e		|
			a       1		|
			b				|
			c			-----
			d 1
			e
~~~

表2-7展示了在MovieLens数据集上利用上面的程序计算电影之间相似度的结果。如表中结果所示，尽管在计算过程中没有利用任何内容属性，但利用ItemCF计算的结果却是可以从内容上看出某种相似度的。一般来说，同系列的电影、同主角的电影、同风格的电影、同国家和地区的电影会有比较大的相似度。

在得到物品之间的相似度后，ItemCF通过如下公式计算用户u对一个物品j的兴趣：
$$
p_{uj} = \sum_{i\in N(u)\cap S(j,K)} w_{ji}r_{ui}
$$
这里*N*(*u*)是用户喜欢的物品的集合，*S*(*j*,*K*)是和物品*j*最相似的*K*个物品的集合，$w_{ji}$ 是物品j和i的相似度，$r_{ui}$ 是用户u对物品i的兴趣。（对于隐反馈数据集，如果用户u对物品i有过行为，即可令 $r_{ui}=1$ 。）该公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。该公式的实现代码如下所示。

~~~python
def Recommendation(train, user_id, W, K): 
 	rank = dict() 
 	ru = train[user_id] 
 	for i,pi in ru.items(): 
 		for j, wj in sorted(W[i].items(), key=itemgetter(1), reverse=True)[0:K]: 
 			if j in ru: 
 				continue 
 			rank[j] += pi * wj 
 	return rank
~~~

ItemCF的一个优势就是可以提供推荐解释，即利用用户历史上喜欢的物品为现在的推荐结果进行解释。如下代码实现了带解释的ItemCF算法：

~~~python
def Recommendation(train, user_id, W, K): 
 	rank = dict() 
 	ru = train[user_id] 
 	for i,pi in ru.items(): 
 		for j, wj in sorted(W[i].items(), key=itemgetter(1), reverse=True)[0:K]: 
 			if j in ru: 
 				continue 
 			rank[j].weight += pi * wj 
 			rank[j].reason[i] = pi * wj 
 	return rank
~~~

表2-8列出了在MovieLens数据集上ItemCF算法离线实验的各项性能指标的评测结果。该表包括算法在不同*K*值下的性能。根据表2-8中的数据我们可以得出如下结论。

- **精度（准确率和召回率）** 可以看到ItemCF推荐结果的精度也是不和*K*成正相关或者负相关的，因此选择合适的*K*对获得最高精度是非常重要的。
- **流行度** 和UserCF不同，参数*K*对ItemCF推荐结果流行度的影响也不是完全正相关的。随着*K*的增加，结果流行度会逐渐提高，但当*K*增加到一定程度，流行度就不会再有明显变化。
- **覆盖率** *K*增加会降低系统的覆盖率。

表2-8 MovieLens数据集中ItemCF算法离线实验的结果

| K    | 准确率 | 召回率 | 覆盖率 | 流行度   |
| ---- | ------ | ------ | ------ | -------- |
| 5    | 21.47% | 10.37% | 21.74% | 7.172411 |
| 10   | 22.28% | 10.76% | 18.84% | 7.254526 |
| 20   | 22.24% | 10.74% | 16.93% | 7.338615 |
| 40   | 21.68% | 10.47% | 15.31% | 7.391163 |
| 80   | 20.64% | 9.97%  | 13.64% | 7.413358 |
| 160  | 19.37% | 9.36%  | 11.77% | 7.385278 |

#### 2. 用户活跃度对物品相似度的影响

从前面的讨论可以看到，在协同过滤中两个物品产生相似度是因为它们共同出现在很多用户的兴趣列表中。换句话说，每个用户的兴趣列表都对物品的相似度产生贡献。那么，是不是每个用户的贡献都相同呢？

假设有这么一个用户，他是开书店的，并且买了当当网上80%的书准备用来自己卖。那么，他的购物车里包含当当网80%的书。假设当当网有100万本书，也就是说他买了80万本。从前面对ItemCF的讨论可以看到，这意味着因为存在这么一个用户，有80万本书两两之间就产生了相似度，也就是说，内存里即将诞生一个80万乘80万的稠密矩阵。

另外可以看到，这个用户虽然活跃，但是买这些书并非都是出于自身的兴趣，而且这些书覆盖了当当网图书的很多领域，所以这个用户对于他所购买书的两两相似度的贡献应该远远小于一个只买了十几本自己喜欢的书的文学青年。

John S. Breese在论文①中提出了一个称为IUF（Inverse User Frequence），即用户活跃度对数的倒数的参数，他也认为活跃用户对物品相似度的贡献应该小于不活跃的用户，他提出应该增加IUF参数来修正物品相似度的计算公式：
$$
w_{ij}=\frac{\sum_{u\in N(i)\cap N(j)}\frac{1}{\log 1+|N(u)|}}{\sqrt{|N(i)||N(j)|}}
$$
当然，上面的公式只是对活跃用户做了一种软性的惩罚，但对于很多过于活跃的用户，比如上面那位买了当当网80%图书的用户，为了避免相似度矩阵过于稠密，我们在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中。

~~~python
def ItemSimilarity(train): 
 	#calculate co-rated users between items 
 	C = dict() 
 	N = dict() 
 	for u, items in train.items(): 
 		for i in users: 
 			N[i] += 1 
 			for j in users: 
 				if i == j: 
 					continue 
 				C[i][j] += 1 / math.log(1 + len(items) * 1.0) 
 	#calculate finial similarity matrix W 
 	W = dict() 
 	for i,related_items in C.items(): 
 		for j, cij in related_items.items(): 
 			W[u][v] = cij / math.sqrt(N[i] * N[j]) 
	return W
~~~

本书将上面的算法记为ItemCF-IUF，下面我们用离线实验评测这个算法。在这里我们不再考虑参数*K*的影响，而是将*K*选为在前面实验中取得最优准确率和召回率的值10。

如表2-9所示，ItemCF-IUF在准确率和召回率两个指标上和ItemCF相近，但ItemCF-IUF明显提高了推荐结果的覆盖率，降低了推荐结果的流行度。从这个意义上说，ItemCF-IUF确实改进了ItemCF的综合性能。

表2-9 MovieLens数据集中ItemCF算法和ItemCF-IUF算法的对比

|            | 准确率 | 召回率 | 覆盖率 | 流行度   |
| ---------- | ------ | ------ | ------ | -------- |
| ItemCF     | 22.28% | 10.76% | 18.84% | 7.254526 |
| ItemCF-IUF | 22.29% | 10.77% | 19.70% | 7.217326 |

#### 3. 物品相似度的归一化

Karypis在研究中发现如果将ItemCF的相似度矩阵按最大值归一化，可以提高推荐的准确率。其研究表明，如果已经得到了物品相似度矩阵*w*，那么可以用如下公式得到归一化之后的相似度矩阵*w'*：
$$
w'_{ij}=\frac{w_{ij}}{\max_\limits{j}w_{ij}}
$$
其实，归一化的好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性。一般来说，物品总是属于很多不同的类，每一类中的物品联系比较紧密。举一个例子，假设在一个电影网站中，有两种电影——纪录片和动画片。那么，ItemCF算出来的相似度一般是纪录片和纪录片的相似度或者动画片和动画片的相似度大于纪录片和动画片的相似度。但是纪录片之间的相似度和动画片之间的相似度却不一定相同。假设物品分为两类——A和B，A类物品之间的相似度为0.5，B类物品之间的相似度为0.6，而A类物品和B类物品之间的相似度是0.2。在这种情况下，如果一个用户喜欢了5个A类物品和5个B类物品，用ItemCF给他进行推荐，推荐的就都是B类物品，因为B类物品之间的相似度大。但如果归一化之后，A类物品之间的相似度变成了1，B类物品之间的相似度也是1，那么这种情况下，用户如果喜欢5个A类物品和5个B类物品，那么他的推荐列表中A类物品和B类物品的数目也应该是大致相等的。从这个例子可以看出，相似度的归一化可以提高推荐的多样性。

那么，对于两个不同的类，什么样的类其类内物品之间的相似度高，什么样的类其类内物品相似度低呢？一般来说，热门的类其类内物品相似度一般比较大。如果不进行归一化，就会推荐比较热门的类里面的物品，而这些物品也是比较热门的。因此，推荐的覆盖率就比较低。相反，如果进行相似度的归一化，则可以提高推荐系统的覆盖率。

表2-10对比了ItemCF算法和ItemCF-Norm算法的离线实验性能。从实验结果可以看到，归一化确实能提高ItemCF的性能，其中各项指标都有了比较明显的提高。

表2-10 MovieLens数据集中ItemCF算法和ItemCF-Norm算法的对比

|             | 准确率 | 召回率 | 覆盖率 | 流行度   |
| ----------- | ------ | ------ | ------ | -------- |
| ItemCF      | 22.28% | 10.76% | 18.84% | 7.254526 |
| ItemCF-Norm | 22.73% | 10.98% | 23.73% | 7.157385 |

### 2.4.3 UserCF和ItemCF的综合比较

UserCF是推荐系统领域较为古老的算法，1992年就已经在电子邮件的个性化推荐系统Tapestry中得到了应用，1994年被GroupLens用来实现新闻的个性化推荐，后来被著名的文章分享网站Digg用来给用户推荐个性化的网络文章。ItemCF则是相对比较新的算法，在著名的电子商务网站亚马逊和DVD租赁网站Netflix中得到了广泛应用。

那么，为什么Digg使用UserCF，而亚马逊网使用ItemCF呢？

首先回顾一下UserCF算法和ItemCF算法的推荐原理。UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品，而ItemCF给用户推荐那些和他之前喜欢的物品类似的物品。从这个算法的原理可以看到，UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF的推荐结果着重于维系用户的历史兴趣。换句话说，UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承。

在新闻网站中，用户的兴趣不是特别细化，绝大多数用户都喜欢看热门的新闻。即使是个性化，也是比较粗粒度的，比如有些用户喜欢体育新闻，有些喜欢社会新闻，而特别细粒度的个性化一般是不存在的。比方说，很少有用户只看某个话题的新闻，主要是因为这个话题不可能保证每天都有新的消息，而这个用户却是每天都要看新闻的。因此，个性化新闻推荐更加强调抓住新闻热点，热门程度和时效性是个性化新闻推荐的重点，而个性化相对于这两点略显次要。因此，UserCF可以给用户推荐和他有相似爱好的一群其他用户今天都在看的新闻，这样在抓住热点和时效性的同时，保证了一定程度的个性化。这是Digg在新闻推荐中使用UserCF的最重要原因。

UserCF适合用于新闻推荐的另一个原因是从技术角度考量的。因为作为一种物品，新闻的更新非常快，每时每刻都有新内容出现，而ItemCF需要维护一张物品相关度的表，如果物品更新很快，那么这张表也需要很快更新，这在技术上很难实现。绝大多数物品相关度表都只能做到一天一次更新，这在新闻领域是不可以接受的。而UserCF只需要用户相似性表，虽然UserCF对于新用户也需要更新相似度表，但在新闻网站中，物品的更新速度远远快于新用户的加入速度，而且对于新用户，完全可以给他推荐最热门的新闻，因此UserCF显然是利大于弊。

但是，在图书、电子商务和电影网站，比如亚马逊、豆瓣、Netflix中，ItemCF则能极大地发挥优势。首先，在这些网站中，用户的兴趣是比较固定和持久的。一个技术人员可能都是在购买技术方面的书，而且他们对书的热门程度并不是那么敏感，事实上越是资深的技术人员，他们看的书就越可能不热门。此外，这些系统中的用户大都不太需要流行度来辅助他们判断一个物品的好坏，而是可以通过自己熟悉领域的知识自己判断物品的质量。因此，这些网站中个性化推荐的任务是帮助用户发现和他研究领域相关的物品。因此，ItemCF算法成为了这些网站的首选算法。此外，这些网站的物品更新速度不会特别快，一天一次更新物品相似度矩阵对它们来说不会造成太大的损失，是可以接受的。

同时，从技术上考虑，UserCF需要维护一个用户相似度的矩阵，而ItemCF需要维护一个物品相似度矩阵。从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间，同理，如果物品很多，那么维护物品相似度矩阵代价较大。

在早期的研究中，大部分研究人员都是让少量的用户对大量的物品进行评价，然后研究用户兴趣的模式。那么，对于他们来说，因为用户很少，计算用户兴趣相似度是最快也是最简单的方法。但在实际的互联网中，用户数目往往非常庞大，而在图书、电子商务网站中，物品的数目则是比较少的。此外，物品的相似度相对于用户的兴趣一般比较稳定，因此使用ItemCF是比较好的选择。当然，新闻网站是个例外，在那儿，物品的相似度变化很快，物品数目庞大，相反用户兴趣则相对固定（都是喜欢看热门的），所以新闻网站的个性化推荐使用UserCF算法的更多。

表2-11从不同的角度对比了UserCF和ItemCF算法。同时，我们也将前面几节的离线实验结果展示在图2-13、图2-14和图2-15中。从图中可见，ItemCF算法在各项指标上似乎都不如UserCF，特别是其推荐结果的覆盖率和新颖度都低于UserCF，这一点似乎和我们之前讨论的不太符合。

表2-11 UserCF和ItemCF优缺点的对比

|          | UserCF                                                       | ItemCF                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 性能     | 适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大 | 适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大 |
| 领域     | 时效性较强，用户个性化兴趣不太明显的领域                     | 长尾物品丰富，用户个性化需求强烈的领域                       |
| 实时性   | 用户有新行为，不一定造成推荐结果的立即变化                   | 用户有新行为，一定会导致推荐结果的实时变化                   |
| 冷启动   | 在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的<br/>新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户 | 新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品<br/>但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户 |
| 推荐理由 | 很难提供令用户信服的推荐解释                                 | 利用用户的历史行为给用户做推荐解释，可以令用户比较信服       |

首先要指出的是，离线实验的性能在选择推荐算法时并不起决定作用。首先应该满足产品的需求，比如如果需要提供推荐解释，那么可能得选择ItemCF算法。其次，需要看实现代价，比如若用户太多，很难计算用户相似度矩阵，这个时候可能不得不抛弃UserCF算法。最后，离线指标和点击率等在线指标不一定成正比。而且，这里对比的是最原始的UserCF和ItemCF算法，这两种算法都可以进行各种各样的改进。一般来说，这两种算法经过优化后，最终得到的离线性能是近似的。

下一节将分析为什么原始ItemCF算法的覆盖率和新颖度都不高。

【哈利波特问题】

亚马逊网的研究人员在设计ItemCF算法之初发现ItemCF算法计算出的图书相关表存在一个问题，就是很多书都和《哈利波特》相关。也就是说，购买任何一本书的人似乎都会购买《哈利波特》。后来他们研究发现，主要是因为《哈利波特》太热门了，确实是购买任何一本书的人几乎都会购买它。

回顾一下ItemCF计算物品相似度的经典公式：
$$
w_{ij}=\frac{N(i)\cap N(j)}{\sqrt{|N(i)||N(j)|}}
$$
前面说过，如果j非常热门，那么上面公式的分子 $|N(i)||N(j)|$ 就会越来越接近 $N(i)$ 。尽管上面的公式分母已经考虑到了j的流行度，但在实际应用中，热门的*j*仍会获得比较大的相似度。

哈利波特问题有几种解决方案。

第一种是最容易想到的，我们可以在分母上加大对热门物品的惩罚，比如采用如下公式：
$$
w_{ij}=\frac{N(i)\cap N(j)}{|N(i)|^{1-\alpha}|N(j)|^\alpha}
$$
其中 $\alpha \in [0.5, 1]$ 。通过提高α，就可以惩罚热门的j。

表2-12给出了选择不同的*α*惩罚热门物品后，ItemCF算法的推荐性能。这里，如果*α*＝0.5就是标准的ItemCF算法。从离线实验结果可以看到，*α*只有在取值为0.5时才会导致最高的准确率和召回率，而无论*α*＜0.5或者*α*＞0.5都不会带来这两个指标的提高。但是，如果看覆盖率和平均流行度就可以发现，*α*越大，覆盖率就越高，并且结果的平均热门程度会降低。因此，通过这种方法可以在适当牺牲准确率和召回率的情况下显著提升结果的覆盖率和新颖性（降低流行度即提高了新颖性）。

表2-12 惩罚流行度后ItemCF的推荐结果性能

| α    | 准确率 | 召回率 | 覆盖率 | 平均流行度 |
| ---- | ------ | ------ | ------ | ---------- |
| 0.4  | 21.94% | 10.60% | 13.39% | 7.4584     |
| 0.5  | 22.28% | 10.76% | 18.84% | 7.2545     |
| 0.55 | 21.71% | 10.49% | 20.61% | 7.1891     |
| 0.6  | 20.32% | 9.82%  | 22.78% | 7.0688     |
| 0.7  | 15.19% | 7.34%  | 30.18% | 6.6117     |

不过，上述方法还不能彻底地解决哈利波特问题。每个用户一般都会在不同的领域喜欢一种物品。以电视为例，看新闻联播是父辈每天的必修课，他们每天基本就看新闻联播，而且每天不看别的新闻，就看这一种新闻。此外，他们很多都是电视剧迷，都会看央视一套8点的电视剧。那么，最终结果就是黄金时间的电视剧都和新闻联播相似，而新闻联播和其他新闻的相似度很低。

上面的问题换句话说就是，两个不同领域的最热门物品之间往往具有比较高的相似度。这个时候，仅仅靠用户行为数据是不能解决这个问题的，因为用户的行为表示这种物品之间应该相似度很高。此时，我们只能依靠引入物品的内容数据解决这个问题，比如对不同领域的物品降低权重等。这些就不是协同过滤讨论的范畴了。

## 2.5 隐语义模型

自从Netflix Prize比赛举办以来，LFM（latent factor model）隐语义模型逐渐成为推荐系统领域耳熟能详的名词。其实该算法最早在文本挖掘领域被提出，用于找到文本的隐含语义。相关的名词有LSI、pLSA、LDA和Topic Model。本节将对隐含语义模型在Top-N推荐中的应用进行详细介绍，并通过实际的数据评测该模型。

### 2.5.1 基础算法

隐语义模型是最近几年推荐系统领域最为热门的研究话题，它的核心思想是通过隐含特征(latent factor)联系用户兴趣和物品。

首先通过一个例子来理解一下这个模型。图2-16展示了两个用户在豆瓣的读书列表。

从他们的阅读列表可以看出，用户A的兴趣涉及侦探小说、科普图书以及一些计算机技术书，而用户B的兴趣比较集中在数学和机器学习方面。

那么如何给A和B推荐图书呢？

- 对于UserCF，首先需要找到和他们看了同样书的其他用户（兴趣相似的用户），然后给他们推荐那些用户喜欢的其他书。

- 对于ItemCF，需要给他们推荐和他们已经看的书相似的书，比如作者B看了很多关于数据挖掘的书，可以给他推荐机器学习或者模式识别方面的书。

还有一种方法，可以对书和物品的兴趣进行分类。对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品。

总结一下，这个基于兴趣分类的方法大概需要解决3个问题。

- 如何给物品进行分类？
- 如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？
- 对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？

对于第一个问题的简单解决方案是找编辑给物品分类。以图书为例，每本书出版时，编辑都会给书一个分类。为了给图书分类，出版界普遍遵循中国图书分类法。但是，即使有很系统的分类体系，编辑给出的分类仍然具有以下缺点：

- 编辑的意见不能代表各种用户的意见。比如，对于《具体数学》应该属于什么分类，有人认为应该属于数学，有些人认为应该属于计算机。从内容看，这本书是关于数学的，但从用户看，这本书的读大部分是做计算机出身的。编辑的分类大部分是从书的内容出发，而不是从书的读者群出发。
- 编辑很难控制分类的粒度。我们知道分类是有不同粒度的，《数据挖掘导论》在粗粒度的分类中可能属于计算机技术，但在细粒度的分类中可能属于数据挖掘。对于不同的用户，我们可能需要不同的粒度。比如对于一位初学者，我们粗粒度地给他做推荐就可以了，而对于一名资深研究人员，我们就需要深入到他的很细分的领域给他做个性化推荐。
- 编辑很难给一个物品多个分类。有的书不仅属于一个类，而是可能属于很多的类。
- 编辑很难给出多维度的分类。我们知道，分类是可以有很多维度的，比如按照作者分类、按照译者分类、按照出版社分类。比如不同的用户看《具体数学》原因可能不同，有些人是因为它是数学方面的书所以才看的，而有些人是因为它是大师Knuth的著作所以才去看，因此在不同人的眼中这本书属于不同的分类。
- 编辑很难决定一个物品在某一个分类中的权重。比如编辑可以很容易地决定《数据挖掘导论》属于数据挖掘类图书，但这本书在这类书中的定位是什么样的，编辑就很难给出一个准确的数字来表示。

为了解决上面的问题，研究人员提出：为什么我们不从数据出发，自动地找到那些类，然后进行个性化推荐？于是，隐含语义分析技术（latent variable analysis）出现了。隐含语义分析技术因为采取基于用户行为统计的自动聚类，较好地解决了上面提出的5个问题。

- 编辑的意见不能代表各种用户的意见，但隐含语义分析技术的分类来自对用户行为的统计，代表了用户对物品分类的看法。隐含语义分析技术和ItemCF在物品分类方面的思想类似，如果两个物品被很多用户同时喜欢，那么这两个物品就很有可能属于同一个类。
- 编辑很难控制分类的粒度，但隐含语义分析技术允许我们指定最终有多少个分类，这个数字越大，分类的粒度就会越细，反正分类粒度就越粗。
- 编辑很难给一个物品多个分类，但隐含语义分析技术会计算出物品属于每个类的权重，因此每个物品都不是硬性地被分到某一个类中。
- 编辑很难给出多维度的分类，但隐含语义分析技术给出的每个分类都不是同一个维度的，它是基于用户的共同兴趣计算出来的，如果用户的共同兴趣是某一个维度，那么LFM给出的类也是相同的维度。
- 编辑很难决定一个物品在某一个分类中的权重，但隐含语义分析技术可以通过统计用户行为决定物品在每个类中的权重，如果喜欢某个类的用户都会喜欢某个物品，那么这个物品在这个类中的权重就可能比较高。

隐含语义分析技术从诞生到今天产生了很多著名的模型和方法，其中和该技术相关且耳熟能详的名词有pLSA、LDA、隐含类别模型（latent class model）、隐含主题模型（latent topic model）、矩阵分解（matrix factorization）。这些技术和方法在本质上是相通的，其中很多方法都可以用于个性化推荐系统。本章将以LFM为例介绍隐含语义分析技术在推荐系统中的应用。

LFM通过如下公式计算用户u对物品i的兴趣： 
$$
Preference(u,i)=r_{ui}=p_u^T q_i = \sum_{f=1}^F p_{u,k}q_{i,k}
$$
这个公式中 $p_{u,k}$ 和 $q_{i,k}$ 是模型的参数，其中 $p_{u,k}$ 度量了用户u的兴趣和第k个隐类的关系，而 $q_{i，k}$ 度量了第k个隐类和物品i之间的关系。那么，下面的问题就是如何计算这两个参数。

对最优化理论或者机器学习有所了解的读者，可能对如何计算这两个参数都比较清楚。这两个参数是从数据集中计算出来的。要计算这两个参数，需要一个训练集，对于每个用户u，训练集里都包含了用户u喜欢的物品和不感兴趣的物品，通过学习这个数据集，就可以获得上面的模型参数。

推荐系统的用户行为分为显性反馈和隐性反馈。LFM在显性反馈数据（也就是评分数据）上解决评分预测问题并达到了很好的精度。不过本章主要讨论的是隐性反馈数据集，这种数据集的特点是只有正样本（用户喜欢什么物品），而没有负样本（用户对什么物品不感兴趣）。

那么，在隐性反馈数据集上应用LFM解决TopN推荐的第一个关键问题就是如何给每个用户生成负样本。

对于这个问题，Rong Pan在文章中进行了深入探讨。他对比了如下几种方法。

- 对于一个用户，用他所有没有过行为的物品作为负样本。
- 对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本。
- 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。
- 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重采样不热门的物品。

对于第一种方法，它的明显缺点是负样本太多，正负样本数目相差悬殊，因而计算复杂度很高，最终结果的精度也很差。对于另外3种方法，Rong Pan在文章中表示第三种好于第二种，而第二种好于第四种。

后来，通过2011年的KDD Cup的Yahoo! Music推荐系统比赛，我们发现对负样本采样时应该遵循以下原则。

- 对每个用户，要保证正负样本的平衡（数目相似）。
- 对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。

一般认为，很热门而用户却没有行为更加代表用户对这个物品不感兴趣。因为对于冷门的物品，用户可能是压根没在网站中发现这个物品，所以谈不上是否感兴趣。

下面的Python代码实现了负样本采样过程（代码第6行将范围上限设为len(items)*3,主要是为保证正、负样本数量接近）：

~~~python
def RandomSelectNegativeSample(self, items): 
 	ret = dict() 
 	for i in items.keys(): 
 		ret[i] = 1 
 	n = 0 
 	for i in range(0, len(items) * 3): 
 		item = items_pool[random.randint(0, len(items_pool) - 1)] 
 		if item in ret: 
 			continue 
 		ret[item] = 0 
 		n + = 1 
 		if n > len(items): 
 			break 
 	return ret
~~~

在上面的代码中，items_pool维护了候选物品的列表，在这个列表中，物品i出现的次数和物品i的流行度成正比。items是一个dict，它维护了用户已经有过行为的物品的集合。因此，上面的代码按照物品的流行度采样出了那些热门的、但用户却没有过行为的物品。经过采样，可以得到一个用户—物品集K={(u,i)}，其中如果(*u*, *i*)是正样本，则有 $r_{ui}=1$ ，否则有 $r_{ui}=0$ 。然后，需要优化如下的损失函数来找到最合适的参数*p*和*q*
$$
C=\sum_{(u,i)\in K}(r_{ui} - \hat{r}_{ui})^2=\sum_{(u,i)\in K} \Big( r_{ui} - \sum_{k=1}^{K}p_{u,k}q_{i,k} \Big )^2 + \lambda ||p_u||^2 + \lambda||q_i||^2
$$
这里， $\lambda ||p_u||^2 + \lambda||q_i||^2$ 是用来防止过拟合的正则化项，*λ*可以通过实验获得。要最小化上面的损失函数，可以利用一种称为随机梯度下降法①的算法。该算法是最优化理论里最基础的优化算法，它首先通过求参数的偏导数找到最速下降方向，然后通过迭代法不断地优化参数。下面介绍优化方法的数学推导。

上面定义的损失函数里有两组参数 $p_{uk}$ 和 $q_{ik}$，随机梯度下降法需要首先对它们分别求偏导数，可以得到：
$$
\frac{\partial C}{\partial p_{uk}}=-2q_{ik}+2\lambda p_{uk}\\
\frac{\partial C}{\partial q_{ik}}=-2q_{uk}+2\lambda q_{ik}
$$
然后，根据随机梯度下降法，需要将参数沿着最速下降方向向前推进，因此可以得到如下递推公式:
$$
p_{uk} = p_{uk} + \alpha(q_{ik}-\lambda p_{uk})\\
q_{ik} = q_{ik} + \alpha(p_{uk}-\lambda q_{ik})
$$
其中，*α*是学习速率（learning rate），它的选取需要通过反复实验获得。

下面的Python代码实现了这一优化过程：

~~~python
def LatentFactorModel(user_items, F, N, alpha, lambda): 
	[P, Q] = InitModel(user_items, F) 
	for step in range(0,N): 
		for user, items in user_items.items(): 
			samples = RandSelectNegativeSamples(items) 
			for item, rui in samples.items(): 
				eui = rui - Predict(user, item) 
                for f in range(0, F): 
					P[user][f] += alpha * (eui * Q[item][f] - lambda * P[user][f]) 
					Q[item][f] += alpha * (eui * P[user][f] - lambda * Q[item][f]) 
		alpha *= 0.9 
        
def Recommend(user, P, Q): 
	rank = dict() 
	for f, puf in P[user].items(): 
		for i, qfi in Q[f].items():
            if i not in rank: 
				rank[i] += puf * qfi 
	return rank
~~~

我们同样通过离线实验评测LFM的性能。首先，我们在MovieLens数据集上用LFM计算出用户兴趣向量*p*和物品向量*q*，然后对于每个隐类找出权重最大的物品。如表2-13所示，表中展示了4个隐类中排名最高（ $q_{ik}$ 最大）的一些电影。结果表明，每一类的电影都是合理的，都代表了一类用户喜欢看的电影。从而说明LFM确实可以实现通过用户行为将物品聚类的功能。

其次，我们通过实验对比了LFM在TopN推荐中的性能。在LFM中，重要的参数有4个：

- 隐特征的个数F； 
- 学习速率alpha； 
- 正则化参数lambda； 
- 负样本/正样本比例 ratio。

通过实验发现，ratio参数对LFM的性能影响最大。因此，固定F=100、alpha=0.02、lambda=0.01，然后研究负样本/正样本比例ratio对推荐结果性能的影响。

如表2-14所示，随着负样本数目的增加，LFM的准确率和召回率有明显提高。不过当ratio>10以后，准确率和召回率基本就比较稳定了。同时，随着负样本数目的增加，覆盖率不断降低，而推荐结果的流行度不断增加，说明ratio参数控制了推荐算法发掘长尾的能力。如果将LFM的结果与表2-6、表2-9、表2-10中ItemCF和UserCF算法的性能相比，可以发现LFM在所有指标上都优于UserCF和ItemCF。当然，这只是在MovieLens一个数据集上的结果，我们也发现，当数据集非常稀疏时，LFM的性能会明显下降，甚至不如UserCF和ItemCF的性能。关于这一点读者可以通过实验自己研究。

表2-14 Netflix数据集中LFM算法在不同F参数下的性能

| ratio | 准确率 | 召回率 | 覆盖率 | 流行度 |
| ----- | ------ | ------ | ------ | ------ |
| 1     | 21.74% | 10.50% | 51.19% | 6.5140 |
| 2     | 24.32% | 11.75% | 53.17% | 6.5458 |
| 3     | 25.66% | 12.39% | 50.41% | 6.6480 |
| 5     | 26.94% | 13.01% | 44.25% | 6.7899 |
| 10    | 27.74% | 13.40% | 33.87% | 6.9552 |
| 20    | 27.37% | 13.22% | 24.30% | 7.1025 |

### 2.5.2 基于LFM的实际系统的例子

雅虎的研究人员公布过一个使用LFM进行雅虎首页个性化设计的方案。本节将简单介绍他们的设计并讨论他们的设计方案。

雅虎首页的界面页面包括不同的模块，比如左侧的分类导航列表、中间的热门新闻列表、右侧的最近热门话题列表。雅虎的研究人员认为这3个模块都可以进行一定的个性化，可以根据用户的兴趣给他们展示不同的内容。

雅虎的研究人员以CTR作为优化目标，利用LFM来预测用户是否会单击一个链接。为此，他们将用户历史上对首页上链接的行为记录作为训练集。其中，如果用户u单击过链接i，那么就定义(*u*, *i*)是正样本，即$r_{ui}= 1$。如果链接i展示给用户u，但用户u从来没有单击过，那么就定义(*u*, *i*)是负样本，即 $r_{ui}=-1$ 。然后，雅虎的研究人员利用前文提到的LFM预测用户是否会单击链接：
$$
\hat{r}_{ui}=p_u^T \cdot q_i
$$
当然，雅虎的研究人员在上面的模型基础上进行了一些修改，利用了一些改进的LFM模型。这些模型主要来自Netflix Prize比赛，因此我们会在第8章详细讨论这些模型。

但是，LFM模型在实际使用中有一个困难，那就是它很难实现实时的推荐。经典的LFM模型每次训练时都需要扫描所有的用户行为记录，这样才能计算出用户隐类向量（ $p_u$ ）和物品隐类向量（ $q_i$ ）。而且LFM的训练需要在用户行为记录上反复迭代才能获得比较好的性能。因此，LFM的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。从而LFM模型不能因为用户行为的变化实时地调整推荐结果来满足用户最近的行为。在新闻推荐中，冷启动问题非常明显。每天都会有大量新的新闻。这些新闻会在很短的时间内获得很多人的关注，但也会在很短的时间内失去用户的关注。因此，它们的生命周期很短，而推荐算法需要在它们短暂的生命周期内就将其推荐给对它们感兴趣的用户。所以，实时性在雅虎的首页个性化推荐系统中非常重要。为了解决传统LFM不能实时化，而产品需要实时性的矛盾，雅虎的研究人员提出了一个解决方案。

他们的解决方案分为两个部分。

- 首先，他们利用新闻链接的内容属性（关键词、类别等）得到链接i的内容特征向量 $y_i$ 。
- 其次，他们会实时地收集用户对链接的行为，并且用这些数据得到链接i的隐特征向量 $q_i$。然后，他们会利用如下公式预测用户u是否会单击链接i：

$$
r_{ui} = x^T_u \cdot y_i + p^T_u \cdot q_i
$$

其中，$y_i$ 是根据物品的内容属性直接生成的，$x_{uk}$ 是用户u对内容特征*k*的兴趣程度，用户向量 $x_u$ 可以根据历史行为记录获得，而且每天只需要计算一次。而 $q_u$ 、$q_i$ 是根据实时拿到的用户最近几小时的行为训练LFM获得的。因此，对于一个新加入的物品i，可以通过 $x^T_u \cdot y_i$ 估计用户u对物品i的兴趣，然后经过几个小时后，就可以通过 $p^T_u \cdot q_i$ 得到更加准确的预测值。

上面的讨论只是简单阐述了雅虎所用的方法，关于雅虎具体的方法可以参考他们的报告。

### 2.5.3 LFM和基于领域的方法的比较

LFM是一种基于机器学习的方法，具有比较好的理论基础。这个方法和基于邻域的方法（比如UserCF、ItemCF）相比，各有优缺点。下面将从不同的方面对比LFM和基于邻域的方法。

- **理论基础** LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标建立最优的模型。基于邻域的方法更多的是一种基于统计的方法，并没有学习过程。
- **离线计算的空间复杂度** 基于邻域的方法需要维护一张离线的相关表。在离线计算相关表的过程中，如果用户/物品数很多，将会占据很大的内存。假设有*M*个用户和*N*个物品，在计算相关表的过程中，我们可能会获得一张比较稠密的临时相关表（尽管最终我们对每个物品只保留*K*个最相关的物品，但在中间计算过程中稠密的相关表是不可避免的），那么假设是用户相关表，则需要 $O(M*M)$的空间，而对于物品相关表，则需要 $O(N*N)$ 的空间。而LFM在建模过程中，如果是*F*个隐类，那么它需要的存储空间是 $O(F*(M+N))$ ，这在*M*和*N*很大时可以很好地节省离线计算的内存。在Netflix Prize中，因为用户数很庞大（40多万），很少有人使用UserCF算法（据说需要30 GB左右的内存），而LFM由于大量节省了训练过程中的内存（只需要4 GB），从而成为Netflix Prize中最流行的算法。
- **离线计算的时间复杂度** 假设有*M*个用户、*N*个物品、*K*条用户对物品的行为记录。那么，UserCF计算用户相关表的时间复杂度是 $O(N* (K/N)^2)$ ，而ItemCF计算物品相关表的时间复杂度是 $O(M*(K/M)^2)$ 。而对于LFM，如果用*F*个隐类，迭代*S*次，那么它的计算复杂度是 $O(K*F*S)$。那么，如果 $K/N > F*S$ ，则代表UserCF的时间复杂度低于LFM，如果 $K/M>F*S$ ，则说明ItemCF的时间复杂度低于LFM。在一般情况下，LFM的时间复杂度要稍微高于UserCF和ItemCF，这主要是因为该算法需要多次迭代。但总体上，这两种算法在时间复杂度上没有质的差别。
- **在线实时推荐** UserCF和ItemCF在线服务算法需要将相关表缓存在内存中，然后可以在线进行实时的预测。以ItemCF算法为例，一旦用户喜欢了新的物品，就可以通过查询内存中的相关表将和该物品相似的其他物品推荐给用户。因此，一旦用户有了新的行为，而且该行为被实时地记录到后台的数据库系统中，他的推荐列表就会发生变化。而从LFM的预测公式可以看到，LFM在给用户生成推荐列表时，需要计算用户对所有物品的兴趣权重，然后排名，返回权重最大的*N*个物品。那么，在物品数很多时，这一过程的时间复杂度非常高，可达 $O(M*N*F)$ 。因此，LFM不太适合用于物品数非常庞大的系统，如果要用，我们也需要一个比较快的算法给用户先计算一个比较小的候选列表，然后再用LFM重新排名。另一方面，LFM在生成一个用户推荐列表时速度太慢，因此不能在线实时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中。因此，LFM不能进行在线实时推荐，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。
- **推荐解释** ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。但LFM无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，却很难用自然语言描述并生成解释展现给用户。

## 2.6 基于图的模型

用户行为很容易用二分图表示，因此很多图的算法都可以用到推荐系统中。本节将重点讨论如何将用户行为用图表示，并利用图的算法给用户进行个性化推荐。

### 2.6.1 用户行为数据的二分图表示

基于图的模型（graph-based model）是推荐系统中的重要内容。其实，很多研究人员把基于邻域的模型也称为基于图的模型，因为可以把基于邻域的模型看做基于图的模型的简单形式。

在研究基于图的模型之前，首先需要将用户行为数据表示成图的形式。本章讨论的用户行为数据是由一系列二元组组成的，其中每个二元组(*u*, *i*)表示用户u对物品i产生过行为。这种数据集很容易用一个二分图表示。

令*G*（*V*，*E*）表示用户物品二分图，其中 $V=V_U\cup V_I$ 由用户顶点集合 $V_U$ 和物品顶点集合 $V_I$ 组成。对于数据集中每一个二元组(*u*, *i*)，图中都有一套对应的边 $e(v_u,v_i)$ ，其中 $v_u\in V_U$ 是用户u对应的顶点， $v_i\in V_I$ 是物品i对应的顶点。图2-18是一个简单的用户物品二分图模型，其中圆形节点代表用户，方形节点代表物品，圆形节点和方形节点之间的边代表用户对物品的行为。比如图中用户节点A和物品节点a、b、d相连，说明用户A对物品a、b、d产生过行为。

### 2.6.2 基于图的推荐算法

将用户行为表示为二分图模型后，下面的任务就是在二分图上给用户进行个性化推荐。如果将个性化推荐算法放到二分图模型上，那么给用户u推荐物品的任务就可以转化为度量用户顶点 $v_u$ 和与 $v_u$ 没有边直接相连的物品节点在图上的相关性，相关性越高的物品在推荐列表中的权重就越高。

度量图中两个顶点之间相关性的方法很多，但一般来说图中顶点的相关性主要取决于下面3个因素：

- 两个顶点之间的路径数；
- 两个顶点之间路径的长度；
- 两个顶点之间的路径经过的顶点。

而相关性高的一对顶点一般具有如下特征：

- 两个顶点之间有很多路径相连；
- 连接两个顶点之间的路径长度都比较短；
- 连接两个顶点之间的路径不会经过出度比较大的顶点。

举一个简单的例子，如图2-19所示，用户A和物品c、e没有边相连，但是用户A和物品c有两条长度为3的路径相连，用户A和物品e有两条长度为3的路径相连。那么，顶点A与e之间的相关性要高于顶点A与c，因而物品e在用户A的推荐列表中应该排在物品c之前，因为顶点A与e之间有两条路径——（A, b, C, e）和（A, d, D, e）。其中，（A, b, C, e）路径经过的顶点的出度为（3, 2, 2, 2），而（A, d, D, e）路径经过的顶点的出度为（3, 2, 3, 2）。因此，（A, d, D, e）经过了一个出度比较大的顶点D，所以（A, d, D, e）对顶点A与e之间相关性的贡献要小于（A, b, C, e）。

基于上面3个主要因素，研究人员设计了很多计算图中顶点之间相关性的方法。本节将介绍一种基于随机游走的PersonalRank算法。

假设要给用户u进行个性化推荐，可以从用户u对应的节点 $v_u$ 开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率*α*决定是继续游走，还是停止这次游走并从 $v_u$ 节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。

如果将上面的描述表示成公式，可以得到如下公式：
$$
PR(v)=
	\begin{cases}
		\alpha\sum_\limits{v'\in in(v)}\frac{PR(v')}{|out(v')|} & (v \ne v_u)\\
		(1-\alpha)+\alpha\sum_\limits{v'\in in(v)}\frac{PR(v')}{|out(v')|} & (v=v_u)
	\end{cases}
$$
下面的Python代码简单实现了上面的公式:

~~~python
def PersonalRank(G, alpha, root): 
	rank = dict() 
	rank = {x:0 for x in G.keys()} 
	rank[root] = 1 
	for k in range(20): 
		tmp = {x:0 for x in G.keys()} 
		for i, ri in G.items(): 
			for j, wij in ri.items(): 
				if j not in tmp: 
					tmp[j] = 0 
				tmp[j] += 0.6 * rank[i] / (1.0 * len(ri)) 
				if j == root: 
					tmp[j] += 1 - alpha 
		rank = tmp 
	return rank
~~~

我们用上面的代码跑了一下图2-20的例子，给A用户进行推荐。图2-21给出了不同迭代次数后每个顶点的访问概率。从图中可以看到，每个顶点的访问概率在9次迭代之后就基本上收敛了。在这个例子中，用户A没有对物品b*、*d有过行为。在最后的迭代结果中，d的访问概率大于b，因此给A的推荐列表就是{*d*, *b*}。

本节在MovieLens的数据集上评测了PersonalRank算法，实验结果如表2-15所示。

表2-15 MovieLens数据集中PersonalRank算法的离线实验结果

| α    | 准确率 | 召回率 | 覆盖率 | 流行度 |
| ---- | ------ | ------ | ------ | ------ |
| 0.8  | 16.45% | 7.95%  | 3.42%  | 7.6928 |

虽然PersonalRank算法可以通过随机游走进行比较好的理论解释，但该算法在时间复杂度上有明显的缺点。因为在为每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛。这一过程的时间复杂度非常高，不仅无法在线提供实时推荐，甚至离线生成推荐结果也很耗时。

为了解决PersonalRank每次都需要在全图迭代并因此造成时间复杂度很高的问题，这里给出两种解决方案。第一种很容易想到，就是减少迭代次数，在收敛之前就停止。这样会影响最终的精度，但一般来说影响不会特别大。另一种方法就是从矩阵论出发，重新设计算法。

对矩阵运算比较熟悉的读者可以轻松将PersonalRank转化为矩阵的形式。令*M*为用户物品二分图的转移概率矩阵，即：
$$
M(v,v')=\frac{1}{|out(v)|}
$$
那么，迭代公式可以转化为：
$$
r=(1-\alpha)r_0+\alpha M^T r
$$
对矩阵论稍微熟悉的读者都可以解出上面的方程，得到：
$$
r = (1-\alpha)(1-\alpha M^T)^{-1} r_0
$$
因此，只需要计算一次 $(1-\alpha M^T)^{-1}$ ，这里 $1-\alpha M^T$ 是稀疏矩阵。关于如何对稀疏矩阵快速求逆，可以参考矩阵计算方面的书籍和论文，本书就不再讨论了。

# 第3章 推荐系统冷启动问题

推荐系统需要根据用户的历史行为和兴趣预测用户未来的行为和兴趣，因此大量的用户行为数据就成为推荐系统的重要组成部分和先决条件。对于很多像百度、当当这样的网站来说，这或许不是个问题，因为它们目前已经积累了大量的用户数据。但是对于很多做纯粹推荐系统的网站（比如Jinni和Pandora），或者很多在开始阶段就希望有个性化推荐应用的网站来说，如何在没有大量用户数据的情况下设计个性化推荐系统并且让用户对推荐结果满意从而愿意使用推荐系统，就是冷启动的问题。

## 3.1 冷启动问题简介

冷启动问题（cold start）主要分3类。

- **用户冷启动** 用户冷启动主要解决如何给新用户做个性化推荐的问题。当新用户到来时，我们没有他的行为数据，所以也无法根据他的历史行为预测其兴趣，从而无法借此给他做个性化推荐。
- **物品冷启动** 物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。
- **系统冷启动** 系统冷启动主要解决如何在一个新开发的网站上（还没有用户，也没有用户行为，只有一些物品的信息）设计个性化推荐系统，从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。

对于这3种不同的冷启动问题，有不同的解决方案。一般来说，可以参考如下解决方案。

- **提供非个性化的推荐** 非个性化推荐的最简单例子就是热门排行榜，我们可以给用户推荐热门排行榜，然后等到用户数据收集到一定的时候，再切换为个性化推荐。
-  利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。
- 利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。
- 要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。
- 对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。
- 在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。

## 3.2 利用用户注册信息

用户的注册信息分3种。

- 人口统计学信息 包括用户的年龄、性别、职业、民族、学历和居住地。
- 用户兴趣的描述 有一些网站会让用户用文字描述他们的兴趣。
- 从其他网站导入的用户站外行为数据 比如用户通过豆瓣、新浪微博的账号登录，就可以在得到用户同意的情况下获取用户在豆瓣或者新浪微博的一些行为数据和社交网络数据。

基于注册信息的个性化推荐流程基本如下：

(1) 获取用户的注册信息；

(2) 根据用户的注册信息对用户分类；

(3) 给用户推荐他所属分类中用户喜欢的物品。

利用的用户人口统计学特征越多，越能准确地预测用户兴趣。

## 3.3 选择合适的物品启动用户的兴趣

解决用户冷启动问题的另一个方法是在新用户第一次访问推荐系统时，不立即给用户展示推荐结果，而是给用户提供一些物品，让用户反馈他们对这些物品的兴趣，然后根据用户反馈给提供个性化推荐。很多推荐系统采取了这种方式来解决用户冷启动问题。

对于这些通过让用户对物品进行评分来收集用户兴趣，从而对用户进行冷启动的系统，它们需要解决的首要问题就是如何选择物品让用户进行反馈。

一般来说，能够用来启动用户兴趣的物品需要具有以下特点。

- **比较热门** 如果要让用户对一个物品进行反馈，前提是用户知道这个物品是什么东西。以电影为例，如果一开始让用户进行反馈的电影都很冷门，而用户不知道这些电影的情节和内容，也就无法对它们做出准确的反馈。
- **具有代表性和区分性** 启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性。还以电影为例，用一部票房很高且广受欢迎的电影做启动物品，可以想象的到的是几乎所有用户都会喜欢这部电影，因而无法区分用户个性化的兴趣。
- **启动物品集合需要有多样性** 在冷启动时，我们不知道用户的兴趣，而用户兴趣的可能性非常多，为了匹配多样的兴趣，我们需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣。Jinni在让用户反馈时没有直接拿电影让用户反馈，而是给出了12个电影类型（截图中只显示了其中的6个电影类型），让用户先选择喜欢哪种类型，这样就很好地保证了启动物品集合的多样性。

上面这些因素都是选择启动物品时需要考虑的，但如何设计一个选择启动物品集合的系统呢？Nadav Golbandi在论文中探讨了这个问题，提出可以用一个决策树解决这个问题。

## 3.4 利用物品的内容信息

物品冷启动需要解决的问题是如何将新加入的物品推荐给对它感兴趣的用户。物品冷启动在新闻网站等时效性很强的网站中非常重要，因为那些网站中时时刻刻都有新加入的物品，而且每个物品必须能够在第一时间展现给用户，否则经过一段时间后，物品的价值就大大降低了。

首先需要指出的是，UserCF算法对物品冷启动问题并不非常敏感。

那么对于UserCF算法就需要解决第一推动力的问题，即第一个用户从哪儿发现新的物品。只要有一小部分人能够发现并喜欢新的物品，UserCF算法就能将这些物品扩散到更多的用户中。解决第一推动力最简单的方法是将新的物品随机展示给用户，但这样显然不太个性化，因此可以考虑利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。

对于ItemCF算法来说，物品冷启动就是一个严重的问题了。因为ItemCF算法的原理是给用户推荐和他之前喜欢的物品相似的物品。ItemCF算法会每隔一段时间利用用户行为计算物品相似度表（一般一天计算一次），在线服务时ItemCF算法会将之前计算好的物品相关度矩阵放在内存中。因此，当新物品加入时，内存中的物品相关表中不会存在这个物品，从而ItemCF算法无法推荐新的物品。解决这一问题的办法是频繁更新物品相似度表，但基于用户行为计算物品相似度是非常耗时的事情，主要原因是用户行为日志非常庞大。而且，新物品如果不展示给用户，用户就无法对它产生行为，通过行为日志计算是计算不出包含新物品的相关矩阵的。为此，我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表（比如半小时计算一次）。

一般来说，物品的内容可以通过向量空间模型表示，该模型会将物品表示成一个关键词向量。对于中文，首先要对文本进行分词，将字流变成词流，然后从词流中检测出命名实体（如人名、地名、组织名等），这些实体和一些其他重要的词将组成关键词集合，最后对关键词进行排名，计算每个关键词的权重，从而生成关键词向量。

如果物品是文本，我们可以用信息检索领域著名的TF-IDF公式计算词的权重
$$
w_i = \frac{TF(e_i)}{\log DF(e_i)}
$$
如果物品是电影，可以根据演员在剧中的重要程度赋予他们权重。向量空间模型的优点是简单，缺点是丢失了一些信息，比如关键词之间的关系信息。不过在绝大多数应用中，向量空间模型对于文本的分类、聚类、相似度计算已经可以给出令人满意的结果。

在给定物品内容的关键词向量后，物品的内容相似度可以通过向量之间的余弦相似度计算：
$$
w_{ij}=\frac{d_i\cdot d_j}{\sqrt{||d_i|| ||d_j||}}
$$
在具体计算物品之间的内容相似度时，最简单的方法当然是对两两物品都利用上面的余弦相似度公式计算相似度

但这种算法的时间复杂度很高。假设有*N*个物品，每个物品平均由*m*个实体表示，那么这个算法的复杂度是 $O(N^2m)$。

在实际应用中，可以首先通过建立关键词—物品的倒排表加速这一计算过程，关于这一方法已经在前面介绍UserCF和ItemCF算法时详细介绍过了。

得到物品的相似度之后，可以利用上一章提到的ItemCF算法的思想，给用户推荐和他历史上喜欢的物品内容相似的物品。

也许有读者认为，既然内容相似度计算简单，能频繁更新，而且能够解决物品冷启动问题，那么为什么还需要协同过滤的算法。为了说明内容过滤算法和协同过滤算法的优劣，本节在MovieLens和GitHub两个数据集上进行了实验。

从MovieLens数据集上的结果可以发现，ContentItemKNN的准确率和召回率仅仅优于Random算法，明显差于ItemCF算法，甚至比MostPopular算法还要差。不过在覆盖率和流行度指标上ContentItemKNN却优于ItemCF。这主要是因为内容过滤算法忽视了用户行为，从而也忽视了物品的流行度以及用户行为中所包含的规律，所以它的精度比较低，但结果的新颖度却比较高。

不过，事情不是绝对的。如果看GitHub数据集的结果，我们会发现完全相反的现象——Content- ItemKNN在所有指标上都优于ItemCF。这主要是因为GitHub提供了一个非常强的内容特征，就是开源项目的作者。在GitHub中，程序员会经常会关注同一个作者的不同项目，这一点是GitHub数据集最重要的特征。而协同过滤算法由于数据稀疏的影响，不能从用户行为中完全统计出这一特征，所以协同过滤算法反而不如利用了先验信息的内容过滤算法。这一点也说明，如果用户的行为强烈受某一内容属性的影响，那么内容过滤的算法还是可以在精度上超过协同过滤算法的。不过这种强的内容特征不是所有物品都具有的，而且需要丰富的领域知识才能获得，所以很多时候内容过滤算法的精度比协同过滤算法差。不过，这也提醒我们，如果能够将这两种算法融合，一定能够获得比单独使用这两种算法更好的效果。

向量空间模型在内容数据丰富时可以获得比较好的效果。以文本为例，如果是计算长文本的相似度，用向量空间模型利用关键词计算相似度已经可以获得很高的精确度。但是，如果文本很短，关键词很少，向量空间模型就很难计算出准确的相似度。换句话说，这两篇文章的关键词虽然不同，但关键词所属的话题是相同的。在这种情况下，首先需要知道文章的话题分布，然后才能准确地计算文章的相似度。如何建立文章、话题和关键词的关系是话题模型（topic model）研究的重点。

代表性的话题模型有LDA。关于LDA的详细理论介绍可以参考DM Blei的论文“Latent Dirichlet Allocation”。

任何模型都有一个假设，LDA作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。

LDA中有3种元素，即文档、话题和词语。每一篇文档都会表现为词的集合，这称为词袋模型(bag of words)。每个词在一篇文章中属于一个话题。令D为文档集合，$D[i]$是第i篇文档。$w[i][j]$是第i篇文档中的第*j*个词。$z[i][j]$是第i篇文档中第j个词属于的话题。

LDA的计算过程包括初始化和迭代两部分。首先要对z进行初始化，而初始化的方法很简单，假设一共有K个话题，那么对第i篇文章中的第j个词，可以随机给它赋予一个话题。同时，用NWZ(*w*,*z*)记录词w被赋予话题z的次数，NZD(*z*,*d*)记录文档d中被赋予话题z的词的个数。

在初始化之后，要通过迭代使话题的分布收敛到一个合理的分布上去。

LDA可以很好地将词组合成不同的话题。

在使用LDA计算物品的内容相似度时，我们可以先计算出物品在话题上的分布，然后利用两个物品的话题分布计算物品的相似度。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度较低。计算分布的相似度可以利用KL散度:
$$
D_{KL}(p||q)=\sum_i p(i)\ln\frac{p(i)}{q(i)}\\
其中p和q是两个分布，KL散度越大说明分布的相似度越低。
$$

## 3.5 发挥专家的作用

很多推荐系统在建立时，既没有用户的行为数据，也没有充足的物品内容信息来计算准确的物品相似度。那么，为了在推荐系统建立时就让用户得到比较好的体验，很多系统都利用专家进行标注。

# 第4章 利用用户标签数据

根据维基百科的定义，标签是一种无层次化结构的、用来描述信息的关键词，它可以用来描述物品的语义。根据给物品打标签的人的不同，标签应用一般分为两种：一种是让作者或者专家给物品打标签；另一种是让普通用户给物品打标签，也就是UGC（User Generated Content，用户生成的内容）的标签应用。UGC的标签系统是一种表示用户兴趣和物品语义的重要方式。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的语义，从而将用户和物品联系了起来。因此本章主要讨论UGC的标签应用，研究用户给物品打标签的行为，探讨如何通过分析这种行为给用户进行个性化推荐。

## 4.1 UGC标签系统的代表应用

从前面的各种应用可以看到，标签系统在各种各样的（音乐、视频和社交等）网站中都得到了广泛应用。标签系统的最大优势在于可以发挥群体的智能，获得对物品内容信息比较准确的关键词描述，而准确的内容信息是提升个性化推荐系统性能的重要资源。

关于标签系统的作用， GroupLen的Shilads Wieland Sen在MoveLens电影推荐系统上做了更为深入的、基于问卷调查的研究。在博士论文中，他探讨了标签系统的不同作用，以及每种作用能够影响多大的人群，如下所示。

- 表达 标签系统帮助我表达对物品的看法。（30%的用户同意。）
- 组织 打标签帮助我组织我喜欢的电影。（23%的用户同意。）
- 学习 打标签帮助我增加对电影的了解。（27%的用户同意。）
- 发现 标签系统使我更容易发现喜欢的电影。（19%的用户同意。）
- 决策 标签系统帮助我判定是否看某一部电影。（14%的用户同意。）

上面的研究证明，标签系统确实能够帮助用户发现可能喜欢的电影，而这正是个性化推荐系统的使命之一。因此，本章将对如何发挥标签在个性化推荐中的作用进行深入探讨

## 4.2 标签系统中的推荐问题

## 4.3 基于标签的推荐系统

## 4.4 给用户推荐标签

# 第5章 利用上下文信息

本章之前提到的推荐系统算法主要集中研究了如何联系用户兴趣和物品，将最符合用户兴趣的物品推荐给用户，但这些算法都忽略了一点，就是用户所处的上下文（context）。这些上下文包括用户访问推荐系统的时间、地点、心情等，对于提高推荐系统的推荐系统是非常重要的。

## 5.1 时间上下文信息

### 5.1.1 时间效应简介

时间是一种重要的上下文信息，对用户兴趣有着深入而广泛的影响。一般认为，时间信息对用户兴趣的影响表现在以下几个方面。

- **用户兴趣是变化的** 我们这里提到的用户兴趣变化是因为用户自身原因发生的变化。比如随着年龄的增长，用户小时候喜欢看动画片，长大了喜欢看文艺片。一位程序员随着工作时间的增加，逐渐从阅读入门书籍过渡到阅读专业书籍。一个人参加工作了，工作后的兴趣和学生时代的兴趣相比发生了变化。那么，如果我们要准确预测用户现在的兴趣，就应该关注用户最近的行为，因为用户最近的行为最能体现他现在的兴趣。当然，考虑用户最近的兴趣只能针对渐变的用户兴趣，而对突变的用户兴趣很难起作用，比如用户突然中奖了。
- **物品也是有生命周期的** 一部电影刚上映的时候可能被很多人关注，但是经久不衰的电影是很少的，很多电影上映后不久就被人们淡忘了。此外，物品也可能受新闻事件的影响，比如一部已经被淡忘的电影会因为突然被某个新闻事件涉及而重新热门起来。因此，当我们决定在某个时刻给某个用户推荐某个物品时，需要考虑该物品在该时刻是否已经过时了。比如，我们给一个NBA迷推荐10年前的某个NBA新闻显然是不太合适的（当然这也不一定，比如用户当时就是在寻找旧的NBA新闻时）。不同系统的物品具有不同的生命周期，比如新闻的生命周期很短暂，而电影的生命周期相对较长。
- **季节效应** 季节效应主要反映了时间本身对用户兴趣的影响。比如人们夏天吃冰淇淋，冬天吃火锅，夏天穿T恤，冬天穿棉衣。当然，我们也不排除有特别癖好的人存在，但大部分用户都是遵循这个规律的。除此之外，节日也是一种季节效应：每年的圣诞节，人们都要去购物；每年的奥斯卡颁奖礼，人们都要关注电影。2011年ACM推荐大会的一个研讨会曾经举办过一次上下文相关的电影推荐算法比赛① ，该比赛要求参赛者预测数据集中用户在奥斯卡颁奖礼附近时刻的行为。关注季节效应的读者可以关注一下这个研讨会上发表的相关论文。

### 5.1.2 时间效应举例

### 5.1.3 系统时间特性的分析

在给定时间信息后，推荐系统从一个静态系统变成了一个时变的系统，而用户行为数据也变成了时间序列。研究一个时变系统，需要首先研究这个系统的时间特性。本节将通过研究时变的用户行为数据集来研究不同类型网站的时间特性。包含时间信息的用户行为数据集由一系列三元组构成，其中每个三元组(*u*,*i*,*t*)代表了用户u在时刻t对物品i产生过行为。在给定数据集后，本节通过统计如下信息研究系统的时间特性。

- **数据集每天独立用户数的增长情况** 有些网站处于快速增长期，它们每天的独立用户数都在线性（甚至呈指数级）增加。而有些网站处于平稳期，每天的独立用户数都比较平稳。还有一些网站处于衰落期，每天的用户都在流失。在3种不同的系统中用户行为是不一样的，因此我们首先需要确定系统的增长情况。
- **系统的物品变化情况** 有些网站，比如新闻网站，每天都会出现大量新的新闻，而每条热门的新闻其时间周期都不会太长，今天热门的新闻也许明天就被人忘记了。 
- **用户访问情况** 有些网站用户来一次就永远不来了，有些网站用户每周来一次，而有些网站用户每天都来。为了度量这些特性，我们可以统计用户的平均活跃天数，同时也可以统计相隔*T*天来系统的用户的重合度。

不同类型网站的物品具有不同的生命周期，比如新闻的生命周期很短，而电影的生命周期很长。我们可以用如下指标度量网站中物品的生命周期。

- **物品平均在线天数** 如果一个物品在某天被至少一个用户产生过行为，就定义该物品在这一天在线。因此，我们可以通过物品的平均在线天数度量一类物品的生存周期。
- **相隔T天系统物品流行度向量的平均相似度** 取系统中相邻*T*天的两天，分别计算这两天的物品流行度，从而得到两个流行度向量。然后，计算这两个向量的余弦相似度，如果相似度大，说明系统的物品在相隔*T*天的时间内没有发生大的变化，从而说明系统的时效性不强，物品的平均在线时间较长。想法，如果相似度很小，说明系统中的物品在相隔*T*天的时间内发生了很大变化，从而说明系统的时效性很强，物品的平均在线时间很短。

### 5.1.4 推荐系统的实时性

用户兴趣是不断变化的，其变化体现在用户不断增加的新行为中。一个实时的推荐系统需要能够实时响应用户新的行为，让推荐列表不断变化，从而满足用户不断变化的兴趣。

实现推荐系统的实时性除了对用户行为的存取有实时性要求，还要求推荐算法本身具有实时性，而推荐算法本身的实时性意味着：

- 实时推荐系统不能每天都给所有用户离线计算推荐结果，然后在线展示昨天计算出来的结果。所以，要求在每个用户访问推荐系统时，都根据用户这个时间点前的行为实时计算推荐列表。
- 推荐算法需要平衡考虑用户的近期行为和长期行为，即要让推荐列表反应出用户近期行为所体现的兴趣变化，又不能让推荐列表完全受用户近期行为的影响，要保证推荐列表对用户兴趣预测的延续性。

### 5.1.5 推荐算法的时间多样性

很多推荐系统的研究人员经常遇到一个问题，就是每天给用户的推荐结果都差不多，没有什么变化。推荐系统每天推荐结果的变化程度被定义为推荐系统的时间多样性。时间多样性高的推荐系统中用户会经常看到不同的推荐结果。

### 5.1.6 时间上下文推荐算法

#### 1. 最近最热门

#### 2. 时间上下文相关的ItemCF算法

#### 3. 时间上下文相关的UserCF算法

### 5.1.7 时间段图模型

### 5.1.8 离线实验

## 5.2 地点上下文信息

除了时间，地点作为一种重要的空间特征，也是一种重要的上下文信息。不同地区的用户兴趣有所不同，用户到了不同的地方，兴趣也会有所不同。在中关村逛街逛累了，希望寻找美食时，你可能会考虑几个因素，包括距离、价位、口味和口碑，而在这些因素里，最重要的因素可能是距离。

# 第6章 利用社交网络数据