# 推荐系统

在互联网永不停歇的增长需求的驱动下，推荐系统的发展可谓一日千里，从2010年之前千篇一律的**协同过滤**（Collaborative Filtering，CF）、**逻辑回归**（Logistic Regression，LR），进化到**因子分解机**（Factorization Machine, FM）、**梯度提升树**（Gradient Boosting Decision Tree, GBDT），再到2015年之后**深度学习推荐模型**的百花齐放，各种模型架构层出不穷。

推荐模型的主流模型经历了**从单一模型到组合模型，从经典框架到深度学习**的发展过程。

# 一、传统推荐系统模型算法

**重要原因**：

诚然，深度学习推荐模型已经成了推荐、广告、搜索领域的主流，但前深度学习时代的推荐模型仍是十分重要的，原因如下：

1. 即使在深度学习空前流行的今天，协同过滤、逻辑回归、因子分解机等传统推荐模型仍然凭借其可解释性强、硬件环境要求低、易于快速训练和部署等不可替代的优势，拥有大量适用的应用场景。
2. 传统推荐模型是深度学习推荐模型的基础。构成深度神经网络（Deep Neural Network，DNN）的基本单元是神经元，而应用广泛的传统逻辑回归模型正式神经元的另一种表现形式；深度学习推荐模型中影响力很大的**基于因子分解机支持的神经网络**（Factorization machine supported Neural Network，FNN）、**深度因子分解机**（Deep Factorization Machine， DeepFM）、**神经网络因子分解机**（Neural Factorization Machine, NFM）等深度学习模型更是与传统的FM模型有着千丝万缕的联系。此外，在传统推荐模型训练中广泛采用的**梯度下降**等训练方式，更是沿用至深度学习时代。所以说，传统推荐模型是深度学习推荐模型的基础，也是学习的入口。

**发展脉络：**

![推荐系统_传统推荐模型的演化关系图](推荐系统 配图\推荐系统_传统推荐模型的演化关系图.png)

简要来说，传统推荐模型的发展脉络主要由以下几个部分组成：

1. **协同过滤算法族**（UserCF、ItemCF、MF）。
   经典的协同过滤算法曾是推荐系统的首选模型，从物品相似度和用户相似度角度出发，协同过滤衍生出物品协同过滤（ItemCF）和用户协同过滤（UserCF）两种算法。为了使协同过滤能够更好地处理稀疏共现矩阵问题、增强模型的泛化能力，从协同过滤衍生出矩阵分解模型（Matrix Factorization，MF），并发展出矩阵分解的各分支模型。
2. **逻辑回归模型族**。
   与协同过滤仅仅利用用户和物品之间的显式或隐式反馈信息相比，逻辑回归能够利用和融合更多用户、物品以及上下文特征。从LR模型衍生出的模型同样“枝繁叶茂”，包括增强了非线性能力的大规模分片线性模型（Large Scale Piece-wise Linear Model，LS-PLM），由逻辑回归发展出来的FM模型，以及与多种不同模型配合使用后的组合模型，等等。
3. **因子分解机模型族**。
   因子分解机在传统逻辑回归的基础上，加入了二阶部分，使模型具备了进行特征组合的能力。更进一步，在因子分解机基础上发展出来的域感知因子分解机（Field-aware Factorization Machine，FFM）则通过加入特征域的概念，进一步加强了因子分解机特征交叉的能力。
4. **组合模型**。
   为了融合多个模型的优点，将不同模型组合使用是构建推荐模型的常用方法。Facebook提出GBDT+LR（梯度提升决策树（Gradient Boosting Decision Tree）+逻辑回归）组合模型是在业界影响力较大的组合方式。

## 1.1 用户协同过滤（UserCF）

协同过滤，就是协同大家的反馈、评价和意见对海量的信息进行过滤，从中筛选出目标用户可能感兴趣的信息的推荐过程。

### 1.1.1 大致步骤

1. 利用用户对商品的历史评价数据。用户、商品、评价记录构成了带有标识的有向图
2. 为了便于计算，将有向图转换为矩阵的形式（被称为“共现矩阵”），用户作为矩阵行坐标，商品作为列坐标，将例如“点赞”和“踩”的用户行为数据转换为矩阵中的相应元素值。
3. 先是找到与用户X兴趣最相似的n（Top n用户）个用户，然后综合相似用户对商品Y的评价，得出用户X对商品Y评价的预测。

### 1.1.2 用户相似度的计算

1. **余弦相似度**
   余弦相似度（Cosine Similarity）衡量了用户向量 $\vec i$ 和用户向量$\vec j$ 之间的夹角大小。显然，夹角越小，证明余弦相似度越大，两个用户越相似。
   $$
   sim(i,j)=cos(i,j)=\frac{i \cdot j}{||i||\cdot||j||}
   $$

2. **皮尔逊相关系数**
   相比余弦相似度，皮尔逊相关系数通过使用用户平均分对各独立评分进行修正，减少了用户评分偏置的影响。
   $$
   sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\overline{R_i})(R_{j,p}-\overline{R_j})}{\sqrt{\sum_{p\in P}(R_{i,p}-\overline{R_i})^2} \sqrt{\sum_{p\in P}(R_{j,p}-\overline{R_j})^2}}
   \\其中，R_{i,p}代表用户 i 对用户p的评分。
   \\\overline{R_i}代表用户 i 对所有物品的平均评分，
   \\P代表所有物品的集合。
   $$

3. 基于皮尔逊系数的思路，还可以通过引入物品平均分的方式，减少物品评分偏置对结果的影响
   $$
   sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\overline{R_p})(R_{j,p}-\overline{R_p})}{\sqrt{\sum_{p\in P}(R_{i,p}-\overline{R_p})^2} \sqrt{\sum_{p\in P}(R_{j,p}-\overline{R_p})^2}}
   \\其中，\overline{R_p} 代表物品p得到的所有评分的平均分。
   $$

在传统协同过滤改进过程中，人们也是通过对相似度定义的改进来解决传统协同过滤算法存在的一些缺陷的。

### 1.1.3 最终结果的排序

获得Top n相似用户之后，利用Top n用户生成最终推荐结果的过程如下。假设“目标用户与其相似用户的喜好是相似的”，可根据相似用户的已有评价对目标用户的偏好进行预测。

这里最常用的方式是利用用户相似度和相似用户的评价的加权平均获得目标用户的评测预测。
$$
R_{u,p}=\frac{\sum_{s\in S}(w_{u,s}\cdot R_{s,p})}{\sum_{s\in S}w_{u,s}}
\\其中，权重w_{u,s}是用户u和用户s的相似度，
\\R_{s,p}是用户s对物品p的评分。
$$
在获得用户u对不同物品的评价预测后，最终的推荐列表根据预测得分进行排序即可得到。至此，完成协同过滤的全部推荐过程。以上介绍的协同过滤算法基于用户相似度进行推荐，因此也被称为基于用户的协同过滤（UserCF）。

### 1.1.4 缺点

1. 互联网应用的场景下，用户数往往远大于物品数，而UserCF需要维护用户相似度矩阵以便快速找出Top n相似用户。该用户相似度矩阵的存储开销非常大，且随着用户数的增长，存储空间以$n^2$的速度快速增长
2. 用户的历史数据向量往往非常稀疏，对于只有几次购买或者点击行为的用户来说，找到相似用户的准确度是非常低的。

## 1.2 物品协同过滤（ItemCF）

具体的讲，ItemCF是基于物品相似度进行推荐的协同过滤算法。通过计算共现矩阵中物品列向量的相似度得到物品之间的相似矩阵，再找到用户历史正反馈物品的相似物品进行进一步排序和推荐。

### 1.1.1 具体步骤

1. 基于历史数据，构建以用户（假设用户总数为m）为行坐标，物品（物品总数为n）为列坐标的 $m\times n$ 维共现矩阵。
2. 计算共现矩阵两两列向量间的相似性（相似度计算方式与用户相似度的计算方式相同），构建 $n\times n$ 维的物品相似度矩阵。
3. 获得用户历史行为数据中的正反馈物品列表。
4. 利用物品相似度矩阵，针对目标用户历史行为中的正反馈物品，找出相似的Top k个物品，组成相似物品集合。
5. 对相似物品集合中的物品，利用相似度分值进行排序，生成最终的推荐列表。

第五步中，如果一个物品与多个用户行为历史中的正反馈物品相似，那么该物品最终的相似度应该是多个相似度的累加
$$
R_{u,p}=\sum_{h \in H}(w_{p,h}\cdot R_{u,h})
\\其中，H是目标用户的正反馈物品集合，
\\w_{p,h}是物品p与物品h的物品相似度，
\\R_{u,h}是用户u对物品h的已有评分。
$$

### 1.2.2 协同过滤的缺点

协同过滤并不具备较强的泛化能力，换句话说，协同过滤无法将两个物品相似这个信息推广到其他物品的相似性计算上。这就导致了一个比较严重的问题——热门的物品具有很强的头部效应，容易跟大量物品产生相似性；而尾部的物品由于特征向量稀疏，很少与其他物品产生相似性，导致很少被推荐。

> **哈利波特问题**
>
> 亚马逊网的研究人员在涉及ItemCF算法之初发现ItemCF算法计算出的图书相关表存在一个问题，就是很多书都和《哈利波特》相关，主要是因为《哈利波特》太热门了。

这一现象揭示了协同过滤的天然缺陷——**推荐结果的头部效应比较明显，处理稀疏向量的能力弱**。

**解决问题**

为解决上述问题，同时增加模型的泛化能力，**矩阵分解技术**被提出。该方法在协同过滤的共现矩阵的基础上，<u>使用更稠密的隐向量标识用户和物品</u>，挖掘用户和物品的隐含兴趣和隐含特征。

另外，<u>协同过滤仅仅利用用户和物品的交互信息</u>，无法有效地引入用户年龄、性别、商品描述、商品分类、当前时间等一系列用户特征、物品特征和上下文特征，<u>这无疑造成了有效信息地遗漏</u>。为了在推荐模型中引入这些特征，推荐系统逐渐发展到以**逻辑回归模型**为核心的、能够综合不同类型特征的**机器学习模型**的道路上。

## 1.3 矩阵分解算法

2006年，Netflix举办的著名推荐算法竞赛Netflix Prize Challenge中，以矩阵分解为主的推荐算法大放异彩，拉开了矩阵分解在业界流行的序幕。本节借用Netflix的场景例子说明矩阵分解算法的原理。

### 1.3.1 原理

矩阵分解算法期望为每一个用户和视频生成一个隐向量，将用户和视频定位到隐向量的表示空间上，距离相近的用户和视频表明兴趣特点相近，在推荐过程中，就应该把距离相近的视频推荐给目标用户。

在“矩阵分解”的算法框架下，**用户和物品的隐向量是通过分解协同过滤生成的共现矩阵得到的**。这也是“矩阵分解”名字的由来。

矩阵分解算法将 $m \times n$ 维的共现矩阵R分解为 $m\times k$ 维的用户矩阵U和 $k\times n$ 维的物品矩阵V相乘的形式。其中m是用户数量，n是物品数量，k是隐向量的维度。k的大小决定了隐向量表达能力的强弱。k的取值越小，隐向量包含的信息越少，模型的泛化程度越高；反之，k的取值越大，隐向量的表达能力越强，但泛化程度相应降低。此外，k的取值还与矩阵分解的求解复杂度直接相关。在具体应用中，k的取值要经过多次试验找到一个推荐效果和工程开销的平衡点。

基于用户矩阵U和物品矩阵V，用户u对物品i的预估评分:
$$
\hat r_{ui}=q^T_i p_u
\\其中p_u是用户u在用户矩阵U中的对应行向量，
\\q_i是物品i在物品矩阵V中的对应列向量
$$

### 1.3.2 矩阵分解的求解过程

对矩阵进行矩阵分解的主要方法有三种：**特征值分解**（Eiden Decomposition）、**奇异值分解**（Singular Value Decomposition，SVD）和**梯度下降**（Gradient Descent）。其中，特征值分解只能作用于方阵，显然不适用于分解用户-物品矩阵。



**奇异值分解**的具体描述如下：

假设矩阵$\boldsymbol M$是一个$m\times n$的矩阵，则一定存在一个分解$\boldsymbol M = \boldsymbol{U \Sigma V^T}$，其中$\boldsymbol U$是$m\times m$的正交矩阵，$\boldsymbol V$是$n \times n$的正交矩阵，$\boldsymbol \Sigma$是$m\times n$的对角阵。

取对角阵$\boldsymbol \Sigma$中较大的k个元素作为隐含特征，删除$\boldsymbol \Sigma$的其他维度及$\boldsymbol U$和$\boldsymbol V$中的对应维度，矩阵$\boldsymbol M$被分解为$\boldsymbol M \approx \boldsymbol U_{m\times k}\boldsymbol \Sigma_{k\times k} V_{k\times n}^T$，至此完成了隐向量维度为k的矩阵分解。

可以说，奇异值分解似乎完美地解决了矩阵分解的问题，但其存在两点缺陷，使其不宜作为互联网场景下矩阵分解的主要方法。

1. 奇异值分解要求原始的共现矩阵是稠密的。互联网场景下大部分用户的行为历史非常少，用户-物品的共现矩阵非常稀疏，这与奇异值分解的应用条件相悖。如果应用奇异值分解，就必须对缺失的元素值进行填充。
2. 传统奇异值分解的计算复杂度达到了$O(mn^2)$的级别，这对于商品数量动辄上百万、用户数量往往上千万的互联网场景来说几乎是不可接受的。



由于上述两个原因，传统奇异值分解也不适用于解决大规模稀疏矩阵的矩阵分解问题。因此，**梯度下降法**成了进行矩阵分解的主要方法，这里对其进行具体介绍。

求解矩阵分解的目标函数：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\boldsymbol q^T_i \boldsymbol p_u)^2
$$


该目标函数的目的是让原始评分 $\boldsymbol r_{ui}$ 与用户向量和物品向量之积 $\boldsymbol q^T_i \boldsymbol p_u$ 的差尽量小，这样才能最大限度地保存共现矩阵地原始信息。其中K是所有用户评分样本的集合。为了减少过拟合现象，加入正则化项后的 <span id="MFfunction">目标函数</span> 如下：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\boldsymbol q^T_i \boldsymbol p_u)^2+\lambda(||\boldsymbol q_i||^2+||\boldsymbol p_u||^2)
$$

>**什么是过拟合现象和正则化**？
>
>正则化对应的英文是Regulation，直译过来是“规则化”，即希望让训练出的模型更“规则”、更稳定，避免预测出一些不稳定的“离奇”结果。（过拟合现象）
>
>为了让模型更“稳重”，需要给模型加入一些限制，这些限制就是正则化项。在加入正则化项之后再次进行训练，拟合函数避免受个别“噪声点”的影响，模型的预测输出更加稳定。
>
>正则化项严格的数学形式是什么样的呢？下面是某模型的损失函数（Loss Function）
>$$
>\frac{1}{2}\sum^n_{n=1}{t_n-\boldsymbol W^T\varnothing(\boldsymbol X_n)}^2+\frac{\lambda}{q}\sum^M_{j=1}|\boldsymbol w_j|^q\\
>其中t_n是训练集样本的真实输出，\boldsymbol W是权重,\varnothing是基函数。
>$$
>如果不考虑加号后面的部分，则上面式子是一个标准的L2损失函数。
>
>在加号后面的项就是正则化项，其中$\lambda$被称为正则化系数，$\lambda$ 越大，正则化的限制越强。剩余部分就是模型权重的q次方之和，q取1时被称为L1正则化，q取2时被称为L2正则化。
>
>将正则化项加入损失函数来保持模型稳定的做法也可以做如下理解。对于加入了正则化项的损失函数来说，模型权重越大，损失函数的值越大。梯度下降是朝着损失（Loss）小的方向发展的，因此正则化项其实是希望在尽量不影响原模型与数据集之间损失的前提下，使模型的权重变小，权重的减小自然会让模型的输出波动更小，从而达到让模型更稳定的目的。

对[目标函数](#MFfunction)的求解可以利用非常标准的梯度下降过程完成。

1. 确定[目标函数](#MFfunction)。

2. 对目标函数求偏导，求取梯度下降的方向和幅度。
   对$\boldsymbol q_i$求偏导，得到的结果为：
   $$
   2(\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol p_u - 2\lambda\boldsymbol q_i
   $$
   对$\boldsymbol p_u$求偏导的结果为
   $$
   2(\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol q_i - 2\lambda\boldsymbol p_u
   $$

3. 利用第2步的求导结果，沿梯度的反方向更新参数：
   $$
   \boldsymbol q_i \leftarrow\boldsymbol q_i-\gamma((\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol p_u-\lambda\boldsymbol q_i)\\
   \boldsymbol p_u \leftarrow\boldsymbol p_u-\gamma((\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol q_i-\lambda\boldsymbol p_u)\\
   其中\gamma为学习率
   $$
   
4. 当迭代次数超过上限n或损失低于阈值$\theta$时，结束训练，否则循环第3步。

在完成矩阵分解过程后，即可得到所有用户和物品的隐向量。在对某用户进行推荐时，可利用该用户的隐向量与所有物品的隐向量进行逐一的内积运算，得出该用户对所有物品的评分评测，再依次进行排序，得到最终的推荐列表。

在了解了矩阵分解的原理之后，就可以更清楚地解释为什么矩阵分解相较协同过滤有更强的泛化能力。在矩阵分解算法中，由于隐向量的存在，使任意的用户和物品之间都可以得到评测分值。而隐向量其实是利用全局信息生成的，有更强的泛化能力；而对协同过滤来说，如果两个用户没有相同的历史行为，两个物品没有相同的购买，那么这两个用户和两个物品的相似度计算，这能使协同过滤不具备泛化利用全局信息的能力）。

### 1.3.3 消除用户和物品打分的偏差

由于不同用户的打分体系不同（比如在5分为满分的情况下，有的用户认为打3分已经是很低的分数了，而有的用户认为打1分才是比较差的评分），不同物品的衡量标准也有所区别（比如电子产品的平均分和日用品的平均分差异也可能比较大），为了消除用户和物品打分的偏差（Bias），常用的做法是在矩阵分解时加入用户和物品的偏差向量，如：
$$
\boldsymbol r_{ui}=\mu+b_i+b_u+\boldsymbol q^T_i\boldsymbol p_u\\
其中\mu是全局偏差常数，\\
b_i是物品偏差系数，可使用物品i收到的所有评分的平均值，\\
b_u是用户偏差系数，可使用用户u给出的所有评分的均值
$$
与此同时，矩阵分解目标函数也需要在[之前目标函数](#MFfunction)基础上做相应改变，如下：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*,\boldsymbol b^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\mu-b_u-b_i-\boldsymbol q^T_i\boldsymbol p_u)^2+\lambda(||\boldsymbol p_u||^2+||\boldsymbol q_i||^2+b_u^2+b_i^2)
$$
同理，矩阵分解的求解过程会随着目标函数的改变而变化，主要区别在于利用新的目标函数，通过求导得出新的梯度下降公式，在此不再赘述。

加入用户和物品的打分偏差项之后，矩阵分解得到的隐向量更能反映不同用户对不同物品的“真实”态度差异，也就更容易捕获评价数据中有价值的信息，从而避免推荐结果有偏。

### 1.3.4 矩阵分解的优点和局限性

**优点**

相比协同过滤，矩阵分解有如下非常明显的优点。

1. **泛化能力强**。在一定程度上解决了数据稀疏问题。
2. **空间复杂度低**。不需再存储协同过滤服务阶段所需的“庞大”的用户相似性或物品相似性矩阵，只需存储用户和物品隐向量。空间复杂度由$n^2$级别降低到$(n+m)\cdot k$级别。
3. **更好的扩展性和灵活性**。矩阵分解的最终产出是用户和物品隐向量，这其实与深度学习中Embedding思想不谋而合，因此矩阵分解的结果也非常便于与其他特征进行组合和拼接，并便于与深度学习网络进行无缝结合。



**局限性**

与此同时，也要意识到矩阵分解的局限性。与协同过滤一样，矩阵分解同样不方便加入用户、物品和上下文相关的特征，这使得矩阵分解丧失了利用很多有效信息的机会，同时在缺乏用户历史行为时，无法进行有效的推荐。为了解决这个问题，逻辑回归模型及其后续发展出的因子分解机等模型，凭借其天然的融合不同特征的能力，逐渐在推荐系统领域得到更广泛的应用。

## 1.4 逻辑回归

相比协同过滤模型仅利用用户和物品的相互行为信息进行推荐，逻辑回归模型能够综合利用用户、物品、上下文等多种不同特征，生成较为“全面”的推荐结果。另外，逻辑回归的另一种表现形式“感知机”作为神经网络中最基础的单一神经元，是深度学习的基础性结构。因此，能够进行多特征融合的逻辑回归模型成了独立于协同过滤的推荐模型发展的另一个主要方向。

相比于协同过滤和矩阵分解利用用户和物品的“相似度”进行推荐，逻辑回归将推荐问题看成一个分类问题，通过预测正样本的概率对物品进行排序。这里的正样本可以是用户“点击”了某商品，也可以是用户“观看”了某视频，均是推荐系统希望用户产生的“正反馈”行为。因此，逻辑回归模型将推荐问题转换成了一个点击率（Click Through Rate，CTR）预估问题。

### 1.4.1 基于逻辑回归模型的推荐流程

基于逻辑回归的推荐过程如下：

1. 将用户年龄、性别、物品属性、物品描述、当前时间、当前地点等特征转换成数值型特征向量。
2. 确定逻辑回归模型的优化目标（以优化“点击率”为例），利用已有样本数据对逻辑回归模型进行训练，确定逻辑回归模型的内部参数。
3. 在模型服务阶段，将特征向量输入逻辑回归模型，经过逻辑回归模型的推断，得到用户“点击”（这里用点击作为推荐系统正反馈行为的例子）物品的概率。
4. 利用“点击”概率对所有候选物品进行排序，得到推荐列表。

基于逻辑回归的推荐过程的重点在于，利用样本的特征向量进行模型训练和在线推断。

### 1.4.2 逻辑回归模型的数学形式

![推荐模型_逻辑回归模型的数学形式的推断过程](推荐系统 配图\推荐模型_逻辑回归模型的数学形式的推断过程.png)

逻辑回归模型的推断过程可以分为如下几步:

1. 将特征向量 $\boldsymbol x=(x_1,x_2,\cdots,x_n)^T$ 作为模型的输入。
2. 通过为各特征赋予相应的权重 $(w_1,w_2,\cdots,w_{n+1})$ 来表示各特征的重要性差异，将各特征进行加权求和，得到 $\boldsymbol x^T \boldsymbol w$。
3. 将 $\boldsymbol x^T \boldsymbol w$ 输入sigmoid函数，使之映射到0~1的区间，得到最终的“点击率”。

> 其中sigmoid函数的具体形式：
> $$
> f(z)=\frac{1}{1+e^{-z}}
> $$
> ![sigmoid函数图像](推荐系统 配图\sigmoid函数图像.png)
>
> 可以直观的看到sigmoid的值域在0~1之间，符合“点击率”的物理意义。

综上，<span id = "LRmath">逻辑回归模型整个推断过程的数学形式 </span>为：
$$
f(\boldsymbol x)=\frac{1}{1+e^{-(\boldsymbol w \cdot \boldsymbol x+b)}}
$$

### 1.4.3 逻辑回归模型的训练方法

对于标准的逻辑回归模型来说，要确定的参数就是特征向量相应的权重向量 $\boldsymbol w$，下面介绍逻辑回归模型的权重向量 $\boldsymbol w$ 的训练方法。

逻辑回归模型常用的训练方法是梯度下降法、牛顿法、拟牛顿法等，其中梯度下降法是应用最广泛的训练方法，也是学习深度学习各种训练方法的基础。

>**什么是梯度下降法**？
>
>梯度下降法是一个一阶最优化算法。应用梯度下降法的目的是找到一个函数局部极小值。为此，必须沿函数上当前点对应梯度（或者近似梯度）的反方向进行规定步长距离的迭代搜索。如果向梯度正方向迭代进行搜索，则会接近函数的局部极大值点，这个过程被称为梯度上升法。
>
>这利用了“梯度”的性质：如果实值函数F(x)在点$x_0$处可微且有定义，那么函数F(x)在点$x_0$处沿着梯度相反的方向$-\nabla F(x)$ 下降最快。
>
>因此，在优化某模型的目标函数时，只需对目标函数进行求导，得到梯度的方向，沿梯度的反方向下降，并迭代此过程直至寻找到局部最小点。

使用梯度下降法求解逻辑回归模型的第一步时确定逻辑回归的目标函数。已知[逻辑回归的数学形式](#LRmath)，这里表示成$f_{\boldsymbol w}(\boldsymbol x)$。对于一个输入样本 $\boldsymbol x$ ，预测结果为正样本（类别1）和负样本（类别0）的概率如下：
$$
\left\{
	\begin{array}{l}
		P(y=1|\boldsymbol x;\boldsymbol w)=f_{\boldsymbol w}(\boldsymbol x)\\
		P(y=0|\boldsymbol x;\boldsymbol w)=1-f_{\boldsymbol w}(\boldsymbol x)
	\end{array}
\right.
$$
综合起来，可以写成：
$$
P(y|\boldsymbol x;\boldsymbol w)=(f_{\boldsymbol w}(\boldsymbol x))^y(1-f_{\boldsymbol w}(\boldsymbol x))^{1-y}
$$
由极大似然估计的原理可以写出逻辑回归的目标函数：
$$
L(\boldsymbol w)=\prod^m_{i=1}P(y|\boldsymbol x;\boldsymbol w)
$$
由于目标函数连乘的形式不便于求导，故在上式两侧取log，并乘以系数-(1/m)，将求最大值的问题转换成求极小值的问题，最终的目标函数形式如下：
$$
J(\boldsymbol w)=-\frac{1}{m}l(\boldsymbol w)=-\frac{1}{m}logL(\boldsymbol w)\\
=-\frac{1}{m}(\sum^m_{i=1}(y^i logf_{\boldsymbol w}(\boldsymbol x^i)+(1-y^i)log(1-f_{\boldsymbol w}(\boldsymbol x^i)))
$$
在得到逻辑回归的目标函数后，需对每个参数求偏导，得到梯度方向，对$J(\boldsymbol w)$中参数$w_j$求偏导的结果如下：
$$
\frac{\partial}{\partial w_j}J(\boldsymbol w)=\frac{1}{m}\sum^m_{i=1}(f_{\boldsymbol w}(\boldsymbol x^i)-y^i)\boldsymbol x^i_j
$$
在得到梯度之后，即可得到模型参数的更新方式，如下：
$$
w_j \leftarrow w_j -\gamma\frac{1}{m}\sum^m_{i=1}(f_w(x^i)-y^i)x^i_j
$$
至此，完成了逻辑回归模型的更新推导。

可以看出，无论矩阵分解还是逻辑回归，在用梯度下降求解时都遵循其基本步骤。问题的关键在于利用模型的数学形式找出其目标函数，并通过求导得到梯度下降的公式。

### 1.4.4 逻辑回归模型的优势

在深度学习模型流行之前，逻辑回归模型曾在相当长的一段时间里是推荐系统、计算广告业界的主要选择之一。除了在形式上适于融合不同特征，形成较“全面”的推荐结果，其流行还有三个方面的原因：一是数学含义上的支撑；二是可解释性强；三是工程化的需要。

1. **数学含义上的支撑**
   逻辑回归作为广义线性模型的一种，它的假设是因变量y服从伯努利分布。那么在CTR预估这个问题上，“点击”事件是否发生就是模型的因变量y，而用户是否点击广告是一个经典的掷偏心硬币问题。因此，CTR模型的因变量显然应该服从伯努利分布。所以，采用逻辑回归作为CTR模型是符合“点击”这一事件的物理意义的。
   与之相比，线性回归作为广义线性模型的另一个特例，其假设是因变量y服从高斯分布，这显然不是点击这类二分类问题的数学假设。

2. **可解释性强**
   直观地讲，逻辑回归模型地数学形式是各特征的加权和，再施以sigmoid函数。在逻辑回归数学基础的支撑下，逻辑回归的简单数学形式页非常符合人类对预估过程的直觉认知。
   使用各特征的加权和是为了综合不同特征对CTR的影响，而不同特征的重要程度不一样，所以，为不同特征指定不同的权重，代表不同的特征的重要程度。最后，通过sigmoid函数，使其值能够映射到0~1区间，正好符合CTR的物理意义。
   逻辑回归如此符合人类的直觉认识显然有其他的好处——使模型具有极强的可解释性。算法工程师可以轻易地根据权重的不同解释哪些特征比较重要，在CTR模型的预测有偏差时定位是哪些因素影响了最后的结果。在与负责运营、产品的同事合作时，也便于给出可解释的原因，有效降低沟通成本。

3. **工程化的需要**

   在互联网公司每天动辄TB级别的数据面前，模型的训练开销和在线推断效率显得异常重要。在GPU尚未流行的2012年之前，逻辑回归模型凭借其易于并行化、模型简单、训练开销小等特点，占据着工程领域的主流。囿于工程团队的限制，即使其他复杂模型的效果有所提升，在没有明显击败逻辑回归模型之前，公司也不会贸然加大计算资源的投入，升级推荐模型或CTR模型，这是逻辑回归持续流行的另一重要原因。

### 1.4.5 逻辑回归模型的局限性

逻辑回归作为一个基础模型，显然有其简单、直观、易用的特点。但其局限性也是非常明显的：表达能力不强，无法进行特征交叉、特征筛选等一系列较为“高级”的操作，因此不可避免地造成信息地损失。为解决这一问题，推荐模型朝着复杂化的方向继续发展，衍生出因子分解机等高维的复杂模型。在进入深度学习时代之后，多层神经网络强大的表达能力可以完全替代逻辑回归模型，让它逐渐从各公司退役。

逻辑回归模型表达能力不强的问题，会不可避免地造成有效信息地损失。在仅使用单一特征而非交叉特征进行判断地情况下，有时不仅是信息损失地问题，甚至会得出错误地结论。著名地“辛普森悖论”用一个简单地例子，说明了进行多维度特征交叉地重要性。

> **什么是辛普森悖论**？
>
> 在对样本集合进行分组研究时，在分组比较中都占优势的一方，在总评中有时反而是失势的一方，这种有悖常理的现象，被称为“辛普森悖论”。
>
> 假如下面两表为视频应用中男性用户和女性用户点击视频的数据。
>
> 男性：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 8          | 530        | 1.51%  |
> | 视频B | 51         | 1520       | 3.36%  |
>
> 女性：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 201        | 2510       | 8.01%  |
> | 视频B | 92         | 1010       | 9.11%  |
>
> 从以上数据中可以看出，无论男性用户还是女性用户，对视频B的点击率都高于A，显然推荐系统应该优先考虑向用户推荐B。
>
> 那么，如果忽略性别这个维度，将数据汇总会得出什么结论呢？
>
> 汇总：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 209        | 3040       | 6.88%  |
> | 视频B | 143        | 2530       | 5.65%  |
>
> 在汇总结果中，视频A的点击率居然比视频B高。如果据此进行推荐，将得出与之前的结果完全相反的结论，这就是所谓的“辛普森悖论”。

逻辑回归只对单一特征做简单加权，不具备进行特征交叉生成高维组合特征的能力，因此表达能力很弱，甚至可能得出像“辛普森悖论”那样的错误结论。因此，通过改造逻辑回归模型，使其具备特征交叉能力是必要和迫切的。

## 1.5 POLY2模型

针对特征交叉的问题，算法工程师经常采用先手动组合特征，再通过各种分析手段筛选特征的方法，但该方法无疑是低效的。更遗憾的是，人类的经验往往有局限性，程序员的时间和精力也无法支撑其找到最优的特征组合。因此，采用POLY2模型进行特征的“暴力”组合成了可行的选择。

### 1.5.1 POLY2模型的数学形式

$$
\empty POLY2(\boldsymbol w,\boldsymbol x)=\sum^{n-1}_{j_1=1}\sum^n_{j_2=j_1+1}w_h(j_1,j_2)x_{j_1}x_{j_2}
$$

可以看到，该模型对所有特征进行两两交叉（特征$x_{j_1}$和$x_{j_2}$），并对所有的特征组合赋予权重$w_h(j_1,j_2)$。POLY2通过暴力组合特征的方式，在一定程度上解决了特征组合的问题。POLY2模型本质上仍是线性模型，其训练方法与逻辑回归并无区别，因此便于工程上的兼容。

### 1.5.2 POLY2模型的缺陷

但POLY2模型存在两个较大的缺陷。

1. 在处理互联网数据时，经常采用one-hot编码的方法处理类别型数据，致使特征向量极度稀疏，POLY2进行无选择的特征交叉——原本就非常稀疏的特征向量更加稀疏，导致大部分交叉特征的权重缺乏有效的数据进行训练，无法收敛。
2. 权重参数的数量从n直接上升到$n^2$，极大的增加了训练复杂度。

> **什么是one-hot编码**？
>
> one-hot编码是将类别型特征向量的一种编码方式。由于类别型特征不具备数值化意义，如果不进行one-hot编码，无法将其直接作为特征向量的一个维度使用。
>
> 举例来说，某样本有三个特征，分别是星期、性别和城市，用`[Weekday=Tuesday,Gender=Male,City=London]`表示。由于模型的输入特征向量仅可以是数值型特征向量，最常用的方法就是将特征做one-hot编码。编码结果如下：
> $$
> \begin{matrix} \underbrace{ [0,1,0,0,0,0,0] }\\Weekday=Tuesday \end{matrix}
> \begin{matrix} \underbrace{ [0,1] }\\Gender=Male \end{matrix}
> \begin{matrix} \underbrace{ [0,0,1,0,\cdots,0,0] }\\City=London \end{matrix}
> $$
> 可以看到，Weekday这个特征域有7个维度，Tuesday对应第2个维度，所以把对应维度置为1。Gender分为Male和Female，one-hot编码就有两个维度，City特征域同理。
>
> 虽然one-hot编码方式可以将类别型特征转变成数值型特征向量，但是会不可避免地造成特征向量中存在大量数值为0的特征维度。这在互联网这种海量用户场景下尤为明显。假设某应用有一亿用户，那么将用户id进行one-hot编码后，将造成1亿维特征向量中仅有1维是非零的。这是造成互联网模型的输入特征向量稀疏的主要原因。

## 1.6 FM模型

为了解决POLY2模型的缺陷，2010年，Rendle提出了FM模型。

FM二阶部分的数学形式：
$$
\varnothing FM(\boldsymbol w,\boldsymbol x)=\sum^n_{j_i=1}\sum^n_{j_2=j_1+1}（\boldsymbol w_{j_i}\cdot\boldsymbol w_{j_2}）x_{j_1}x_{j_2}
$$
与POLY2相比，其主要区别是用两个向量的内积（$\boldsymbol w_{j_i}\cdot\boldsymbol w_{j_2}$）取代了单一的权重系数$w_h(j_1,j_2)$。具体地说，FM为每个特征学习了一个隐权重向量（lacent vector）。在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。

本质上，FM引入隐向量的做法，与矩阵分解用隐向量代表用户和物品的做法异曲同工。可以说，FM是将矩阵分解隐向量的思想进行了进一步扩展，从单纯的用户、物品隐向量扩展到了所有特征上。

FM通过引入特征隐向量的方式，直接把POLY2模型$n^2$级别的权重参数数量减少到了nk（k为隐向量维度，n>>k）。在使用梯度下降法进行FM训练的过程中，FM的训练复杂度同样可被降低到nk级别，极大地降低了训练开销。

隐向量的引入使FM能更好地解决数据稀疏性地问题。举例来说，在某商品推荐的场景下，样本有两个特征，分别是频道（channel）和品牌（brand），某训练样本的特征组合是（ESPN, Adidas）。在POLY2中，只有当ESPN和Adidas同时出现在一个训练样本中时，模型才能学到这个组合特征对应的权重；而在FM中，ESPN的隐向量也可以通过（ESPN, Gucci）样本进行更新，Adidas的隐向量也可以通过（NBC, Adidas）样本进行更新，这大幅降低了模型对数据稀疏性的要求。甚至对于一个从未出现过的特征组合（NBC, Gucci），由于模型之前已经分别学习过NBC, Gucci的隐向量，具备了计算该特征组合权重的能力，这是POLY2无法实现的。相比POLY2，FM虽然丢失了某些具体特征组合的精确记忆能力，但是泛化能力大大提高。

在工程方面，FM同样可以用梯度下降法进行学习，使其不失实时性和灵活性。相比之后深度学习模型复杂的网络结构导致难以部署和线上服务，FM较容易实现的模型结构使其线上推断的过程相对简单，也更容易进行线上部署和服务。因此，FM在2012-2016年前后，成为业界主流的推荐模型之一。

## 1.7 FFM模型

2015年，基于FM提出的FFM在多项CTR预估大赛中夺魁，并被Criteo、美团等公司深度应用在推荐系统、CTR预估等领域。相比FM模型，FFM模型引入了特征域感知（field-aware）这一概念，使模型的表达能力更强。
$$
\varnothing FFM(\boldsymbol w,\boldsymbol x)=\sum^n_{j_1=1}\sum^n_{j_2=j_1+1}(\boldsymbol w_{j_1,f_2}\cdot\boldsymbol w_{j_2,f_1})x_{j_1}x_{j_2}
$$
上式是FFM的数学形式的二阶部分。其与FM的区别在于隐向量由原来的$\boldsymbol w_{j_1}$变成了$\boldsymbol w_{j_1,f_2}$,这意味着每个特征对应的不是唯一一个隐向量，而是一组隐向量。当$\boldsymbol x_{j_1}$特征与$\boldsymbol x_{j_2}$特征进行交叉时，$\boldsymbol x_{j_1}$特征会从$\boldsymbol x_{j_1}$的这一组隐向量中挑出与特征$\boldsymbol x_{j_2}$的域$f_2$对应的隐向量$\boldsymbol w_{j_1,f_2}$进行交叉。同理，$\boldsymbol x_{j_2}$也会用与$\boldsymbol x_{j_1}$的域$f_1$对应的隐向量进行交叉。

这里所说的域（field）简单地讲，代表特征域，域内的特征一般是采用one-hot编码形成的一段one-hot特征向量。例如，用户的性别分为男、女、未知三类，那么对一个女性用户来说，采用one-hot方式的编码的特征向量为`[0,1,0]`，这个三维的特征向量就是一个”性别“特征域。将所有特征域连接起来，就组成了样本的整体特征向量。

下面介绍Criteo FFM的论文中的一个例子，更具体地说明FFM的特点。假设在训练推荐模型过程中接收到的训练样本如下：

~~~
Publisher(P)		Advertiser(A)		Gender(G)
ESPN				NIKE				Male
~~~

其中，Publisher、Advertiser、Gender是三个特征域，ESPN、NIKE、Male分别是这三个特征域的特征值（还需要转换成one-hot特征）。

如果按照FM的原理，特征ESPN和NIKE和Male都有对应的隐向量$\boldsymbol w_{ESPN}$，$\boldsymbol w_{NIKE}$，$\boldsymbol w_{Male}$，那么ESPN特征与NIKE特征、ESPN特征与Male特征做交叉的权重应该是$\boldsymbol w_{ESPN}\cdot \boldsymbol w_{NIKE}$和$\boldsymbol w_{ESPN}\cdot \boldsymbol w_{Male}$。其中，ESPN对应的隐向量$\boldsymbol w_{ESPN}$在两次特征交叉过程中是不变的。

而在FFM中，ESPN与NIKE、ESPN与Male交叉特殊的权重分别是$\boldsymbol w_{ESPN,A}\cdot \boldsymbol w_{NIKE,P}$和$\boldsymbol w_{ESPN,G}\cdot \boldsymbol w_{Male,P}$。

细心的读者肯定已经注意到，ESPN在与NIKE和Male交叉时分别使用了不同的隐向量$\boldsymbol w_{ESPN,A}$和$\boldsymbol w_{ESPN,G}$，这是由于NIKE和Male分别在不同的特征域Advertiser（A）和Gender(G)导致的。

在FFM模型的训练过程中，需要学习n个特征在f个域上的k维隐向量，参数数量共$n\cdot k\cdot f$个。在训练方面，FFM的二次项并不能像FM那样简化，因此其复杂度为$kn^2$。

相比FM，FFM引入了特征域的概念，为模型引入了更多有价值的信息，使模型的表达能力更强，但与此同时，FFM的计算复杂度上升到$kn^2$，远大于FM的$kn$。在实际工程应用中，需要在模型效果和工程投入之间进行权衡。

### 1.7.1 从POLY2到FFM的模型演化过程

POLY2模型直接学习每个交叉特征的权重，若特征数量为n，则权重数量为$n^2$量级，具体为n(n-1)/2个。如下所示，每个圆点代表一个特征交叉项。

~~~
f(w,x) =	⚪		+		⚪		+		⚪
		w(ESPN,NIKE)	w(ESPN,Male)	w(NIKE,Male)
~~~

FM模型学习每个特征的k维隐向量，交叉特征由相应特征隐向量的内积得到，权重数量共nk个。FM比POLY2的泛化能力强，但记忆能力有所减弱，处理稀疏特征向量的能力远强于POLY2。每个特征交叉项不再是单独的圆点，而是3个圆点的内积，代表每个特征有一个3维的隐向量。

~~~
			⚪		⚪				⚪		⚪				⚪		⚪
f(w,x) =	⚪	·	⚪		+		⚪	·	⚪		+		⚪	·	⚪
			⚪		⚪				⚪		⚪				⚪		⚪
		w(ESPN)		w(NIKE)			w(ESPN)		w(Male)			w(NIKE)	w(Male)
~~~

FFM模型在FM模型的基础上引入了特征域的概念，在做特征交叉时，每个特征选择与对方域对应的隐向量做内积运算，得到交叉特征的权重，在有n个特征，f个特征域，隐向量维度为k的前提下，参数数量共$n\cdot k\cdot f$个。如下所示，每个特征都有两个隐向量，根据特征交叉对象特征域的不同，选择使用对应的隐向量。

~~~
			⚪⚪		⚪⚪			⚪⚪		⚪⚪			⚪⚪		⚪⚪
f(w,x) =	⚪⚪	·	⚪⚪		+	⚪⚪	·	⚪⚪		+	⚪⚪	·	⚪⚪
			⚪⚪		⚪⚪			⚪⚪		⚪⚪			⚪⚪		⚪⚪
		w(ESPN,A)	w(NIKE,P)		w(ESPN,G)	w(Male,P)	w(NIKE,G)	w(Male,A)
~~~

理论上，FM模型族利用交叉特征的思路可以引申到三阶特征交叉，甚至更高维的阶段，但由于组合爆炸问题的限制，三阶FM无论是权重数量还是训练复杂度都过高，难以在实际工程中实现。那么，如何突破二阶特征交叉的限制，进一步加强模型特征组合的能力，就成了推荐模型发展的方向。

## 1.8 GBDT+LR

FFM模型采用引入特征域的方式增强了模型的特征交叉能力，但无论如何，FFM只能做二阶的特征交叉，如果继续提高特征交叉的维度，会不可避免地产生组合爆炸和计算复杂度过高的问题。那么，有没有其他方法可以有效地处理高维特征组合和筛选的问题呢？2014年，Facebook提出了基于GBDT+LR组合模型的解决方案。

### 1.8.1 GBDT+LR组合模型的结构

简而言之，Facebook提出了一种利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当作LR模型输入，预估CTR的模型结构。

> GBDT+LR的模型结构：
>
> 输入特征 --> 树分裂 --> 转换后的特征 --> 线性分类器

需要强调的是，用GDBT构建特征工程，利用LR预估CTR这两步是独立训练的，所以不存在如何将LR的梯度回传到GDBT这类复杂的问题。利用LR预估CTR的过程在1.4逻辑回归可以看到，本节着重讲解利用GBDT构建新的特征向量的过程。

> **什么是GBDT模型**？
>
> GBDT的基本结构是决策树组成的树林，学习方式是梯度提升。
>
> 具体地讲，GBDT作为集成模型，预测的方式是把所有子树的结果加起来。
> $$
> D(x)=d_{tree1}(x)+d_{tree2}(x)+\cdots
> $$
> GBDT通过逐一生成决策子树的方式生成整个树林，生成新子树的过程是利用样本标签值与当前树林预测值之间的残差，构建新的子树。
>
> 假设当前已经生成了3棵子树，则当前的预测值为
> $$
> D(x)=d_{tree1}(x)+d_{tree2}(x)+d_{tree3}(x)
> $$
> GBDT期望的是构建第4棵子树，使当前树林的预测结果D(x)与第4棵子树的预测结果$d_{tree4}(x)$之和，能进一步逼近理论上拟合函数f(x)，即
> $$
> D(x)+d_{tree4}(x)=f(x)
> $$
> 所以，第4棵子树的生成过程是以目标拟合函数和已有树林预测结果的残差R(X)为目标的：
> $$
> R(x)=f(x)-D(x)
> $$
> 理论上，如果可以无限生成决策树，那么GBDT可以无限逼近由所有训练集样本组成的目标拟合函数，从而达到减少预测误差的目的。

GBDT是由多棵回归树组成的树林，后一棵树以前面树林的结果与真实结果的残差为拟合目标。每棵树生成的过程是一棵标准的回归树生成过程，因此回归树中每个节点的分裂是一个自然的特征选择的过程，而多层节点的结构则对特征进行了有效的自动组合，也就非常高效的解决了过去棘手的特征选择和特征组合的问题。

### 1.8.2 GBDT进行特征转换的过程

利用训练集训练好GBDT模型之后，就可以利用该模型完成从原始特征向量到新的离散型特征向量的转化。具体过程如下。

一个训练样本在输入GBDT的某一子树后，会根据每个节点的规则最终落入某一叶子节点，把该叶子节点置为1，其他叶子节点置为0，所有叶子节点组成的向量即形成了该棵树的特征向量，把GBDT所有子树的特征向量连接起来，即形成了后续LR模型输入的离散型特征向量。

举例来说，GBDT可以由三棵子树构成，每棵子树有4个叶子节点，输入一个训练样本后，其先后落入”子树1“的第3个叶节点中，那么特征向量就是`[0,0,1,0]`，”子树2“的第1个叶节点，特征向量为`[1,0,0,0]`，”子树3“的第4个叶节点，特征向量为`[0,0,0,1]`，最后连接所有特征向量，形成最终的特征向量`[0,0,1,0,1,0,0,0,0,0,0,1]`。

事实上，决策树的深度决定了特征交叉的阶数。如果决策树的深度为4，则通过3次节点分裂，最终的叶节点实际上是进行三阶特征组合后的结果，如此强的特征组合能力显然是FM系的模型不具备的。但GBDT容易产生过拟合，以及GBDT的特征转换方式实际上丢失了大量特征的数值信息，因此不能简单地说GBDT的特征交叉能力强，效果就比FFM好，在模型的选择和调试上，永远都是多种因素综合作用的结果。

### 1.8.3 GBDT+LR组合模型开启的特征工程新趋势

GBDT+LR组合模型对于推荐系统领域的重要性在于，它大大推进了特征工程模型化这一重要趋势。在GBDT+LR组合模型出现之前，特征工程的主要解决方法有两个：一是进行人工的或半人工的特征组合和特征筛选；二是通过改造目标函数，改进模型结构，增加特征交叉项的方式增强特征组合能力。但这两种方法都有弊端，第一种方法对算法工程师的经验和精力投入要求较高；第二种方法则要求从根本上改变模型结构，对模型设计能力的要求较高。

GBDT+LR组合模型的提出，意味着特征工程可以完全交由一个独立的模型来完成，模型的输入可以是原始的特征向量，不必在特征工程上投入过多的人工筛选和模型设计的精力，实现真正的端到端（End to End）训练。

广义上讲，深度学习模型通过各类网络结构、Embedding层等方法完成特征工程的自动化，都是GBDT+LR开启的特征工程模型化这一趋势的延续。

## 1.9 LS-PLM

阿里巴巴曾经的主流推荐模型——”大规模分段线性模型“（Large Scale Piece-wise Linear Model，简称为LS-PLM）。

虽然该模型在2017年才被阿里巴巴公之于众，但其实早在2012年，它就是阿里巴巴主流的推荐模型，并在深度学习模型提出之前长时间应用于阿里巴巴的各类广告场景。

LS-PLM的结构与三层神经网络极其相似，在深度学习来临的前夜，可以将它看作推荐系统领域连接两个时代的节点。

### 1.9.1 LS-PLM模型的主要结构

LS-PLM，又被称为MLR（Mixed Logistic Regression，混合逻辑回归）模型。本质上，LS-PLM可以看作对逻辑回归的自然推广，它在逻辑回归的基础上采用分而治之的思路，先对样本进行分片，再在样本分片中应用逻辑回归进行CTR预估。

在逻辑回归的基础上加入聚类思想，其灵感来自对广告推荐领域样本特点的观察。举例来说，如果CTR模型要预估的是女性受众点击女装广告的CTR，那么显然，我们不希望把男性用户点击数码类产品的样本数据也考虑进来，因为这样的样本不仅与女性购买女装的广告场景毫无相关性，甚至会在模型训练过程中干扰相关特征的权重。为了让CTR模型对不同用户群体、不同使用场景更有针对性，其采用的方法是先对全量样本进行聚类，再对每个分类施以逻辑回归模型进行CTR预估。LS-PLM的实现思路就是由该灵感产生的。

LS-PLM的数学形式，首先用聚类函数$\pi$对样本进行分类（这里的$\pi$采用了softmax函数对样本进行多分类），再用LR模型计算样本在分片中具体的CTR，然后将二者相乘后求和。
$$
f(x)=\sum^m_{i=1}\pi_i(x)\cdot\eta_i(x)=\sum^m_{i=1}\frac{e^{\eta_i\cdot x}}{\sum^m_{j=1}e^{\mu_j\cdot x}}\cdot\frac{1}{1+e^{-w_i\cdot x}}
$$
其中的超参数”分片数“m可以较好地平衡模型的拟合与推广能力。当m=1时，LS-PLM就退化为普通的逻辑回归。m越大，模型的拟合能力越强。与此同时，模型参数规模也随m的增大而线性增长，模型收敛所需的训练样本也随之增长。在实践中，阿里巴巴给出的m的经验值为12.

如下图所示，分别用红色和蓝色表示两类训练数据，传统LR模型的拟合能力不足，无法找到非线性的分类面，而MLR模型用4个分片可以完美地拟合出数据中的菱形分类面。

![推荐系统_MLR模型对训练数据的拟合](推荐系统 配图\推荐系统_MLR模型对训练数据的拟合.jpg)

### 1.9.2 LS-PLM模型的优点

LS-PLM模型适用于工业级的推荐、广告等大规模稀疏数据的场景，主要是因为其具有以下两个优势。

1. 端到端的非线性学习能力：LS-PLM具有样本分片的能力，因此能够挖掘出数据中蕴藏的非线性模式，省去了大量的人工样本处理和特征工程的过程，使LS-PLM算法可以端到端地完成训练，便于用一个全局模型对不同应用领域、业务场景进行统一建模。
2. 模型的稀疏性强：LS-PLM在建模时引入了L1和L2，L1范数，可以使最终训练出来的模型具有较高的稀疏度，使模型的部署更加轻量级。模型服务过程仅需使用权重非零特征，因此稀疏模型也使其在线推断的效率更高。

## 1.10 总结

| 模型名称 | 基本原理                                                     | 特点                                                         | 局限性                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 协同过滤 | 根据用户的行为历史生成用户-物品共现矩阵，利用用户相似性和物品相似性进行推荐 | 原理简单、直接，应用广泛                                     | 泛化能力差，处理稀疏矩阵的能力差，推荐结果头部效应比较明显   |
| 矩阵分解 | 将协同过滤算法中的共现矩阵分解为用户矩阵和物品矩阵，利用用户隐向量和物品隐向量的内积进行排序并推荐 | 相较协同过滤，泛化能力有所增强，对稀疏矩阵的处理能力有所增强 | 除了用户历史行为数据，难以利用其他用户、物品特征及上下文特征 |
| 逻辑回归 | 将推荐问题转化成类似CTR预估的二分类问题，将用户、物品、上下文等不同特征转换成特征向量，输入逻辑回归模型得到CTR，再按照预估CTR进行排序并推荐 | 能够融合多种类型的不同特征                                   | 模型不具备特征组合能力，表达能力较差                         |
| FM       | 在逻辑回归的基础上，在模型中加入二阶特征交叉的部分，为每一维特征训练得到相应特征隐向量，通过隐向量间的内积运算得到交叉特征权重 | 相比逻辑回归，具备了二阶特征交叉能力，模型的表达能力增强     | 由于组合爆炸的问题的限制，模型不易扩展到三阶特征交叉阶段     |
| FFM      | 在FM模型的基础上，加入“特征域”的概念，使每个特征在与不同域的特征交叉时采用不同的隐向量 | 相比FM，进一步加强了特征交叉的能力                           | 模型的训练开销达到了$O(n^2)$的量级，训练开销较大             |
| GBDT+LR  | 利用GBDT进行“自动化”的特征组合，将原始特征向量转换成离散型特征向量，并输入逻辑回归模型，进行最终的CTR预估 | 特征工程模型化，使模型具备了更高阶特征组合的能力             | GBDT无法进行完全并行的训练，更新所需的训练时长较长           |
| LS-PLM   | 首先对样本进行“分片”，在每个“分片”内部构建逻辑回归模型，将每个样本的各个“分片”概率与逻辑回归的得分进行加权平均，得到最终的预估值 | 模型结构类似三层神经网络，具备了较强的表达能力               | 模型结构相比深度学习模型仍比较简单，有进一步提高的空间       |

# 二、深度学习推荐系统模型

**进展**：

1. 与传统的机器学习模型相比，深度学习模型的表达能力更强，能够挖掘出更多数据中潜藏的模式。
2. 深度学习的模型结构非常灵活，能够根据业务场景和数据特点，灵活调整模型结构，使模型与应用场景完美契合。

**演化关系**：

以多层感知机（Multi-Layer Perception, MLP) 为核心，通过改变神经网络的结构，构建特点各异的深度学习推荐模型，其主要的演变方向如下：

![推荐系统_主流深度学习推荐模型的演化图谱](推荐系统 配图\推荐系统_主流深度学习推荐模型的演化图谱.png)

1. **改变神经网络的复杂程度**：从最简单的单层神经网络模型AutoRec（自编码器推荐），到经典的深度神经网络结构Deep Crossing（深度特征交叉），其主要的进化方式在于——增加了深度神经网络的层数和结构复杂度。
2. **改变特征交叉方式**
3. **组合模型**
4. **FM模型的深度学习演化版本**
5. **注意力机制与推荐模型的结合**
6. **序列模型与推荐模型的结合**
7. **强化学习与推荐模型的结合**

# 参考文献

1. 《深度学习推荐系统》王喆/编著 电子工业出版社 2020.3
2. 《推荐系统实践》项亮/编著 人民邮电出版社 2012.6